{"blobs":[{"after":{"path":"app/controllers/application_controller/feature_flags_dependency.rb","content":"# frozen_string_literal: true\n\nclass ApplicationController\n  # A single around_filter that can be used to check and/or enable multiple\n  # feature flags for a request.\n  def enable_feature_flags\n    old_diff_timeout = GitHub::Diff.custom_default_timeout\n    if employee? && new_timeout = params[:prog_diff_timeout]\n      GitHub::Diff.custom_default_timeout = new_timeout.to_f\n    end\n\n    yield\n  ensure\n    GitHub::Diff.custom_default_timeout = old_diff_timeout\n  end\n\n  def current_user_feature_enabled?(sym)\n    logged_in? && current_user.feature_enabled?(sym)\n  end\n  helper_method :current_user_feature_enabled?\n\n  def current_repository_feature_enabled?(sym)\n    current_repository && current_repository.feature_enabled?(sym)\n  end\n  helper_method :current_repository_feature_enabled?\n\n  def enterprise_required\n    render_404 unless GitHub.enterprise?\n  end\n  private :enterprise_required\n\n  # define before_filter restriction method for audit_log_export feature\n  def audit_log_export_required\n    render_404 unless logged_in? && GitHub.audit_log_export_enabled?\n  end\n  private :audit_log_export_required\n\n  # Public: Enable \"mute button\" on search results.\n  # See: https://github.com/github/github/pull/24385\n  def mute_search_button_enabled?\n    preview_features?\n  end\n  helper_method :mute_search_button_enabled?\n\n  # Public: Enable new 'Discover repositories' tab on the dashboard\n  # See https://github.com/github/github/issues/76414\n  def discover_repos_dashboard_enabled?\n    current_user_feature_enabled?(\"discover-repos-dashboard\")\n  end\n  helper_method :discover_repos_dashboard_enabled?\n\n  def discover_repos_dashboard_required\n    unless discover_repos_dashboard_enabled?\n      if request.xhr? || pjax?\n        head :not_found\n      else\n        render_404\n      end\n    end\n  end\n\n  def abilities_team_enabled?\n    logged_in? && current_user.abilities_team_enabled?\n  end\n  helper_method :abilities_team_enabled?\n\n  # User feature flag-related methods\n\n  def dependencies_graph_enabled?\n    logged_in? && current_user.feature_enabled?(:dependencies_graph)\n  end\n  helper_method :dependencies_graph_enabled?\n\n  # Enable saved replies on the repo and org level\n  def repo_org_saved_replies_enabled?\n    logged_in? && current_user.feature_enabled?(:repo_org_saved_replies)\n  end\n  helper_method :repo_org_saved_replies_enabled?\n\n  # define controller method and helper method for `#oauth_registered_callback_urls_enabled?` user feature flag\n  def oauth_registered_callback_urls_enabled?\n    logged_in? && current_user.oauth_registered_callback_urls_enabled?\n  end\n  helper_method :oauth_registered_callback_urls_enabled?\n\n  # Dashboard Next\n  # See: https://github.com/github/product/pull/599\n  def dashboard_next?\n    current_user_feature_enabled?(:dashboard_next)\n  end\n  helper_method :dashboard_next?\n\n  # Bookmarks\n  # See: https://github.com/github/github/pull/71296\n  def can_bookmark?\n    current_user_feature_enabled?(:can_bookmark)\n  end\n  helper_method :can_bookmark?\n\n  # Universe callout on our logged-in user dashboards\n  # Replaces the broadcast and jobs banners for a promotion to buy Universe\n  # conference tickets. Maps to a dismissible user notice.\n  def universe_2017_dashboard_enabled?\n    current_user_feature_enabled?(:universe_dashboard)\n    # return true if GitHub.flipper[:universe_dashboard].enabled?\n  end\n  helper_method :universe_2017_dashboard_enabled?\n\n  # Repository feature flag-related methods\n\n  # Force raw/image rendering on a blob.  Needed for now because Git LFS objects\n  # look like text files.\n  def force_render_raw?\n    current_repository ? current_repository.git_lfs_enabled? : false\n  end\n  helper_method :force_render_raw?\n\n  def user_sync_emails?\n    GitHub.user_sync_emails? && logged_in? && current_user.ldap_mapped?\n  end\n  helper_method :user_sync_emails?\n\n  def user_sync_keys?\n    GitHub.user_sync_keys? && logged_in? && current_user.ldap_mapped?\n  end\n  helper_method :user_sync_keys?\n\n  def user_sync_gpg_keys?\n    GitHub.user_sync_gpg_keys? && logged_in? && current_user.ldap_mapped?\n  end\n  helper_method :user_sync_gpg_keys?\n\n  def syntax_highlighted_diffs_enabled?\n    # Staff can disable syntax-highlighted diffs with ?shd=0.\n    disabled = preview_features? && params[:shd] == \"0\"\n    !disabled\n  end\n  helper_method :syntax_highlighted_diffs_enabled?\n\n  def instance_audit_log_enabled?\n    GitHub.instance_audit_log_enabled? && logged_in? && current_user.site_admin?\n  end\n  helper_method :instance_audit_log_enabled?\n\n  def instance_audit_log_required\n    render_404 unless instance_audit_log_enabled?\n  end\n\n  def integrations_directory_enabled?\n    return false if GitHub.enterprise?\n\n    GitHub::PlatformEnforcement.allow_direct_data_access do\n      return true if GitHub.flipper[:integrations_directory].enabled?\n      current_user_feature_enabled?(:integrations_directory)\n    end\n  end\n  helper_method :integrations_directory_enabled?\n\n  def integrations_two_ui_enabled?\n    return true if GitHub.enterprise? && GitHub.apps_enabled?\n    logged_in? && current_user.integrations_two_ui_enabled?\n  end\n  helper_method :integrations_two_ui_enabled?\n\n  def deployments_next_dashboard_enabled?\n    return false unless logged_in?\n    if current_repository\n      return true if current_repository.feature_enabled?(:deployments_next_dashboard)\n    end\n    current_user.feature_enabled?(:deployments_next_dashboard)\n  end\n  helper_method :deployments_next_dashboard_enabled?\n\n  def deployments_next_reponav_enabled?\n    return false unless logged_in?\n    if current_repository\n      return true if current_repository.feature_enabled?(:deployments_next_reponav)\n    end\n    current_user.feature_enabled?(:deployments_next_reponav)\n  end\n  helper_method :deployments_next_reponav_enabled?\n\n  # Is the S/MIME signed-commits feature enabled for the request?\n  #\n  # If there's a `current_repository`, we check that the feature is enabled on\n  # the repo *and* the user. Otherwise, we just check the user.\n  #\n  # Returns boolean.\n  def smime_signed_commits_enabled?\n    if logged_in? && current_user.feature_enabled?(:smime_signed_commits)\n      if current_repository\n        current_repository.feature_enabled?(:smime_signed_commits)\n      else\n        true\n      end\n    end\n  end\n  helper_method :smime_signed_commits_enabled?\n\n  def enterprise_new_enabled?\n    return true if GitHub.flipper[:enterprise_new].enabled?\n  end\n  helper_method :enterprise_new_enabled?\n\n  def desktop_survey_hashed_id\n    @desktop_survey_hashed_id ||= current_user_crc32(unique_string: \"In app desktop survey\")\n  end\n  helper_method :desktop_survey_hashed_id\n\n  def quote_markdown_enabled?\n    # memoize return value because this will get asked repeatedly for each PR\n    # inline conversation thread\n    return @quote_markdown_enabled if defined?(@quote_markdown_enabled)\n    @quote_markdown_enabled = current_user_feature_enabled?(:quote_markdown)\n  end\n  helper_method :quote_markdown_enabled?\n\n  def org_creation_survey?\n    current_user.feature_enabled?(:org_creation_survey)\n  end\n  helper_method :org_creation_survey?\n\n  # Marketing page feature flag-releated methods\n\n  # Check whether the Marketplace is enabled for current request\n  #\n  # Returns a Boolean value.\n  def marketplace_enabled?\n    !GitHub.enterprise?\n  end\n  helper_method :marketplace_enabled?\n\n  # Halts the request unless the Marketplace feature is enabled for the current request.\n  #\n  # This is intended for use as a `before` filter for use in conjunction with\n  # the #marketplace_enabled? feature flag.\n  #\n  # Returns nothing.\n  def marketplace_required\n    render_404 unless marketplace_enabled?\n  end\n\n  def lfs_locked_files_enabled?\n    current_repository.feature_enabled?(:lfs_locked_files) ||\n      (logged_in? && current_user.feature_enabled?(:lfs_locked_files))\n  end\n  helper_method :lfs_locked_files_enabled?\n\n  def tiered_sudo_enabled?\n    logged_in? && current_user.feature_enabled?(:tiered_sudo)\n  end\n  helper_method :tiered_sudo_enabled?\n\n  def team_discussions_enabled?\n    logged_in? && current_user.feature_enabled?(:team_discussions)\n  end\n  helper_method :team_discussions_enabled?\n\n  def semantic_edge_languages_enabled?\n    logged_in? && current_user.semantic_edge_languages_enabled?\n  end\n  helper_method :semantic_edge_languages_enabled?\n\n  def semiotic_on_kubes_enabled?\n    logged_in? && current_user.semiotic_on_kubes_enabled?\n  end\n  helper_method :semiotic_on_kubes_enabled?\n\n  private\n\n  def flipper_session_id\n    session[FlipperSession.session_key] ||= FlipperSession.generate_id\n  end\n\n  def flipper_session\n    @flipper_session ||= FlipperSession.new(flipper_session_id)\n  end\n  helper_method :flipper_session\n\n  def universe_banner_enabled?\n    return true if GitHub.flipper[:universe_banner].enabled?\n  end\n  helper_method :universe_banner_enabled?\n\n  # Internal: Calculate crc32 for the current_user or a unique user id from the\n  # _octo cookie for logged_out requests.\n  #\n  # unique_string - String additional random variable so that different popups\n  #                 can be run at the same time. See\n  #                 http://watchout4snakes.com/wo4snakes/Random/RandomSentence\n  #                 for generating random sentences that work well for this\n  #                 value.\n  #\n  # Returns an Integer or nil if user could not be uniquely identified.\n  def current_user_crc32(unique_string:)\n    id = if logged_in?\n      current_user.id.to_s\n    elsif cookies[:_octo] =~ /^[^.]+\\.[^.]+\\.\\d+\\.\\d+$/\n      # Turn \"GH1.2-3.XYZ.DEF\" into \"XYZ.DEF\"\n      cookies[:_octo].split(\".\")[2..3].join(\".\")\n    end\n\n    return nil unless id\n\n    Zlib.crc32(\"#{id}#{unique_string}\")\n  end\nend\n","language":"Ruby"},"before":{"path":"app/controllers/application_controller/feature_flags_dependency.rb","content":"# frozen_string_literal: true\n\nclass ApplicationController\n  # A single around_filter that can be used to check and/or enable multiple\n  # feature flags for a request.\n  def enable_feature_flags\n    old_diff_timeout = GitHub::Diff.custom_default_timeout\n    if employee? && new_timeout = params[:prog_diff_timeout]\n      GitHub::Diff.custom_default_timeout = new_timeout.to_f\n    end\n\n    yield\n  ensure\n    GitHub::Diff.custom_default_timeout = old_diff_timeout\n  end\n\n  def current_user_feature_enabled?(sym)\n    logged_in? && current_user.feature_enabled?(sym)\n  end\n  helper_method :current_user_feature_enabled?\n\n  def current_repository_feature_enabled?(sym)\n    current_repository && current_repository.feature_enabled?(sym)\n  end\n  helper_method :current_repository_feature_enabled?\n\n  def enterprise_required\n    render_404 unless GitHub.enterprise?\n  end\n  private :enterprise_required\n\n  # define before_filter restriction method for audit_log_export feature\n  def audit_log_export_required\n    render_404 unless logged_in? && GitHub.audit_log_export_enabled?\n  end\n  private :audit_log_export_required\n\n  # Public: Enable \"mute button\" on search results.\n  # See: https://github.com/github/github/pull/24385\n  def mute_search_button_enabled?\n    preview_features?\n  end\n  helper_method :mute_search_button_enabled?\n\n  # Public: Enable new 'Discover repositories' tab on the dashboard\n  # See https://github.com/github/github/issues/76414\n  def discover_repos_dashboard_enabled?\n    current_user_feature_enabled?(\"discover-repos-dashboard\")\n  end\n  helper_method :discover_repos_dashboard_enabled?\n\n  def discover_repos_dashboard_required\n    unless discover_repos_dashboard_enabled?\n      if request.xhr? || pjax?\n        head :not_found\n      else\n        render_404\n      end\n    end\n  end\n\n  def abilities_team_enabled?\n    logged_in? && current_user.abilities_team_enabled?\n  end\n  helper_method :abilities_team_enabled?\n\n  # User feature flag-related methods\n\n  def dependencies_graph_enabled?\n    logged_in? && current_user.feature_enabled?(:dependencies_graph)\n  end\n  helper_method :dependencies_graph_enabled?\n\n  # Enable saved replies on the repo and org level\n  def repo_org_saved_replies_enabled?\n    logged_in? && current_user.feature_enabled?(:repo_org_saved_replies)\n  end\n  helper_method :repo_org_saved_replies_enabled?\n\n  # define controller method and helper method for `#oauth_registered_callback_urls_enabled?` user feature flag\n  def oauth_registered_callback_urls_enabled?\n    logged_in? && current_user.oauth_registered_callback_urls_enabled?\n  end\n  helper_method :oauth_registered_callback_urls_enabled?\n\n  # Dashboard Next\n  # See: https://github.com/github/product/pull/599\n  def dashboard_next?\n    current_user_feature_enabled?(:dashboard_next)\n  end\n  helper_method :dashboard_next?\n\n  # Bookmarks\n  # See: https://github.com/github/github/pull/71296\n  def can_bookmark?\n    current_user_feature_enabled?(:can_bookmark)\n  end\n  helper_method :can_bookmark?\n\n  # Universe callout on our logged-in user dashboards\n  # Replaces the broadcast and jobs banners for a promotion to buy Universe\n  # conference tickets. Maps to a dismissible user notice.\n  def universe_2017_dashboard_enabled?\n    current_user_feature_enabled?(:universe_dashboard)\n    # return true if GitHub.flipper[:universe_dashboard].enabled?\n  end\n  helper_method :universe_2017_dashboard_enabled?\n\n  # Repository feature flag-related methods\n\n  # Force raw/image rendering on a blob.  Needed for now because Git LFS objects\n  # look like text files.\n  def force_render_raw?\n    current_repository ? current_repository.git_lfs_enabled? : false\n  end\n  helper_method :force_render_raw?\n\n  def user_sync_emails?\n    GitHub.user_sync_emails? && logged_in? && current_user.ldap_mapped?\n  end\n  helper_method :user_sync_emails?\n\n  def user_sync_keys?\n    GitHub.user_sync_keys? && logged_in? && current_user.ldap_mapped?\n  end\n  helper_method :user_sync_keys?\n\n  def user_sync_gpg_keys?\n    GitHub.user_sync_gpg_keys? && logged_in? && current_user.ldap_mapped?\n  end\n  helper_method :user_sync_gpg_keys?\n\n  def syntax_highlighted_diffs_enabled?\n    # Staff can disable syntax-highlighted diffs with ?shd=0.\n    disabled = preview_features? && params[:shd] == \"0\"\n    !disabled\n  end\n  helper_method :syntax_highlighted_diffs_enabled?\n\n  def instance_audit_log_enabled?\n    GitHub.instance_audit_log_enabled? && logged_in? && current_user.site_admin?\n  end\n  helper_method :instance_audit_log_enabled?\n\n  def instance_audit_log_required\n    render_404 unless instance_audit_log_enabled?\n  end\n\n  def integrations_directory_enabled?\n    return false if GitHub.enterprise?\n\n    GitHub::PlatformEnforcement.allow_direct_data_access do\n      return true if GitHub.flipper[:integrations_directory].enabled?\n      current_user_feature_enabled?(:integrations_directory)\n    end\n  end\n  helper_method :integrations_directory_enabled?\n\n  def integrations_two_ui_enabled?\n    return true if GitHub.enterprise? && GitHub.apps_enabled?\n    logged_in? && current_user.integrations_two_ui_enabled?\n  end\n  helper_method :integrations_two_ui_enabled?\n\n  def deployments_next_dashboard_enabled?\n    return false unless logged_in?\n    if current_repository\n      return true if current_repository.feature_enabled?(:deployments_next_dashboard)\n    end\n    current_user.feature_enabled?(:deployments_next_dashboard)\n  end\n  helper_method :deployments_next_dashboard_enabled?\n\n  def deployments_next_reponav_enabled?\n    return false unless logged_in?\n    if current_repository\n      return true if current_repository.feature_enabled?(:deployments_next_reponav)\n    end\n    current_user.feature_enabled?(:deployments_next_reponav)\n  end\n  helper_method :deployments_next_reponav_enabled?\n\n  # Is the S/MIME signed-commits feature enabled for the request?\n  #\n  # If there's a `current_repository`, we check that the feature is enabled on\n  # the repo *and* the user. Otherwise, we just check the user.\n  #\n  # Returns boolean.\n  def smime_signed_commits_enabled?\n    if logged_in? && current_user.feature_enabled?(:smime_signed_commits)\n      if current_repository\n        current_repository.feature_enabled?(:smime_signed_commits)\n      else\n        true\n      end\n    end\n  end\n  helper_method :smime_signed_commits_enabled?\n\n  def enterprise_new_enabled?\n    return true if GitHub.flipper[:enterprise_new].enabled?\n  end\n  helper_method :enterprise_new_enabled?\n\n  def desktop_survey_hashed_id\n    @desktop_survey_hashed_id ||= current_user_crc32(unique_string: \"In app desktop survey\")\n  end\n  helper_method :desktop_survey_hashed_id\n\n  def quote_markdown_enabled?\n    # memoize return value because this will get asked repeatedly for each PR\n    # inline conversation thread\n    return @quote_markdown_enabled if defined?(@quote_markdown_enabled)\n    @quote_markdown_enabled = current_user_feature_enabled?(:quote_markdown)\n  end\n  helper_method :quote_markdown_enabled?\n\n  def org_creation_survey?\n    current_user.feature_enabled?(:org_creation_survey)\n  end\n  helper_method :org_creation_survey?\n\n  # Marketing page feature flag-releated methods\n\n  # Check whether the Marketplace is enabled for current request\n  #\n  # Returns a Boolean value.\n  def marketplace_enabled?\n    !GitHub.enterprise?\n  end\n  helper_method :marketplace_enabled?\n\n  # Halts the request unless the Marketplace feature is enabled for the current request.\n  #\n  # This is intended for use as a `before` filter for use in conjunction with\n  # the #marketplace_enabled? feature flag.\n  #\n  # Returns nothing.\n  def marketplace_required\n    render_404 unless marketplace_enabled?\n  end\n\n  def lfs_locked_files_enabled?\n    current_repository.feature_enabled?(:lfs_locked_files) ||\n      (logged_in? && current_user.feature_enabled?(:lfs_locked_files))\n  end\n  helper_method :lfs_locked_files_enabled?\n\n  def tiered_sudo_enabled?\n    logged_in? && current_user.feature_enabled?(:tiered_sudo)\n  end\n  helper_method :tiered_sudo_enabled?\n\n  def team_discussions_enabled?\n    logged_in? && current_user.feature_enabled?(:team_discussions)\n  end\n  helper_method :team_discussions_enabled?\n\n  def semantic_edge_languages_enabled?\n    logged_in? && current_user.semantic_edge_languages_enabled?\n  end\n  helper_method :semantic_edge_languages_enabled?\n\n  private\n\n  def flipper_session_id\n    session[FlipperSession.session_key] ||= FlipperSession.generate_id\n  end\n\n  def flipper_session\n    @flipper_session ||= FlipperSession.new(flipper_session_id)\n  end\n  helper_method :flipper_session\n\n  def universe_banner_enabled?\n    return true if GitHub.flipper[:universe_banner].enabled?\n  end\n  helper_method :universe_banner_enabled?\n\n  # Internal: Calculate crc32 for the current_user or a unique user id from the\n  # _octo cookie for logged_out requests.\n  #\n  # unique_string - String additional random variable so that different popups\n  #                 can be run at the same time. See\n  #                 http://watchout4snakes.com/wo4snakes/Random/RandomSentence\n  #                 for generating random sentences that work well for this\n  #                 value.\n  #\n  # Returns an Integer or nil if user could not be uniquely identified.\n  def current_user_crc32(unique_string:)\n    id = if logged_in?\n      current_user.id.to_s\n    elsif cookies[:_octo] =~ /^[^.]+\\.[^.]+\\.\\d+\\.\\d+$/\n      # Turn \"GH1.2-3.XYZ.DEF\" into \"XYZ.DEF\"\n      cookies[:_octo].split(\".\")[2..3].join(\".\")\n    end\n\n    return nil unless id\n\n    Zlib.crc32(\"#{id}#{unique_string}\")\n  end\nend\n","language":"Ruby"}},{"after":{"path":"app/controllers/pull_requests_controller.rb","content":"# frozen_string_literal: true\n\nclass PullRequestsController < AbstractRepositoryController\n  areas_of_responsibility :code_collab, :pull_requests\n\n  include ShowPartial, PrefetchHelper, ProgressiveTimeline, DiscussionPreloadHelper,\n    ControllerMethods::Diffs, MarketplaceHelper\n\n  helper :compare\n  before_filter :login_required, only: [:create, :comment, :merge_button, :sync, :dismiss_protip]\n  before_filter :login_required_redirect_for_public_repo, only: [:new]\n  before_filter :writable_repository_required,\n    except: [:new, :show, :show_partial, :merge_button, :diff, :patch, :merge_button_matrix]\n  before_filter :check_for_empty_repository, only: [:create, :new]\n  before_filter :ensure_pull_head_pushable, only: [:cleanup, :undo_cleanup, :sync]\n  before_filter :content_authorization_required, only: [:create, :merge]\n  skip_before_filter :cap_pagination, unless: :robot?\n\n  layout :repository_layout\n\n  param_encoding :create, :base, \"ASCII-8BIT\"\n  param_encoding :create, :head, \"ASCII-8BIT\"\n  param_encoding :new, :range, \"ASCII-8BIT\"\n\n  def new\n    redirect_to compare_path(current_repository, params[:range], true)\n  end\n\n  def create\n    repo = current_repository\n    return render_404 unless repo\n    return if reject_bully_for?(repo)\n\n    params[:pull_request] ||= {}\n    options = params.slice(:base, :head)\n    options[:user] = current_user\n\n    params[:issue] ||= {}\n    params[:issue][:title] = params[:pull_request][:title]\n    params[:issue][:body]  = params[:pull_request][:body]\n    options[:issue] = build_issue\n    options[:collab_privs] = !!params[:collab_privs]\n    options[:reviewer_user_ids] = params[:reviewer_user_ids]\n    options[:reviewer_team_ids] = params[:reviewer_team_ids]\n\n    begin\n      @pull_request = PullRequest.create_for!(repo, options)\n      @comparison   = @pull_request.comparison\n      @issue        = @pull_request.issue\n\n      GitHub.instrument \"pull_request.create\", user: current_user\n      instrument_issue_creation_via_ui(@pull_request)\n      instrument_saved_reply_use(params[:saved_reply_id], \"pull_request\")\n      # Keep track of if a pull request targets the repo's\n      # default branch, or one in progress.\n      if options[:base].strip == \"#{repo.owner}:#{repo.default_branch}\"\n        GitHub.stats.increment(\"pullrequest.target.default\")\n      else\n        GitHub.stats.increment(\"pullrequest.target.other\")\n      end\n\n      if params[:quick_pull].present?\n        type = @pull_request.cross_repo? ? \"cross\" : \"same\"\n        GitHub.stats.increment(\"pullrequest.quick.total.create\")\n        GitHub.stats.increment(\"pullrequest.quick.#{type}.create\")\n      end\n\n      redirect_to pull_request_path(@pull_request, repo)\n    rescue ActiveRecord::RecordInvalid => e\n      flash[:error] = \"Pull request creation failed. #{human_failure_message(e)}\"\n      range = [options[:base], options[:head]].compact.join(\"...\")\n      redirect_to compare_path(repo, range, true)\n    end\n  end\n\n  ShowCommitsQuery = parse_query <<-'GRAPHQL'\n    query($id: ID!) {\n      pull: node(id: $id) {\n        ...Views::PullRequests::Commits::PullRequest\n      }\n    }\n  GRAPHQL\n\n  def show\n    @mobile_view_available = true\n\n    redirect_or_error = ensure_valid_pull_request\n\n    if performed?\n      return redirect_or_error\n    end\n\n    if params[:range]\n      env[\"pull_request.timeout_reason\"] = \"compute_diff\"\n\n      if oids = parse_show_range_oid_components(@pull, params[:range])\n        oid1, oid2 = oids\n      else\n        return render \"pull_requests/bad_range\", status: :not_found\n      end\n\n      allowed_commits = @pull.changed_commit_oids\n      if !(oid1.nil? || allowed_commits.include?(oid1)) || !allowed_commits.include?(oid2)\n        return render \"pull_requests/bad_range\", status: :not_found\n      end\n\n      if oid1 && (oid1 == oid2 || !@pull.repository.rpc.descendant_of([[oid2, oid1]]).values.first)\n        return render \"pull_requests/bad_range\", status: :not_found\n      end\n\n      expected_canonical_range = oid1 ? \"#{oid1}..#{oid2}\" : \"#{oid2}\"\n      if params[:range] != expected_canonical_range\n        return redirect_to(range: expected_canonical_range)\n      end\n\n      if params[:tab] == \"commits\"\n        @specified_tab = \"files\"\n        oid1 = current_repository.commits.find(oid2).parent_oids.first\n      end\n\n      @comparison = @pull.historical_comparison\n      merge_base_oid = @comparison.compare_repository.best_merge_base(@pull.base_sha, oid2)\n\n      if merge_base_oid.nil?\n        return render \"pull_requests/orphan_commit\", status: :not_found, locals: { oid2: oid2 }\n      end\n\n      oid1 ||= @pull.compare_repository.best_merge_base(oid2, merge_base_oid) if merge_base_oid\n      unless @pull_comparison = PullRequest::Comparison.find(pull: @pull, start_commit_oid: oid1, end_commit_oid: oid2, base_commit_oid: merge_base_oid)\n        return render \"pull_requests/bad_range\", status: :not_found\n      end\n\n      load_diff\n\n      env[\"pull_request.timeout_reason\"] = nil\n    else\n      @comparison = @pull.comparison\n\n      if specified_tab == \"files\"\n        env[\"pull_request.timeout_reason\"] = \"compute_diff\"\n\n        start_oid, end_oid = @pull.merge_base, @pull.head_sha\n        if start_oid && end_oid\n          begin\n            start_commit, end_commit = @pull.compare_repository.commits.find([start_oid, end_oid])\n            @pull_comparison = PullRequest::Comparison.new(pull: @pull, start_commit: start_commit, end_commit: end_commit, base_commit: start_commit)\n\n            load_diff\n          rescue GitRPC::ObjectMissing\n          end\n        end\n\n        env[\"pull_request.timeout_reason\"] = nil\n      end\n    end\n\n    prefetch_deferred do\n      if specified_tab == \"files\" && @pull_comparison && logged_in?\n        @pull_comparison.mark_as_seen(user: current_user)\n        mark_thread_as_read @pull.issue\n      elsif specified_tab == \"discussion\"\n        mark_thread_as_read @pull.issue\n      end\n    end\n\n    if prefetch_viewed?\n      return head(:no_content)\n    end\n\n    @labels = current_repository.sorted_labels\n\n    prepare_for_rendering(timeline: specified_tab == \"discussion\", pull_comparison: @pull_comparison)\n\n    unless \"discussion\" == specified_tab\n      override_analytics_location \"/<user-name>/<repo-name>/pull_requests/show/#{specified_tab}\"\n    end\n\n    # Enroll the user in an A/A expriment to test Frequency. Can be removed after experiment verification is concluded.\n    if \"discussion\" == specified_tab && show_marketplace_ci_cta?(current_repository)\n      GitHub::UserResearch.experiment_variant(\n        experiment: UserExperimentCohort::MARKETPLACECICTA,\n        subject: current_user\n      )\n    end\n\n    respond_to do |format|\n      format.html do\n        if show_mobile_view? && (request_category != \"raw\")\n          return render_template_view(\"mobile/pull_requests/show\", Mobile::PullRequests::ShowPageView, {\n            pull: @pull,\n            diffs: @pull_comparison.try(:diffs),\n            tab: specified_tab,\n            visible_timeline_items: visible_timeline_items,\n            showing_full_timeline: showing_full_timeline?\n          }, layout: \"mobile/application\")\n        end\n\n        if params[:shdds]\n          @syntax_highlighted_diffs_forced = true\n          render_to_string\n          head :no_content\n        else\n          if logged_in?\n            @current_review = @pull.latest_pending_review_for(current_user)\n          end\n\n          if specified_tab == \"files\"\n            if @pull_comparison.nil?\n              render \"pull_requests/files_unavailable\"\n            else\n              render \"pull_requests/files\"\n            end\n          elsif specified_tab == \"commits\"\n            data = platform_execute(ShowCommitsQuery, variables: { id: @pull.global_relay_id })\n            render \"pull_requests/commits\", locals: { pull_node: data.pull }\n          else\n            render \"pull_requests/conversation\"\n          end\n        end\n      end\n      if params[:tab] == \"commits\"\n        format.diff { commit_diff(oid2) }\n        format.patch { commit_patch(oid2) }\n      end\n    end\n  end\n\n  def commit_diff(oid)\n    redirect_to commit_path(oid, current_repository) + \".diff\"\n  end\n\n  def commit_patch(oid)\n    redirect_to commit_path(oid, current_repository) + \".patch\"\n  end\n\n  TIMELINE_PARTIALS = %w[\n    pull_requests/timeline\n    pull_requests/timeline_marker\n  ].freeze\n\n  VALID_REASONS = %w[\n    view-more-button\n    expose-fragment\n  ].freeze\n\n  ShowPartialCommitsPartialQuery = parse_query <<-'GRAPHQL'\n    query($id: ID!) {\n      pull: node(id: $id) {\n        ...Views::PullRequests::CommitsPartial::PullRequest\n      }\n    }\n  GRAPHQL\n\n  def show_partial\n    partial = params[:partial]\n    return head :not_found unless valid_partial?(partial)\n\n    GitHub.stats.time(\"pullrequest.show_partial_find\") do\n      @pull = PullRequest.find_by_number_and_repo(params[:id].to_i, current_repository)\n    end\n\n    return head :not_found unless @pull\n\n    if partial == \"pull_requests/timeline\"\n      if focused_timeline? && visible_timeline_items.empty?\n        return head :bad_request\n      end\n\n      reason = VALID_REASONS.include?(params[:reason]) ? params[:reason] : \"other\"\n      GitHub.stats.increment(\"pullrequest.show_partial.timeline.#{reason}.count\")\n    end\n\n    prepare_for_rendering(timeline: TIMELINE_PARTIALS.include?(partial), pull_comparison: nil)\n\n    if partial == \"pull_requests/commits_partial\"\n      pull_node = platform_execute(ShowPartialCommitsPartialQuery, variables: { id: @pull.global_relay_id }).pull\n    end\n\n    GitHub.stats.time(\"pullrequest.show_partial_render\") do\n      respond_to do |format|\n        format.html do\n          render partial: partial, object: @pull, layout: false, locals: { # rubocop:disable GitHub/RailsControllerRenderLiteral\n            pull: @pull,\n            pull_request: pull_node,\n            merge_type: params[:merge_type]\n          }\n        end\n      end\n    end\n  end\n\n  ShowPartialCommitQuery = parse_query <<-'GRAPHQL'\n    query($id: ID!) {\n      node(id: $id) {\n        ...Views::Commits::PullCommitsListItem::PullRequestCommit\n        ...Views::Commit::PullCondensed::PullRequestCommit\n      }\n    }\n  GRAPHQL\n\n  # TODO Remove this endpoint and use NodesController once everything\n  # in the view templates moved to GraphQL.\n  def show_partial_commit\n    partial = params[:partial]\n    return head :not_found unless valid_partial?(partial)\n\n    unless pull = PullRequest.find_by_number_and_repo(params[:id].to_i, current_repository)\n      return head :not_found\n    end\n\n    unless commit = current_commit\n      return head :not_found\n    end\n\n    pull_request_commit = Platform::Models::PullRequestCommit.new(pull, current_commit)\n    data = platform_execute(ShowPartialCommitQuery, variables: { id: pull_request_commit.global_relay_id })\n\n    # TODO Remove once we transitioned `commits/pull_commits_list_item` to GraphQL\n    Commit.prefill_combined_statuses([current_commit], current_repository)\n\n    GitHub.stats.time(\"pullrequest.show_partial_render\") do\n      respond_to do |format|\n        format.html do\n          render partial: partial, object: commit, layout: false, locals: { pull: pull, commit: commit, pull_request_commit: data.node } # rubocop:disable GitHub/RailsControllerRenderLiteral\n        end\n      end\n    end\n  end\n\n  def show_partial_comparison\n    partial = params[:partial]\n    return head :not_found unless valid_partial?(partial)\n\n    unless pull = PullRequest.find_by_number_and_repo(params[:id].to_i, current_repository)\n      return head :not_found\n    end\n\n    unless pull_comparison = PullRequest::Comparison.find(pull: pull, start_commit_oid: params[:start_commit_oid], end_commit_oid: params[:end_commit_oid], base_commit_oid: params[:base_commit_oid])\n      return head :not_found\n    end\n\n    GitHub.stats.time(\"pullrequest.show_partial_render\") do\n      respond_to do |format|\n        format.html do\n          render partial: partial, locals: { pull: pull, pull_comparison: pull_comparison } # rubocop:disable GitHub/RailsControllerRenderLiteral\n        end\n      end\n    end\n  end\n\n  def show_toc\n    pull = PullRequest.find_by_number_and_repo(params[:id], current_repository)\n    return head :not_found unless pull\n\n    return head :not_found unless valid_sha_param?(:sha1) &&\n                                  valid_sha_param?(:sha2) && params[:sha2].present? &&\n                                  valid_sha_param?(:base_sha)\n\n    diff_options = { base_sha: params[:base_sha] }\n    diff = GitHub::Diff.new(pull.compare_repository, params[:sha1], params[:sha2], diff_options)\n\n    summary = diff.toc_summary(\n      allow_edge_languages: semantic_edge_languages_enabled? || params[:ds],\n      use_semiotic_on_kubes: semiotic_on_kubes_enabled?)\n\n    # If the darkship param is supplied, we immediately return and display no results.\n    return head :ok if params[:ds]\n\n    respond_to do |format|\n      format.html do\n        render partial: \"pull_requests/diffbar/toc_menu_items\",\n          layout: false,\n          locals: {\n            summary_delta_views: diff.summary.deltas.map { |d| Diff::SummaryDeltaView.new(d) },\n            toc_summary: summary\n          }\n      end\n    end\n  end\n\n  def cleanup\n    stats_key  = [\"pullrequest\",\n                  \"delete_button\",\n                  @pull.cross_repo? ? \"cross_repo\" : \"same_repo\"].join(\".\")\n\n    # The branch was deleted by someone else before this user\n    # clicked the button. Send us to the bottom.\n    if !@pull.head_ref_exist?\n      raise Git::Ref::NotFound\n    end\n\n    result = @pull.cleanup_head_ref(current_user,\n                              request_reflog_data(\"pull request branch delete button\"))\n\n    GitHub.stats.increment(\"#{stats_key}.#{result ? \"success\" : \"error\"}\")\n\n    if request.xhr?\n      render_head_ref_update\n    else\n      if result\n        flash[:notice] = \"Branch deleted successfully.\"\n      else\n        flash[:error] = \"Oops, something went wrong.\"\n      end\n\n      redirect_to pull_request_path(@pull)\n    end\n\n  # We can get here both from above where the branch has already\n  # been deleted before the button is clicked, or a race condition\n  # where the application code thinks the branch exists but by\n  # the time we execute the git command, someone else has already deleted it.\n  rescue Git::Ref::NotFound\n    GitHub.stats.increment(\"#{stats_key}.already_deleted\")\n    render_head_ref_update\n  end\n\n  def undo_cleanup\n    stats_key  = [\"pullrequest\",\n                  \"delete_button_undo\",\n                  @pull.cross_repo? ? \"cross_repo\" : \"same_repo\"].join(\".\")\n\n    if @pull.restore_head_ref(current_user,\n                              request_reflog_data(\"pull request branch undo button\"))\n      GitHub.stats.increment(\"#{stats_key}.success\")\n    else\n      GitHub.stats.increment(\"#{stats_key}.error\")\n    end\n\n    render_head_ref_update\n  end\n\n  def merge\n    @pull = current_repository.issues.find_by_number(params[:id].to_i).try(:pull_request)\n    return render_404 unless @pull\n\n    if params[:squash_commits] == \"1\"\n      merge_method = \"squash\"\n    elsif params[:do].present?\n      merge_method = params[:do]\n    else\n      if current_repository.merge_commit_allowed?\n        merge_method = \"merge\"\n      else\n        merge_method = \"squash\"\n      end\n    end\n\n    merge_method_allowed = case merge_method\n      when \"merge\"\n        current_repository.merge_commit_allowed?\n      when \"squash\"\n        current_repository.squash_merge_allowed?\n      when \"rebase\"\n        current_repository.rebase_merge_allowed?\n      else\n        false\n    end\n\n    if !merge_method_allowed\n      result, message = nil, \"The selected merge method (#{merge_method}) is not allowed.\"\n    elsif @pull.git_merges_cleanly? and @pull.base_repository.pushable_by?(current_user)\n      GitHub.stats.increment(\"pullrequest.merge_button.click\")\n      begin\n        result, message = @pull.merge(current_user,\n                                      message_title: params[:commit_title],\n                                      message: params[:commit_message],\n                                      reflog_data: request_reflog_data(\"pull request merge button\"),\n                                      expected_head: params[:head_sha],\n                                      method: merge_method.to_sym)\n      rescue Git::Ref::HookFailed => e\n        @hook_out = e.message\n        result, message = nil, \"Pre-receive hooks failed. See below for details.\"\n      end\n\n      if merge_method == \"rebase\"\n        @pull.base_repository.set_sticky_merge_method(current_user, \"rebase\")\n      elsif merge_method == \"squash\"\n        @pull.base_repository.set_sticky_merge_method(current_user, \"squash\")\n      elsif merge_method == \"merge\"\n        @pull.base_repository.set_sticky_merge_method(current_user, \"merge_commit\")\n      end\n    else\n      result, message = nil, \"We couldn’t merge this pull request. Reload the page before trying again.\"\n    end\n\n    if request.xhr?\n      if result\n        GitHub.dogstats.histogram(\"pull_request.merged.requested_reviewers.count\", @pull.review_requests.pending.size)\n        respond_to do |format|\n          format.json do\n            prepare_for_rendering(timeline: true, pull_comparison: nil)\n            render_immediate_partials @pull, :timeline_marker, :sidebar, :merging, :form_actions\n          end\n        end\n      else\n        GitHub.stats.increment(\"pullrequest.merge_button.error\")\n        respond_to do |format|\n          format.html do\n            render status: :unprocessable_entity, partial: \"pull_requests/merging_error\", locals: {\n              title: \"Merge attempt failed\",\n              message: (message || \"We couldn’t merge this pull request.\"),\n              hook_output: @hook_out\n            }\n          end\n        end\n        # render :plain => message, :status => :unprocessable_entity\n      end\n    else\n      if result\n        GitHub.dogstats.histogram(\"pull_request.merged.requested_reviewers.count\", @pull.review_requests.pending.size)\n        redirect_to pull_request_path(@pull) + \"#merged-event\"\n      else\n        flash[:error] = message\n        GitHub.stats.increment(\"pullrequest.merge_button.error\")\n        redirect_to pull_request_path(@pull)\n      end\n    end\n  end\n\n  def change_base\n    @pull = find_pull_request\n    return render_404 if !@pull || @pull.merged? ||\n      !@pull.issue.can_modify?(current_user) ||\n      !params[:new_base].present?\n\n    new_base = URI.decode(params[:new_base])\n    begin\n      @pull.change_base_branch(current_user, new_base)\n      flash[:notice] = \"Updated base branch to #{new_base}.\"\n    rescue PullRequest::BadComparison, PullRequest::AlreadyExists => e\n      flash[:error] = e.ui_message\n    end\n    redirect_to pull_request_path(@pull)\n  end\n\n  def update_branch\n    @pull = find_pull_request\n    return render_404 unless @pull\n\n    begin\n      @pull.merge_base_into_head({\n        user: current_user,\n        expected_head_oid: params[:expected_head_oid]\n      })\n\n      if request.xhr?\n        respond_to do |format|\n          format.json do\n            prepare_for_rendering(timeline: true, pull_comparison: nil)\n            render_immediate_partials(@pull, :timeline_marker, :merging)\n          end\n        end\n      else\n        redirect_to pull_request_path(@pull) + \"#partial-pull-merging\"\n      end\n    rescue GitHub::UIError => e\n      if request.xhr?\n        respond_to do |format|\n          format.html do\n            render status: :unprocessable_entity, partial: \"pull_requests/merging_error\", locals: {\n              title: \"Update branch attempt failed\",\n              message: e.ui_message\n            }\n          end\n        end\n      else\n        flash[:error] = e.ui_message\n        redirect_to pull_request_path(@pull) + \"#partial-pull-merging\"\n      end\n    end\n  end\n\n  def revert\n    @pull = find_pull_request\n    return render_404 unless @pull && @pull.revertable_by?(current_user)\n\n    stats_key = [\"pullrequest\",\n                 \"revert_button\",\n                 @pull.cross_repo? ? \"cross_repo\" : \"same_repo\"].join(\".\")\n\n    begin\n      revert_branch, error = @pull.revert(current_user, request_reflog_data(\"pull request revert button\"), timeout: (request_time_left / 3))\n      if revert_branch\n        GitHub.stats.increment(\"#{stats_key}.success\")\n\n        base_label, head_label =\n          if revert_branch.repository == @pull.base_repository\n            [@pull.base_ref_name, revert_branch.name]\n          else\n            [\"#{@pull.base_label(username_qualified: true)}\", \"#{revert_branch.repository.owner.login}:#{revert_branch.name}\"]\n          end\n\n        flash[:pull_request] = {\n          title: \"Revert \\\"#{@pull.title}\\\"\",\n          body: \"Reverts #{@pull.base_repository.name_with_owner}##{@pull.number}\"\n        }\n        redirect_to(compare_path(@pull.base_repository, \"#{base_label}...#{head_label}\", true))\n      else\n        if error == :merge_conflict\n          GitHub.stats.increment(\"#{stats_key}.merge_conflict\")\n        else\n          GitHub.stats.increment(\"#{stats_key}.error\")\n        end\n\n        flash[:error] = \"Sorry, this pull request couldn’t be reverted automatically. It may have \\\n                         already been reverted, or the content may have changed since it was merged.\"\n        redirect_to pull_request_path(@pull)\n      end\n    rescue Git::Ref::HookFailed => e\n      flash[:hook_out] = e.message\n      flash[:hook_message] = \"Pull request could not be reverted.\"\n      redirect_to pull_request_path(@pull)\n    end\n  end\n\n  def merge_button\n    pull = current_repository.issues.find_by_number(params[:id].to_i).try(:pull_request)\n    return render_404 if pull.nil?\n    merge_state = pull.cached_merge_state(viewer: current_user)\n\n    respond_to do |format|\n      format.html do\n        if merge_state.unknown?\n          head :accepted\n        else\n          render partial: \"pull_requests/merge_button\", locals: { pull: pull }\n        end\n      end\n\n      format.json do\n        render json: {mergeable_state: merge_state.status}.to_json\n      end\n    end\n  end\n\n  def diff\n    # This might be a request for a redirect to the PR for a branch name ending in .diff,\n    # or might be a request for a numbered PR in .diff format.\n    diff_ref = \"#{params[:id]}.diff\"\n    if current_repository.heads.include?(diff_ref)\n      return redirect_or_404(diff_ref)\n    end\n\n    redirect_or_error = ensure_valid_pull_request\n    if performed?\n      return redirect_or_error\n    else\n      redirect_to build_pull_request_diff_url\n    end\n  end\n\n  def patch\n    # This might be a request for a redirect to the PR for a branch name ending in .patch,\n    # or might be a request for a numbered PR in .patch format.\n    patch_ref = \"#{params[:id]}.patch\"\n    if current_repository.heads.include?(patch_ref)\n      return redirect_or_404(patch_ref)\n    end\n\n    redirect_or_error = ensure_valid_pull_request\n    if performed?\n      return redirect_or_error\n    else\n      redirect_to build_pull_request_patch_url\n    end\n  end\n\n  def comment\n    return if reject_bully?\n\n    @pull = current_repository.issues.find_by_number(params[:id].to_i).try(:pull_request)\n    return render_404 unless @pull\n    issue = @pull.issue\n\n    valid = true\n    comment_body = params[:comment][:body]\n\n    if !comment_body.nil? && !can_skip_creating_comment?\n      comment = issue.create_comment(current_user, comment_body)\n      valid &&= comment.persisted?\n\n    elsif params[:comment_and_close] == \"1\"\n      comment = issue.comment_and_close(current_user, comment_body)\n      valid &= comment if comment_body.present?\n\n      GitHub.dogstats.histogram(\"pull_request.closed.requested_reviewers.count\", @pull.review_requests.pending.size)\n\n    elsif params[:comment_and_open] == \"1\"\n      comment = issue.comment_and_open(current_user, comment_body)\n      valid &= comment if comment_body.present?\n    end\n\n    mark_thread_as_read issue\n    if valid && comment_body.present?\n      GitHub.instrument \"comment.create\", user: current_user\n      instrument_saved_reply_use(params[:saved_reply_id], \"pull_request_comment\")\n    end\n\n    respond_to do |format|\n      format.json do\n        if valid\n          prepare_for_rendering(timeline: true, pull_comparison: nil)\n          render_immediate_partials @pull, :timeline_marker, :sidebar, :merging, :form_actions, :title\n        else\n          errors = comment.errors.map { |attr, msg| msg }\n          render json: { errors: errors }, status: :unprocessable_entity\n        end\n      end\n      format.html do\n        if valid\n          anchor = comment ? \"#issuecomment-#{comment.id}\" : \"\"\n          redirect_to pull_request_path(@pull) + anchor\n        else\n          flash[:error] = comment.errors.full_messages.to_sentence\n          redirect_to :back\n        end\n      end\n    end\n  end\n\n  def dismiss_protip\n    current_user.dismiss_notice(\"continuous_integration_tip\")\n\n    head :ok\n  end\n\n  if Rails.env.development?\n    def merge_button_matrix\n      if mobile?\n        render \"pull_requests/merge_button_matrix_mobile\", layout: \"mobile/application\"\n      else\n        render \"pull_requests/merge_button_matrix\", layout: \"mobile/application\"\n      end\n    end\n  end\n\n  def set_collab\n    pull = current_repository.issues.find_by_number(params[:id].to_i).try(:pull_request)\n\n    return render_404 if !pull || !pull.head_repository.repository.pushable_by?(current_user)\n\n    if !!params[:collab_privs]\n      pull.fork_collab = :allowed\n    else\n      pull.fork_collab = :denied\n    end\n\n    pull.save!\n\n    redirect_to pull_request_path(pull)\n  end\n\n  def resolve_conflicts\n    redirect_or_error = ensure_valid_pull_request\n\n    unless logged_in? && @pull.head_repository && @pull.head_repository.pushable_by?(current_user, ref: @pull.head_ref_name)\n      return render_404\n    end\n    return redirect_to pull_request_path(@pull) unless @pull.conflict_resolvable? && conflict_editor_enabled?(@pull)\n\n    if performed?\n      return redirect_or_error\n    end\n\n    render \"pull_requests/resolve_conflicts\", locals: { pull: @pull }\n  end\n\nprotected\n\n  helper_method :tab_specified?\n  def tab_specified?(tab_name)\n    specified_tab.to_s == tab_name.to_s\n  end\n\n  helper_method :pull_request_subscribe_enabled?\n  def pull_request_subscribe_enabled?\n    Rails.development? || Rails.test? || preview_features?\n  end\n\n  def specified_tab\n    @specified_tab || params[:tab].presence || \"discussion\"\n  end\n  helper_method :specified_tab\n\n  def valid_tab?\n    params[:tab].blank? || %w{commits files tasks}.include?(params[:tab])\n  end\n\n  def reject_bully_for?(repo)\n    if blocked_by_owner?(repo.owner_id)\n      flash[:error] = \"You can't perform that action at this time.\"\n      redirect_to repo.permalink\n      true\n    end\n  end\n\n  def reject_bully?\n    reject_bully_for? current_repository\n  end\n\n  def tree_name\n    if @pull && @pull.open?\n      @pull.head_ref_name\n    elsif @pull\n      @pull.head_sha\n    else\n      super\n    end\n  end\n\n  private\n\n  def find_pull_request\n    PullRequest.find_by_number_and_repo(params[:id].to_i, current_repository, include: [{ issue: :comments }])\n  end\n\n  # Private: For a given ref name, redirect to the appropriate pull request\n  # path if one exists, or 404 otherwise.\n  #\n  # Returns the redirect or render_404 result.\n  def redirect_or_404(ref)\n    # redirect to number version if ref is a branch name,\n    # redirect to new if ref is a branch with no pull request\n    # 404 otherwise\n    if pull = current_repository.pull_requests.for_branch(ref).last\n      redirect_to pull_request_path(pull)\n    elsif ref =~ /[:.]/ || current_repository.heads.include?(ref)\n      redirect_to new_pull_request_path(range: ref)\n    else\n      render_404\n    end\n  end\n\n  # Private: Validate the requested pull request ID. If necessary redirect to\n  # a more appropriate URL or return a 404 if the PR isn't/shouldn't be\n  # available.\n  def ensure_valid_pull_request\n    if params[:id] =~ /\\D/\n      return redirect_or_404(params[:id])\n    end\n\n    @pull = find_pull_request\n\n    return redirect_to(issue_path(id: params[:id])) unless @pull\n    return redirect_to(pull_request_path @pull) unless valid_tab?\n\n    return render_404 if @pull.hide_from_user?(current_user)\n\n    @prose_url_hints = { tab: \"files\" }\n\n    @pull.set_diff_options(\n      use_summary: true,\n      ignore_whitespace: ignore_whitespace?\n    )\n  end\n\n  def conflict_editor_enabled?(pull)\n    return true unless pull.cross_repo?\n\n    GitHub.cross_repo_conflict_editor_enabled?\n  end\n\n  # Validates the provided parameter is a valid sha, or nil\n  def valid_sha_param?(param_name)\n    param = params[param_name]\n    param.nil? || param =~ /[0-9a-f]{40}/\n  end\n\n  def load_diff\n    @pull_comparison.ignore_whitespace = ignore_whitespace?\n    @pull_comparison.diff_options[:use_summary] = true\n\n    # load diff data\n    if !show_mobile_view?\n      @pull_comparison.diff_options[:top_only] = true\n\n      GitHub.dogstats.time(\"diff.load.initial\", tags: dogstats_request_tags) do\n        @pull_comparison.diffs.apply_auto_load_single_entry_limits!\n        @pull_comparison.diffs.load_diff(timeout: request_time_left / 2)\n      end\n    else\n      @pull_comparison.diffs.load_diff(timeout: request_time_left / 2)\n    end\n  end\n\n  # Preload data needed for rendering the PR.\n  #\n  # timeline - Boolean specifying whether the PR's timeline will be rendered.\n  # pull_comparison - PullRequest::Comparison specifying whether the PR's diff will be rendered.\n  #\n  # Returns nothing.\n  def prepare_for_rendering(timeline:, pull_comparison:)\n    prepare_for_rendering_timeline_items(timeline: timeline, pull_comparison: pull_comparison)\n    prepare_for_rendering_diffs(timeline: timeline, pull_comparison: pull_comparison)\n  end\n\n  # Preload data needed for rendering timeline items.\n  #\n  # timeline - Boolean specifying whether the PR's timeline will be rendered.\n  # pull_comparison - PullRequest::Comparison specifying whether the PR's diff\n  #   (which contains timeline items corresponding to live review threads) will be rendered.\n  #\n  # Returns nothing.\n  def prepare_for_rendering_timeline_items(timeline:, pull_comparison:)\n    timeline_items = visible_timeline_items\n    if pull_comparison\n      # Add in the review threads that are shown on the Files changed tab.\n      # Note that some of these might be also be shown on the Discussion tab,\n      # but the AR objects will actually be distinct so it's still worth\n      # prefilling/warming both objects.\n      timeline_items = timeline_items.dup\n      threads = pull_comparison.review_threads(viewer: current_user)\n      timeline_items.concat(threads.to_a)\n    end\n\n    @pull.prefill_timeline_associations(timeline_items,\n      preload_diff_entries: timeline, show_mobile_view: show_mobile_view?)\n\n    preload_discussion_group_data(timeline_items)\n  end\n\n  # Preload data needed for rendering diffs.\n  #\n  # timeline - Boolean specifying whether the PR's timeline (which contains\n  #            diffs for review threads) will be rendered.\n  # pull_comparison - PullRequest::Comparison specifying whether the PR's diff will be rendered.\n  #\n  # Returns nothing.\n  def prepare_for_rendering_diffs(timeline:, pull_comparison:)\n    return unless syntax_highlighted_diffs_enabled?\n\n    diffs_to_highlight = []\n    if timeline\n      visible_timeline_items.each do |item|\n        next unless item.is_a?(PullRequestReviewThread)\n        next unless item.diff_entry\n        diffs_to_highlight << item.diff_entry\n      end\n    end\n    if pull_comparison\n      diffs_to_highlight.concat(pull_comparison.diffs.to_a)\n    end\n    SyntaxHighlightedDiff.new(@pull.comparison.compare_repository, current_user).highlight!(diffs_to_highlight, attributes_commit_oid: @pull.head_sha)\n  end\n\n  def can_skip_creating_comment?\n    params[:comment_and_close].present? ||\n      params[:comment_and_open].present?\n  end\n\n  # If it's empty, you can't issue a pull request.  There will be no\n  # base SHA to merge against.\n  def check_for_empty_repository\n    if current_repository.empty?\n      redirect_to current_repository\n    end\n  end\n\n  def ensure_pull_head_pushable\n    @pull = current_repository.issues.find_by_number(params[:id].to_i).try(:pull_request)\n\n    if @pull.nil? || !@pull.head_repository.pushable_by?(current_user)\n      render_404\n    end\n  end\n\n  # Reload the pull so the deletable/restorable status is current,\n  # then render updates for the event list and the merge/delete buttons.\n  def render_head_ref_update\n    @pull.reload\n    respond_to do |format|\n      format.json do\n        prepare_for_rendering(timeline: true, pull_comparison: nil)\n        render_immediate_partials(@pull, :timeline_marker, :merging, :form_actions)\n      end\n    end\n  end\n\n  # Internal: Provide a better failure message than simply taking the validation errors\n  #\n  # e - the ActiveRecord::RecordInvalid exception from the creation failure\n  #\n  # Returns a String\n  def human_failure_message(e)\n    pr = e.record\n\n    # e.record can be an Issue, raised in PullRequest.create_for.\n    return e.message unless pr.is_a?(PullRequest)\n\n    if bad_branches = pr.missing_refs\n      if bad_branches.length == 1\n        \"The #{bad_branches.first} branch doesn’t exist.\"\n      else\n        \"The #{bad_branches.join(' and ')} branches don’t exist.\"\n      end\n    elsif [:base_ref, :head_ref].any? { |attr| pr.errors[attr].include?(GitHub::Validations::Unicode3Validator::ERROR_MESSAGE) }\n      \"Branch names cannot contain unicode characters above 0xffff.\"\n    else\n      e.message\n    end\n  end\n\n  # If there are this many timeline items or fewer, we'll render the timeline\n  # inline when the user is viewing the Files tab. If there are more than this\n  # many items, we'll leave the timeline out and load it as needed to try to\n  # avoid timing out.\n  MAXIMUM_TIMELINE_SIZE_FOR_INLINE_RENDER = 149\n\n  def render_discussion_page?\n    return @render_discussion_page if defined?(@render_discussion_page)\n    @render_discussion_page =\n      tab_specified?(\"discussion\") || (!show_mobile_view? && @pull.timeline_children_for(current_user).count <= MAXIMUM_TIMELINE_SIZE_FOR_INLINE_RENDER)\n  end\n  helper_method :render_discussion_page?\n\n  def render_files_page?\n    return @render_files_page if defined?(@render_files_page)\n    @render_files_page = tab_specified?(\"files\") || (!show_mobile_view? && !@pull.corrupt? && !@pull.large_diff?)\n  end\n  helper_method :render_files_page?\n\n  def pull_request_authorization_token\n    current_user.signed_auth_token expires: 60.seconds.from_now,\n                                   scope: pull_request_authorization_token_scope_key\n  end\n\n  def build_pull_request_diff_url\n    route_options ||= {}\n\n    if GitHub.prs_content_domain?\n      route_options[:host] = GitHub.prs_content_host_name\n    end\n\n    if current_repository.private?\n      route_options[:token] = pull_request_authorization_token\n    end\n\n    route_options[:full_index] = params[:full_index]\n\n    pull_request_raw_diff_url(route_options)\n  end\n\n  def build_pull_request_patch_url\n    route_options ||= {}\n\n    if GitHub.prs_content_domain?\n      route_options[:host] = GitHub.prs_content_host_name\n    end\n\n    if current_repository.private?\n      route_options[:token] = pull_request_authorization_token\n    end\n\n    route_options[:full_index] = params[:full_index]\n\n    pull_request_raw_patch_url(route_options)\n  end\n\n  def request_reflog_data(via)\n    super(via).merge({ pr_author_login: @pull.safe_user.login })\n  end\n\n  def content_authorization_required\n    authorize_content(:pull_request, repo: current_repository)\n  end\n\n  # Internal: Extract OID components from PR range.\n  #\n  #   /github/github/pull/123/files/abc123..def456\n  #   /github/github/pull/123/files/def456\n  #\n  # pull  - Current PullRequest\n  # range - String range parameter\n  #\n  # If a complete range is given, a pair of resolved String OIDs will be\n  # returned. If only one end sha is given, nil and a resolved String OID\n  # will be returned. Otherwise nil is returned if no range was matched.\n  def parse_show_range_oid_components(pull, range)\n    if m = range.to_s.match(/\\A(?<sha1>[a-fA-F0-9]{7,40})\\.\\.(?<sha2>[a-fA-F0-9]{7,40}|HEAD)\\z/)\n      sha2 = m[:sha2] == \"HEAD\" ? pull.head_sha : m[:sha2]\n      result = pull.repository.rpc.expand_shas([m[:sha1], sha2], \"commit\")\n      sha1, sha2 = result[m[:sha1]], result[sha2]\n      [sha1, sha2] if sha1 && sha2\n    elsif m = range.to_s.match(/^(?<sha2>[a-fA-F0-9]{7,40})$/)\n      result = pull.repository.rpc.expand_shas([m[:sha2]], \"commit\")\n      sha2 = result[m[:sha2]]\n      return [nil, sha2] if sha2\n    end\n  end\n\n  def visible_timeline_items\n    return [] unless render_discussion_page?\n    super\n  end\n\n  def showing_full_timeline?\n    return false unless render_discussion_page?\n    super\n  end\n\n  def timeline_owner\n    @pull\n  end\n\n  MobileCommitsQuery = parse_query <<-'GRAPHQL'\n    query($ids: [ID!]!) {\n      nodes(ids: $ids) {\n        ...Views::Mobile::PullRequests::CommitList::Commit\n      }\n    }\n  GRAPHQL\n\n  # XXX: Adhoc GraphQL loader for PullRequest.changedChanges connection.\n  #\n  # Load required GraphQL data for each Commit in PullRequest#changed_commits and\n  # wrap it in a fake connection to be compatible with mobile/commits/list template.\n  def load_mobile_pull_request_commits\n    commits = @pull.changed_commits\n\n    # we need to \"fudge\" the repository for these commits as the head repository could disappear\n    # but we should always have these commits in the base. This shouldn't be necessary when this\n    # query is updated to use proper PullRequestCommit objects instead.\n    ids = commits.map do |c|\n      c.repository = @pull.base_repository\n      c.global_relay_id\n    end\n    data = platform_execute(MobileCommitsQuery, variables: { \"ids\" => ids })\n    data.nodes\n  end\n  helper_method :load_mobile_pull_request_commits\nend\n","language":"Ruby"},"before":{"path":"app/controllers/pull_requests_controller.rb","content":"# frozen_string_literal: true\n\nclass PullRequestsController < AbstractRepositoryController\n  areas_of_responsibility :code_collab, :pull_requests\n\n  include ShowPartial, PrefetchHelper, ProgressiveTimeline, DiscussionPreloadHelper,\n    ControllerMethods::Diffs, MarketplaceHelper\n\n  helper :compare\n  before_filter :login_required, only: [:create, :comment, :merge_button, :sync, :dismiss_protip]\n  before_filter :login_required_redirect_for_public_repo, only: [:new]\n  before_filter :writable_repository_required,\n    except: [:new, :show, :show_partial, :merge_button, :diff, :patch, :merge_button_matrix]\n  before_filter :check_for_empty_repository, only: [:create, :new]\n  before_filter :ensure_pull_head_pushable, only: [:cleanup, :undo_cleanup, :sync]\n  before_filter :content_authorization_required, only: [:create, :merge]\n  skip_before_filter :cap_pagination, unless: :robot?\n\n  layout :repository_layout\n\n  param_encoding :create, :base, \"ASCII-8BIT\"\n  param_encoding :create, :head, \"ASCII-8BIT\"\n  param_encoding :new, :range, \"ASCII-8BIT\"\n\n  def new\n    redirect_to compare_path(current_repository, params[:range], true)\n  end\n\n  def create\n    repo = current_repository\n    return render_404 unless repo\n    return if reject_bully_for?(repo)\n\n    params[:pull_request] ||= {}\n    options = params.slice(:base, :head)\n    options[:user] = current_user\n\n    params[:issue] ||= {}\n    params[:issue][:title] = params[:pull_request][:title]\n    params[:issue][:body]  = params[:pull_request][:body]\n    options[:issue] = build_issue\n    options[:collab_privs] = !!params[:collab_privs]\n    options[:reviewer_user_ids] = params[:reviewer_user_ids]\n    options[:reviewer_team_ids] = params[:reviewer_team_ids]\n\n    begin\n      @pull_request = PullRequest.create_for!(repo, options)\n      @comparison   = @pull_request.comparison\n      @issue        = @pull_request.issue\n\n      GitHub.instrument \"pull_request.create\", user: current_user\n      instrument_issue_creation_via_ui(@pull_request)\n      instrument_saved_reply_use(params[:saved_reply_id], \"pull_request\")\n      # Keep track of if a pull request targets the repo's\n      # default branch, or one in progress.\n      if options[:base].strip == \"#{repo.owner}:#{repo.default_branch}\"\n        GitHub.stats.increment(\"pullrequest.target.default\")\n      else\n        GitHub.stats.increment(\"pullrequest.target.other\")\n      end\n\n      if params[:quick_pull].present?\n        type = @pull_request.cross_repo? ? \"cross\" : \"same\"\n        GitHub.stats.increment(\"pullrequest.quick.total.create\")\n        GitHub.stats.increment(\"pullrequest.quick.#{type}.create\")\n      end\n\n      redirect_to pull_request_path(@pull_request, repo)\n    rescue ActiveRecord::RecordInvalid => e\n      flash[:error] = \"Pull request creation failed. #{human_failure_message(e)}\"\n      range = [options[:base], options[:head]].compact.join(\"...\")\n      redirect_to compare_path(repo, range, true)\n    end\n  end\n\n  ShowCommitsQuery = parse_query <<-'GRAPHQL'\n    query($id: ID!) {\n      pull: node(id: $id) {\n        ...Views::PullRequests::Commits::PullRequest\n      }\n    }\n  GRAPHQL\n\n  def show\n    @mobile_view_available = true\n\n    redirect_or_error = ensure_valid_pull_request\n\n    if performed?\n      return redirect_or_error\n    end\n\n    if params[:range]\n      env[\"pull_request.timeout_reason\"] = \"compute_diff\"\n\n      if oids = parse_show_range_oid_components(@pull, params[:range])\n        oid1, oid2 = oids\n      else\n        return render \"pull_requests/bad_range\", status: :not_found\n      end\n\n      allowed_commits = @pull.changed_commit_oids\n      if !(oid1.nil? || allowed_commits.include?(oid1)) || !allowed_commits.include?(oid2)\n        return render \"pull_requests/bad_range\", status: :not_found\n      end\n\n      if oid1 && (oid1 == oid2 || !@pull.repository.rpc.descendant_of([[oid2, oid1]]).values.first)\n        return render \"pull_requests/bad_range\", status: :not_found\n      end\n\n      expected_canonical_range = oid1 ? \"#{oid1}..#{oid2}\" : \"#{oid2}\"\n      if params[:range] != expected_canonical_range\n        return redirect_to(range: expected_canonical_range)\n      end\n\n      if params[:tab] == \"commits\"\n        @specified_tab = \"files\"\n        oid1 = current_repository.commits.find(oid2).parent_oids.first\n      end\n\n      @comparison = @pull.historical_comparison\n      merge_base_oid = @comparison.compare_repository.best_merge_base(@pull.base_sha, oid2)\n\n      if merge_base_oid.nil?\n        return render \"pull_requests/orphan_commit\", status: :not_found, locals: { oid2: oid2 }\n      end\n\n      oid1 ||= @pull.compare_repository.best_merge_base(oid2, merge_base_oid) if merge_base_oid\n      unless @pull_comparison = PullRequest::Comparison.find(pull: @pull, start_commit_oid: oid1, end_commit_oid: oid2, base_commit_oid: merge_base_oid)\n        return render \"pull_requests/bad_range\", status: :not_found\n      end\n\n      load_diff\n\n      env[\"pull_request.timeout_reason\"] = nil\n    else\n      @comparison = @pull.comparison\n\n      if specified_tab == \"files\"\n        env[\"pull_request.timeout_reason\"] = \"compute_diff\"\n\n        start_oid, end_oid = @pull.merge_base, @pull.head_sha\n        if start_oid && end_oid\n          begin\n            start_commit, end_commit = @pull.compare_repository.commits.find([start_oid, end_oid])\n            @pull_comparison = PullRequest::Comparison.new(pull: @pull, start_commit: start_commit, end_commit: end_commit, base_commit: start_commit)\n\n            load_diff\n          rescue GitRPC::ObjectMissing\n          end\n        end\n\n        env[\"pull_request.timeout_reason\"] = nil\n      end\n    end\n\n    prefetch_deferred do\n      if specified_tab == \"files\" && @pull_comparison && logged_in?\n        @pull_comparison.mark_as_seen(user: current_user)\n        mark_thread_as_read @pull.issue\n      elsif specified_tab == \"discussion\"\n        mark_thread_as_read @pull.issue\n      end\n    end\n\n    if prefetch_viewed?\n      return head(:no_content)\n    end\n\n    @labels = current_repository.sorted_labels\n\n    prepare_for_rendering(timeline: specified_tab == \"discussion\", pull_comparison: @pull_comparison)\n\n    unless \"discussion\" == specified_tab\n      override_analytics_location \"/<user-name>/<repo-name>/pull_requests/show/#{specified_tab}\"\n    end\n\n    # Enroll the user in an A/A expriment to test Frequency. Can be removed after experiment verification is concluded.\n    if \"discussion\" == specified_tab && show_marketplace_ci_cta?(current_repository)\n      GitHub::UserResearch.experiment_variant(\n        experiment: UserExperimentCohort::MARKETPLACECICTA,\n        subject: current_user\n      )\n    end\n\n    respond_to do |format|\n      format.html do\n        if show_mobile_view? && (request_category != \"raw\")\n          return render_template_view(\"mobile/pull_requests/show\", Mobile::PullRequests::ShowPageView, {\n            pull: @pull,\n            diffs: @pull_comparison.try(:diffs),\n            tab: specified_tab,\n            visible_timeline_items: visible_timeline_items,\n            showing_full_timeline: showing_full_timeline?\n          }, layout: \"mobile/application\")\n        end\n\n        if params[:shdds]\n          @syntax_highlighted_diffs_forced = true\n          render_to_string\n          head :no_content\n        else\n          if logged_in?\n            @current_review = @pull.latest_pending_review_for(current_user)\n          end\n\n          if specified_tab == \"files\"\n            if @pull_comparison.nil?\n              render \"pull_requests/files_unavailable\"\n            else\n              render \"pull_requests/files\"\n            end\n          elsif specified_tab == \"commits\"\n            data = platform_execute(ShowCommitsQuery, variables: { id: @pull.global_relay_id })\n            render \"pull_requests/commits\", locals: { pull_node: data.pull }\n          else\n            render \"pull_requests/conversation\"\n          end\n        end\n      end\n      if params[:tab] == \"commits\"\n        format.diff { commit_diff(oid2) }\n        format.patch { commit_patch(oid2) }\n      end\n    end\n  end\n\n  def commit_diff(oid)\n    redirect_to commit_path(oid, current_repository) + \".diff\"\n  end\n\n  def commit_patch(oid)\n    redirect_to commit_path(oid, current_repository) + \".patch\"\n  end\n\n  TIMELINE_PARTIALS = %w[\n    pull_requests/timeline\n    pull_requests/timeline_marker\n  ].freeze\n\n  VALID_REASONS = %w[\n    view-more-button\n    expose-fragment\n  ].freeze\n\n  ShowPartialCommitsPartialQuery = parse_query <<-'GRAPHQL'\n    query($id: ID!) {\n      pull: node(id: $id) {\n        ...Views::PullRequests::CommitsPartial::PullRequest\n      }\n    }\n  GRAPHQL\n\n  def show_partial\n    partial = params[:partial]\n    return head :not_found unless valid_partial?(partial)\n\n    GitHub.stats.time(\"pullrequest.show_partial_find\") do\n      @pull = PullRequest.find_by_number_and_repo(params[:id].to_i, current_repository)\n    end\n\n    return head :not_found unless @pull\n\n    if partial == \"pull_requests/timeline\"\n      if focused_timeline? && visible_timeline_items.empty?\n        return head :bad_request\n      end\n\n      reason = VALID_REASONS.include?(params[:reason]) ? params[:reason] : \"other\"\n      GitHub.stats.increment(\"pullrequest.show_partial.timeline.#{reason}.count\")\n    end\n\n    prepare_for_rendering(timeline: TIMELINE_PARTIALS.include?(partial), pull_comparison: nil)\n\n    if partial == \"pull_requests/commits_partial\"\n      pull_node = platform_execute(ShowPartialCommitsPartialQuery, variables: { id: @pull.global_relay_id }).pull\n    end\n\n    GitHub.stats.time(\"pullrequest.show_partial_render\") do\n      respond_to do |format|\n        format.html do\n          render partial: partial, object: @pull, layout: false, locals: { # rubocop:disable GitHub/RailsControllerRenderLiteral\n            pull: @pull,\n            pull_request: pull_node,\n            merge_type: params[:merge_type]\n          }\n        end\n      end\n    end\n  end\n\n  ShowPartialCommitQuery = parse_query <<-'GRAPHQL'\n    query($id: ID!) {\n      node(id: $id) {\n        ...Views::Commits::PullCommitsListItem::PullRequestCommit\n        ...Views::Commit::PullCondensed::PullRequestCommit\n      }\n    }\n  GRAPHQL\n\n  # TODO Remove this endpoint and use NodesController once everything\n  # in the view templates moved to GraphQL.\n  def show_partial_commit\n    partial = params[:partial]\n    return head :not_found unless valid_partial?(partial)\n\n    unless pull = PullRequest.find_by_number_and_repo(params[:id].to_i, current_repository)\n      return head :not_found\n    end\n\n    unless commit = current_commit\n      return head :not_found\n    end\n\n    pull_request_commit = Platform::Models::PullRequestCommit.new(pull, current_commit)\n    data = platform_execute(ShowPartialCommitQuery, variables: { id: pull_request_commit.global_relay_id })\n\n    # TODO Remove once we transitioned `commits/pull_commits_list_item` to GraphQL\n    Commit.prefill_combined_statuses([current_commit], current_repository)\n\n    GitHub.stats.time(\"pullrequest.show_partial_render\") do\n      respond_to do |format|\n        format.html do\n          render partial: partial, object: commit, layout: false, locals: { pull: pull, commit: commit, pull_request_commit: data.node } # rubocop:disable GitHub/RailsControllerRenderLiteral\n        end\n      end\n    end\n  end\n\n  def show_partial_comparison\n    partial = params[:partial]\n    return head :not_found unless valid_partial?(partial)\n\n    unless pull = PullRequest.find_by_number_and_repo(params[:id].to_i, current_repository)\n      return head :not_found\n    end\n\n    unless pull_comparison = PullRequest::Comparison.find(pull: pull, start_commit_oid: params[:start_commit_oid], end_commit_oid: params[:end_commit_oid], base_commit_oid: params[:base_commit_oid])\n      return head :not_found\n    end\n\n    GitHub.stats.time(\"pullrequest.show_partial_render\") do\n      respond_to do |format|\n        format.html do\n          render partial: partial, locals: { pull: pull, pull_comparison: pull_comparison } # rubocop:disable GitHub/RailsControllerRenderLiteral\n        end\n      end\n    end\n  end\n\n  def show_toc\n    pull = PullRequest.find_by_number_and_repo(params[:id], current_repository)\n    return head :not_found unless pull\n\n    return head :not_found unless valid_sha_param?(:sha1) &&\n                                  valid_sha_param?(:sha2) && params[:sha2].present? &&\n                                  valid_sha_param?(:base_sha)\n\n    diff_options = { base_sha: params[:base_sha] }\n    diff = GitHub::Diff.new(pull.compare_repository, params[:sha1], params[:sha2], diff_options)\n\n    summary = diff.toc_summary(allow_edge_languages: semantic_edge_languages_enabled? || params[:ds])\n    # If the darkship param is supplied, we immediately return and display no results.\n    return head :ok if params[:ds]\n\n    respond_to do |format|\n      format.html do\n        render partial: \"pull_requests/diffbar/toc_menu_items\",\n          layout: false,\n          locals: {\n            summary_delta_views: diff.summary.deltas.map { |d| Diff::SummaryDeltaView.new(d) },\n            toc_summary: summary\n          }\n      end\n    end\n  end\n\n  def cleanup\n    stats_key  = [\"pullrequest\",\n                  \"delete_button\",\n                  @pull.cross_repo? ? \"cross_repo\" : \"same_repo\"].join(\".\")\n\n    # The branch was deleted by someone else before this user\n    # clicked the button. Send us to the bottom.\n    if !@pull.head_ref_exist?\n      raise Git::Ref::NotFound\n    end\n\n    result = @pull.cleanup_head_ref(current_user,\n                              request_reflog_data(\"pull request branch delete button\"))\n\n    GitHub.stats.increment(\"#{stats_key}.#{result ? \"success\" : \"error\"}\")\n\n    if request.xhr?\n      render_head_ref_update\n    else\n      if result\n        flash[:notice] = \"Branch deleted successfully.\"\n      else\n        flash[:error] = \"Oops, something went wrong.\"\n      end\n\n      redirect_to pull_request_path(@pull)\n    end\n\n  # We can get here both from above where the branch has already\n  # been deleted before the button is clicked, or a race condition\n  # where the application code thinks the branch exists but by\n  # the time we execute the git command, someone else has already deleted it.\n  rescue Git::Ref::NotFound\n    GitHub.stats.increment(\"#{stats_key}.already_deleted\")\n    render_head_ref_update\n  end\n\n  def undo_cleanup\n    stats_key  = [\"pullrequest\",\n                  \"delete_button_undo\",\n                  @pull.cross_repo? ? \"cross_repo\" : \"same_repo\"].join(\".\")\n\n    if @pull.restore_head_ref(current_user,\n                              request_reflog_data(\"pull request branch undo button\"))\n      GitHub.stats.increment(\"#{stats_key}.success\")\n    else\n      GitHub.stats.increment(\"#{stats_key}.error\")\n    end\n\n    render_head_ref_update\n  end\n\n  def merge\n    @pull = current_repository.issues.find_by_number(params[:id].to_i).try(:pull_request)\n    return render_404 unless @pull\n\n    if params[:squash_commits] == \"1\"\n      merge_method = \"squash\"\n    elsif params[:do].present?\n      merge_method = params[:do]\n    else\n      if current_repository.merge_commit_allowed?\n        merge_method = \"merge\"\n      else\n        merge_method = \"squash\"\n      end\n    end\n\n    merge_method_allowed = case merge_method\n      when \"merge\"\n        current_repository.merge_commit_allowed?\n      when \"squash\"\n        current_repository.squash_merge_allowed?\n      when \"rebase\"\n        current_repository.rebase_merge_allowed?\n      else\n        false\n    end\n\n    if !merge_method_allowed\n      result, message = nil, \"The selected merge method (#{merge_method}) is not allowed.\"\n    elsif @pull.git_merges_cleanly? and @pull.base_repository.pushable_by?(current_user)\n      GitHub.stats.increment(\"pullrequest.merge_button.click\")\n      begin\n        result, message = @pull.merge(current_user,\n                                      message_title: params[:commit_title],\n                                      message: params[:commit_message],\n                                      reflog_data: request_reflog_data(\"pull request merge button\"),\n                                      expected_head: params[:head_sha],\n                                      method: merge_method.to_sym)\n      rescue Git::Ref::HookFailed => e\n        @hook_out = e.message\n        result, message = nil, \"Pre-receive hooks failed. See below for details.\"\n      end\n\n      if merge_method == \"rebase\"\n        @pull.base_repository.set_sticky_merge_method(current_user, \"rebase\")\n      elsif merge_method == \"squash\"\n        @pull.base_repository.set_sticky_merge_method(current_user, \"squash\")\n      elsif merge_method == \"merge\"\n        @pull.base_repository.set_sticky_merge_method(current_user, \"merge_commit\")\n      end\n    else\n      result, message = nil, \"We couldn’t merge this pull request. Reload the page before trying again.\"\n    end\n\n    if request.xhr?\n      if result\n        GitHub.dogstats.histogram(\"pull_request.merged.requested_reviewers.count\", @pull.review_requests.pending.size)\n        respond_to do |format|\n          format.json do\n            prepare_for_rendering(timeline: true, pull_comparison: nil)\n            render_immediate_partials @pull, :timeline_marker, :sidebar, :merging, :form_actions\n          end\n        end\n      else\n        GitHub.stats.increment(\"pullrequest.merge_button.error\")\n        respond_to do |format|\n          format.html do\n            render status: :unprocessable_entity, partial: \"pull_requests/merging_error\", locals: {\n              title: \"Merge attempt failed\",\n              message: (message || \"We couldn’t merge this pull request.\"),\n              hook_output: @hook_out\n            }\n          end\n        end\n        # render :plain => message, :status => :unprocessable_entity\n      end\n    else\n      if result\n        GitHub.dogstats.histogram(\"pull_request.merged.requested_reviewers.count\", @pull.review_requests.pending.size)\n        redirect_to pull_request_path(@pull) + \"#merged-event\"\n      else\n        flash[:error] = message\n        GitHub.stats.increment(\"pullrequest.merge_button.error\")\n        redirect_to pull_request_path(@pull)\n      end\n    end\n  end\n\n  def change_base\n    @pull = find_pull_request\n    return render_404 if !@pull || @pull.merged? ||\n      !@pull.issue.can_modify?(current_user) ||\n      !params[:new_base].present?\n\n    new_base = URI.decode(params[:new_base])\n    begin\n      @pull.change_base_branch(current_user, new_base)\n      flash[:notice] = \"Updated base branch to #{new_base}.\"\n    rescue PullRequest::BadComparison, PullRequest::AlreadyExists => e\n      flash[:error] = e.ui_message\n    end\n    redirect_to pull_request_path(@pull)\n  end\n\n  def update_branch\n    @pull = find_pull_request\n    return render_404 unless @pull\n\n    begin\n      @pull.merge_base_into_head({\n        user: current_user,\n        expected_head_oid: params[:expected_head_oid]\n      })\n\n      if request.xhr?\n        respond_to do |format|\n          format.json do\n            prepare_for_rendering(timeline: true, pull_comparison: nil)\n            render_immediate_partials(@pull, :timeline_marker, :merging)\n          end\n        end\n      else\n        redirect_to pull_request_path(@pull) + \"#partial-pull-merging\"\n      end\n    rescue GitHub::UIError => e\n      if request.xhr?\n        respond_to do |format|\n          format.html do\n            render status: :unprocessable_entity, partial: \"pull_requests/merging_error\", locals: {\n              title: \"Update branch attempt failed\",\n              message: e.ui_message\n            }\n          end\n        end\n      else\n        flash[:error] = e.ui_message\n        redirect_to pull_request_path(@pull) + \"#partial-pull-merging\"\n      end\n    end\n  end\n\n  def revert\n    @pull = find_pull_request\n    return render_404 unless @pull && @pull.revertable_by?(current_user)\n\n    stats_key = [\"pullrequest\",\n                 \"revert_button\",\n                 @pull.cross_repo? ? \"cross_repo\" : \"same_repo\"].join(\".\")\n\n    begin\n      revert_branch, error = @pull.revert(current_user, request_reflog_data(\"pull request revert button\"), timeout: (request_time_left / 3))\n      if revert_branch\n        GitHub.stats.increment(\"#{stats_key}.success\")\n\n        base_label, head_label =\n          if revert_branch.repository == @pull.base_repository\n            [@pull.base_ref_name, revert_branch.name]\n          else\n            [\"#{@pull.base_label(username_qualified: true)}\", \"#{revert_branch.repository.owner.login}:#{revert_branch.name}\"]\n          end\n\n        flash[:pull_request] = {\n          title: \"Revert \\\"#{@pull.title}\\\"\",\n          body: \"Reverts #{@pull.base_repository.name_with_owner}##{@pull.number}\"\n        }\n        redirect_to(compare_path(@pull.base_repository, \"#{base_label}...#{head_label}\", true))\n      else\n        if error == :merge_conflict\n          GitHub.stats.increment(\"#{stats_key}.merge_conflict\")\n        else\n          GitHub.stats.increment(\"#{stats_key}.error\")\n        end\n\n        flash[:error] = \"Sorry, this pull request couldn’t be reverted automatically. It may have \\\n                         already been reverted, or the content may have changed since it was merged.\"\n        redirect_to pull_request_path(@pull)\n      end\n    rescue Git::Ref::HookFailed => e\n      flash[:hook_out] = e.message\n      flash[:hook_message] = \"Pull request could not be reverted.\"\n      redirect_to pull_request_path(@pull)\n    end\n  end\n\n  def merge_button\n    pull = current_repository.issues.find_by_number(params[:id].to_i).try(:pull_request)\n    return render_404 if pull.nil?\n    merge_state = pull.cached_merge_state(viewer: current_user)\n\n    respond_to do |format|\n      format.html do\n        if merge_state.unknown?\n          head :accepted\n        else\n          render partial: \"pull_requests/merge_button\", locals: { pull: pull }\n        end\n      end\n\n      format.json do\n        render json: {mergeable_state: merge_state.status}.to_json\n      end\n    end\n  end\n\n  def diff\n    # This might be a request for a redirect to the PR for a branch name ending in .diff,\n    # or might be a request for a numbered PR in .diff format.\n    diff_ref = \"#{params[:id]}.diff\"\n    if current_repository.heads.include?(diff_ref)\n      return redirect_or_404(diff_ref)\n    end\n\n    redirect_or_error = ensure_valid_pull_request\n    if performed?\n      return redirect_or_error\n    else\n      redirect_to build_pull_request_diff_url\n    end\n  end\n\n  def patch\n    # This might be a request for a redirect to the PR for a branch name ending in .patch,\n    # or might be a request for a numbered PR in .patch format.\n    patch_ref = \"#{params[:id]}.patch\"\n    if current_repository.heads.include?(patch_ref)\n      return redirect_or_404(patch_ref)\n    end\n\n    redirect_or_error = ensure_valid_pull_request\n    if performed?\n      return redirect_or_error\n    else\n      redirect_to build_pull_request_patch_url\n    end\n  end\n\n  def comment\n    return if reject_bully?\n\n    @pull = current_repository.issues.find_by_number(params[:id].to_i).try(:pull_request)\n    return render_404 unless @pull\n    issue = @pull.issue\n\n    valid = true\n    comment_body = params[:comment][:body]\n\n    if !comment_body.nil? && !can_skip_creating_comment?\n      comment = issue.create_comment(current_user, comment_body)\n      valid &&= comment.persisted?\n\n    elsif params[:comment_and_close] == \"1\"\n      comment = issue.comment_and_close(current_user, comment_body)\n      valid &= comment if comment_body.present?\n\n      GitHub.dogstats.histogram(\"pull_request.closed.requested_reviewers.count\", @pull.review_requests.pending.size)\n\n    elsif params[:comment_and_open] == \"1\"\n      comment = issue.comment_and_open(current_user, comment_body)\n      valid &= comment if comment_body.present?\n    end\n\n    mark_thread_as_read issue\n    if valid && comment_body.present?\n      GitHub.instrument \"comment.create\", user: current_user\n      instrument_saved_reply_use(params[:saved_reply_id], \"pull_request_comment\")\n    end\n\n    respond_to do |format|\n      format.json do\n        if valid\n          prepare_for_rendering(timeline: true, pull_comparison: nil)\n          render_immediate_partials @pull, :timeline_marker, :sidebar, :merging, :form_actions, :title\n        else\n          errors = comment.errors.map { |attr, msg| msg }\n          render json: { errors: errors }, status: :unprocessable_entity\n        end\n      end\n      format.html do\n        if valid\n          anchor = comment ? \"#issuecomment-#{comment.id}\" : \"\"\n          redirect_to pull_request_path(@pull) + anchor\n        else\n          flash[:error] = comment.errors.full_messages.to_sentence\n          redirect_to :back\n        end\n      end\n    end\n  end\n\n  def dismiss_protip\n    current_user.dismiss_notice(\"continuous_integration_tip\")\n\n    head :ok\n  end\n\n  if Rails.env.development?\n    def merge_button_matrix\n      if mobile?\n        render \"pull_requests/merge_button_matrix_mobile\", layout: \"mobile/application\"\n      else\n        render \"pull_requests/merge_button_matrix\", layout: \"mobile/application\"\n      end\n    end\n  end\n\n  def set_collab\n    pull = current_repository.issues.find_by_number(params[:id].to_i).try(:pull_request)\n\n    return render_404 if !pull || !pull.head_repository.repository.pushable_by?(current_user)\n\n    if !!params[:collab_privs]\n      pull.fork_collab = :allowed\n    else\n      pull.fork_collab = :denied\n    end\n\n    pull.save!\n\n    redirect_to pull_request_path(pull)\n  end\n\n  def resolve_conflicts\n    redirect_or_error = ensure_valid_pull_request\n\n    unless logged_in? && @pull.head_repository && @pull.head_repository.pushable_by?(current_user, ref: @pull.head_ref_name)\n      return render_404\n    end\n    return redirect_to pull_request_path(@pull) unless @pull.conflict_resolvable? && conflict_editor_enabled?(@pull)\n\n    if performed?\n      return redirect_or_error\n    end\n\n    render \"pull_requests/resolve_conflicts\", locals: { pull: @pull }\n  end\n\nprotected\n\n  helper_method :tab_specified?\n  def tab_specified?(tab_name)\n    specified_tab.to_s == tab_name.to_s\n  end\n\n  helper_method :pull_request_subscribe_enabled?\n  def pull_request_subscribe_enabled?\n    Rails.development? || Rails.test? || preview_features?\n  end\n\n  def specified_tab\n    @specified_tab || params[:tab].presence || \"discussion\"\n  end\n  helper_method :specified_tab\n\n  def valid_tab?\n    params[:tab].blank? || %w{commits files tasks}.include?(params[:tab])\n  end\n\n  def reject_bully_for?(repo)\n    if blocked_by_owner?(repo.owner_id)\n      flash[:error] = \"You can't perform that action at this time.\"\n      redirect_to repo.permalink\n      true\n    end\n  end\n\n  def reject_bully?\n    reject_bully_for? current_repository\n  end\n\n  def tree_name\n    if @pull && @pull.open?\n      @pull.head_ref_name\n    elsif @pull\n      @pull.head_sha\n    else\n      super\n    end\n  end\n\n  private\n\n  def find_pull_request\n    PullRequest.find_by_number_and_repo(params[:id].to_i, current_repository, include: [{ issue: :comments }])\n  end\n\n  # Private: For a given ref name, redirect to the appropriate pull request\n  # path if one exists, or 404 otherwise.\n  #\n  # Returns the redirect or render_404 result.\n  def redirect_or_404(ref)\n    # redirect to number version if ref is a branch name,\n    # redirect to new if ref is a branch with no pull request\n    # 404 otherwise\n    if pull = current_repository.pull_requests.for_branch(ref).last\n      redirect_to pull_request_path(pull)\n    elsif ref =~ /[:.]/ || current_repository.heads.include?(ref)\n      redirect_to new_pull_request_path(range: ref)\n    else\n      render_404\n    end\n  end\n\n  # Private: Validate the requested pull request ID. If necessary redirect to\n  # a more appropriate URL or return a 404 if the PR isn't/shouldn't be\n  # available.\n  def ensure_valid_pull_request\n    if params[:id] =~ /\\D/\n      return redirect_or_404(params[:id])\n    end\n\n    @pull = find_pull_request\n\n    return redirect_to(issue_path(id: params[:id])) unless @pull\n    return redirect_to(pull_request_path @pull) unless valid_tab?\n\n    return render_404 if @pull.hide_from_user?(current_user)\n\n    @prose_url_hints = { tab: \"files\" }\n\n    @pull.set_diff_options(\n      use_summary: true,\n      ignore_whitespace: ignore_whitespace?\n    )\n  end\n\n  def conflict_editor_enabled?(pull)\n    return true unless pull.cross_repo?\n\n    GitHub.cross_repo_conflict_editor_enabled?\n  end\n\n  # Validates the provided parameter is a valid sha, or nil\n  def valid_sha_param?(param_name)\n    param = params[param_name]\n    param.nil? || param =~ /[0-9a-f]{40}/\n  end\n\n  def load_diff\n    @pull_comparison.ignore_whitespace = ignore_whitespace?\n    @pull_comparison.diff_options[:use_summary] = true\n\n    # load diff data\n    if !show_mobile_view?\n      @pull_comparison.diff_options[:top_only] = true\n\n      GitHub.dogstats.time(\"diff.load.initial\", tags: dogstats_request_tags) do\n        @pull_comparison.diffs.apply_auto_load_single_entry_limits!\n        @pull_comparison.diffs.load_diff(timeout: request_time_left / 2)\n      end\n    else\n      @pull_comparison.diffs.load_diff(timeout: request_time_left / 2)\n    end\n  end\n\n  # Preload data needed for rendering the PR.\n  #\n  # timeline - Boolean specifying whether the PR's timeline will be rendered.\n  # pull_comparison - PullRequest::Comparison specifying whether the PR's diff will be rendered.\n  #\n  # Returns nothing.\n  def prepare_for_rendering(timeline:, pull_comparison:)\n    prepare_for_rendering_timeline_items(timeline: timeline, pull_comparison: pull_comparison)\n    prepare_for_rendering_diffs(timeline: timeline, pull_comparison: pull_comparison)\n  end\n\n  # Preload data needed for rendering timeline items.\n  #\n  # timeline - Boolean specifying whether the PR's timeline will be rendered.\n  # pull_comparison - PullRequest::Comparison specifying whether the PR's diff\n  #   (which contains timeline items corresponding to live review threads) will be rendered.\n  #\n  # Returns nothing.\n  def prepare_for_rendering_timeline_items(timeline:, pull_comparison:)\n    timeline_items = visible_timeline_items\n    if pull_comparison\n      # Add in the review threads that are shown on the Files changed tab.\n      # Note that some of these might be also be shown on the Discussion tab,\n      # but the AR objects will actually be distinct so it's still worth\n      # prefilling/warming both objects.\n      timeline_items = timeline_items.dup\n      threads = pull_comparison.review_threads(viewer: current_user)\n      timeline_items.concat(threads.to_a)\n    end\n\n    @pull.prefill_timeline_associations(timeline_items,\n      preload_diff_entries: timeline, show_mobile_view: show_mobile_view?)\n\n    preload_discussion_group_data(timeline_items)\n  end\n\n  # Preload data needed for rendering diffs.\n  #\n  # timeline - Boolean specifying whether the PR's timeline (which contains\n  #            diffs for review threads) will be rendered.\n  # pull_comparison - PullRequest::Comparison specifying whether the PR's diff will be rendered.\n  #\n  # Returns nothing.\n  def prepare_for_rendering_diffs(timeline:, pull_comparison:)\n    return unless syntax_highlighted_diffs_enabled?\n\n    diffs_to_highlight = []\n    if timeline\n      visible_timeline_items.each do |item|\n        next unless item.is_a?(PullRequestReviewThread)\n        next unless item.diff_entry\n        diffs_to_highlight << item.diff_entry\n      end\n    end\n    if pull_comparison\n      diffs_to_highlight.concat(pull_comparison.diffs.to_a)\n    end\n    SyntaxHighlightedDiff.new(@pull.comparison.compare_repository, current_user).highlight!(diffs_to_highlight, attributes_commit_oid: @pull.head_sha)\n  end\n\n  def can_skip_creating_comment?\n    params[:comment_and_close].present? ||\n      params[:comment_and_open].present?\n  end\n\n  # If it's empty, you can't issue a pull request.  There will be no\n  # base SHA to merge against.\n  def check_for_empty_repository\n    if current_repository.empty?\n      redirect_to current_repository\n    end\n  end\n\n  def ensure_pull_head_pushable\n    @pull = current_repository.issues.find_by_number(params[:id].to_i).try(:pull_request)\n\n    if @pull.nil? || !@pull.head_repository.pushable_by?(current_user)\n      render_404\n    end\n  end\n\n  # Reload the pull so the deletable/restorable status is current,\n  # then render updates for the event list and the merge/delete buttons.\n  def render_head_ref_update\n    @pull.reload\n    respond_to do |format|\n      format.json do\n        prepare_for_rendering(timeline: true, pull_comparison: nil)\n        render_immediate_partials(@pull, :timeline_marker, :merging, :form_actions)\n      end\n    end\n  end\n\n  # Internal: Provide a better failure message than simply taking the validation errors\n  #\n  # e - the ActiveRecord::RecordInvalid exception from the creation failure\n  #\n  # Returns a String\n  def human_failure_message(e)\n    pr = e.record\n\n    # e.record can be an Issue, raised in PullRequest.create_for.\n    return e.message unless pr.is_a?(PullRequest)\n\n    if bad_branches = pr.missing_refs\n      if bad_branches.length == 1\n        \"The #{bad_branches.first} branch doesn’t exist.\"\n      else\n        \"The #{bad_branches.join(' and ')} branches don’t exist.\"\n      end\n    elsif [:base_ref, :head_ref].any? { |attr| pr.errors[attr].include?(GitHub::Validations::Unicode3Validator::ERROR_MESSAGE) }\n      \"Branch names cannot contain unicode characters above 0xffff.\"\n    else\n      e.message\n    end\n  end\n\n  # If there are this many timeline items or fewer, we'll render the timeline\n  # inline when the user is viewing the Files tab. If there are more than this\n  # many items, we'll leave the timeline out and load it as needed to try to\n  # avoid timing out.\n  MAXIMUM_TIMELINE_SIZE_FOR_INLINE_RENDER = 149\n\n  def render_discussion_page?\n    return @render_discussion_page if defined?(@render_discussion_page)\n    @render_discussion_page =\n      tab_specified?(\"discussion\") || (!show_mobile_view? && @pull.timeline_children_for(current_user).count <= MAXIMUM_TIMELINE_SIZE_FOR_INLINE_RENDER)\n  end\n  helper_method :render_discussion_page?\n\n  def render_files_page?\n    return @render_files_page if defined?(@render_files_page)\n    @render_files_page = tab_specified?(\"files\") || (!show_mobile_view? && !@pull.corrupt? && !@pull.large_diff?)\n  end\n  helper_method :render_files_page?\n\n  def pull_request_authorization_token\n    current_user.signed_auth_token expires: 60.seconds.from_now,\n                                   scope: pull_request_authorization_token_scope_key\n  end\n\n  def build_pull_request_diff_url\n    route_options ||= {}\n\n    if GitHub.prs_content_domain?\n      route_options[:host] = GitHub.prs_content_host_name\n    end\n\n    if current_repository.private?\n      route_options[:token] = pull_request_authorization_token\n    end\n\n    route_options[:full_index] = params[:full_index]\n\n    pull_request_raw_diff_url(route_options)\n  end\n\n  def build_pull_request_patch_url\n    route_options ||= {}\n\n    if GitHub.prs_content_domain?\n      route_options[:host] = GitHub.prs_content_host_name\n    end\n\n    if current_repository.private?\n      route_options[:token] = pull_request_authorization_token\n    end\n\n    route_options[:full_index] = params[:full_index]\n\n    pull_request_raw_patch_url(route_options)\n  end\n\n  def request_reflog_data(via)\n    super(via).merge({ pr_author_login: @pull.safe_user.login })\n  end\n\n  def content_authorization_required\n    authorize_content(:pull_request, repo: current_repository)\n  end\n\n  # Internal: Extract OID components from PR range.\n  #\n  #   /github/github/pull/123/files/abc123..def456\n  #   /github/github/pull/123/files/def456\n  #\n  # pull  - Current PullRequest\n  # range - String range parameter\n  #\n  # If a complete range is given, a pair of resolved String OIDs will be\n  # returned. If only one end sha is given, nil and a resolved String OID\n  # will be returned. Otherwise nil is returned if no range was matched.\n  def parse_show_range_oid_components(pull, range)\n    if m = range.to_s.match(/\\A(?<sha1>[a-fA-F0-9]{7,40})\\.\\.(?<sha2>[a-fA-F0-9]{7,40}|HEAD)\\z/)\n      sha2 = m[:sha2] == \"HEAD\" ? pull.head_sha : m[:sha2]\n      result = pull.repository.rpc.expand_shas([m[:sha1], sha2], \"commit\")\n      sha1, sha2 = result[m[:sha1]], result[sha2]\n      [sha1, sha2] if sha1 && sha2\n    elsif m = range.to_s.match(/^(?<sha2>[a-fA-F0-9]{7,40})$/)\n      result = pull.repository.rpc.expand_shas([m[:sha2]], \"commit\")\n      sha2 = result[m[:sha2]]\n      return [nil, sha2] if sha2\n    end\n  end\n\n  def visible_timeline_items\n    return [] unless render_discussion_page?\n    super\n  end\n\n  def showing_full_timeline?\n    return false unless render_discussion_page?\n    super\n  end\n\n  def timeline_owner\n    @pull\n  end\n\n  MobileCommitsQuery = parse_query <<-'GRAPHQL'\n    query($ids: [ID!]!) {\n      nodes(ids: $ids) {\n        ...Views::Mobile::PullRequests::CommitList::Commit\n      }\n    }\n  GRAPHQL\n\n  # XXX: Adhoc GraphQL loader for PullRequest.changedChanges connection.\n  #\n  # Load required GraphQL data for each Commit in PullRequest#changed_commits and\n  # wrap it in a fake connection to be compatible with mobile/commits/list template.\n  def load_mobile_pull_request_commits\n    commits = @pull.changed_commits\n\n    # we need to \"fudge\" the repository for these commits as the head repository could disappear\n    # but we should always have these commits in the base. This shouldn't be necessary when this\n    # query is updated to use proper PullRequestCommit objects instead.\n    ids = commits.map do |c|\n      c.repository = @pull.base_repository\n      c.global_relay_id\n    end\n    data = platform_execute(MobileCommitsQuery, variables: { \"ids\" => ids })\n    data.nodes\n  end\n  helper_method :load_mobile_pull_request_commits\nend\n","language":"Ruby"}},{"after":{"path":"app/models/user/feature_flags_dependency.rb","content":"# rubocop:disable Style/FrozenStringLiteralComment\n\n# See https://github.com/github/github/blob/master/docs/feature-flags.md\nclass User\n  module FeatureFlagMethods\n    # Does this user have access to staff-only features on github.com? Make sure\n    # to use this method instead of `User#site_admin?` for early access github.com\n    # features, otherwise these features will be visible to Enterprise admins.\n    #\n    # Returns a Boolean.\n    def preview_features?\n      return unless GitHub.preview_features_enabled?\n      if GitHub.enterprise?\n        enterprise_preview_features?\n      else\n        employee?\n      end\n    end\n\n    # Does this user have access to preview features on Enterprise? This method\n    # should be used for early access to Enterprise features that should not\n    # be visible to Enterprise admins (customers) just yet.\n    #\n    # Returns a Boolean.\n    def enterprise_preview_features?\n      GitHub.enterprise? && enterprise_preview_features_team?\n    end\n\n    # Does this user have access to some open-source maintainers-relevant\n    # early access features on GitHub.com?\n    #\n    # Returns a Boolean.\n    def maintainers_early_access?\n      !GitHub.enterprise? && maintainers_early_access_team?\n    end\n\n    # Should this user see prerelease badges for features they have early access to\n    # Currently only visible to the open source maintainers EAP and staff\n    #\n    # Returns boolean\n    def prerelease_badges?\n      !GitHub.enterprise? && (maintainers_early_access? || preview_features?)\n    end\n\n    # Public: Is the specified feature enabled for this user?\n    # We override the default Flipper behavior to also check employee mode.\n    # \"Employee only\" features are not available if employee mode is disabled;\n    # see also Flipper::EmployeeMode.\n    #\n    # Returns a Boolean\n    def feature_enabled?(feature_name)\n      enabled = super\n      feature = GitHub.flipper[feature_name]\n      enabled && !(disabled_employee_mode? && feature.enabled_for_employees_only?)\n    end\n\n    def abilities_team_enabled?\n      preview_features? && abilities_team?\n    end\n\n    # New security feature to require callback url registration and validation.\n    def oauth_registered_callback_urls_enabled?\n      feature_enabled?(:oauth_multiple_callback_urls)\n    end\n\n    # Internal: Is this an abilibuddy?\n    def abilities_team?\n      team_access? :abilities\n    end\n\n    # Internal: Is this user a stafftooler\n    def stafftools_team?\n      team_access? :stafftools\n    end\n\n    def user_security_team?\n      team_access? :user_security\n    end\n\n    def has_operator_mode?(conf)\n      site_admin? && ((!GitHub.enterprise? && (team_access?(:ops) || team_access?(:systems))) ||\n                 ![nil, \"false\"].include?(conf[\"operator_mode\"]))\n    end\n\n    def enterprise_preview_features_team?\n      team_access? :enterprise_preview_features\n    end\n\n    def maintainers_early_access_team?\n      team_access? :maintainers_early_access\n    end\n\n    # employees that are required to use admin.github.com for stafftools\n    def restricted_frontend_required?\n      feature_enabled?(:require_restricted_front_end) && GitHub.admin_host_name\n    end\n\n    def blob_comment_display_enabled?\n      feature_enabled?(:blob_comment_display)\n    end\n\n    def restricted_frontend_redirect_required?\n      restricted_frontend_required? && !GitHub.restricted_front_end?\n    end\n\n    # Does this user have access to enable per-seat billing for an organization?\n    def perseat_stafftools_enabled?\n      feature_enabled?(:perseat_stafftools)\n    end\n\n    def integrations_directory_enabled?\n      return false if GitHub.enterprise?\n      feature_enabled?(:integrations_directory)\n    end\n\n    def integrations_two_ui_enabled?\n      !GitHub.enterprise?\n    end\n\n    # Are edge languages for semantic features enabled for the current user?\n    def semantic_edge_languages_enabled?\n      feature_enabled?(:semantic_edge_languages)\n    end\n\n    # Should semiotic requests for the current user be routed to the kubes semiotic fes?\n    def semiotic_on_kubes_enabled?\n      feature_enabled?(:semiotic_on_kubes)\n    end\n\n    # Is codesearch disabled for the current user? This feature flag is used to\n    # block users that are negatively impacting the Elasticsearch cluster.\n    #\n    # see https://github.com/devtools/features/disable_codesearch\n    #\n    # Returns a Boolean.\n    def codesearch_disabled?\n      feature_enabled?(:disable_codesearch)\n    end\n\n    # Check whether refunds are disabled for current user\n    #\n    # Returns a Boolean value.\n    def refunds_disabled?\n      feature_enabled?(:disable_refunds)\n    end\n\n    # Internal: Checks if the user is a member of a team.\n    #\n    # team - Symbol name for a Team that matches a FeatureFlagMethods class\n    #        method that loads a team.  `:early_access` will check against\n    #        FeatureFlagMethods.early_access_team.\n    #\n    # Returns a Boolean.\n    def team_access?(team)\n      GitHub::FeatureFlag.user_team_access?(team, self)\n    end\n  end\n\n  include FeatureFlagMethods\nend\n","language":"Ruby"},"before":{"path":"app/models/user/feature_flags_dependency.rb","content":"# rubocop:disable Style/FrozenStringLiteralComment\n\n# See https://github.com/github/github/blob/master/docs/feature-flags.md\nclass User\n  module FeatureFlagMethods\n    # Does this user have access to staff-only features on github.com? Make sure\n    # to use this method instead of `User#site_admin?` for early access github.com\n    # features, otherwise these features will be visible to Enterprise admins.\n    #\n    # Returns a Boolean.\n    def preview_features?\n      return unless GitHub.preview_features_enabled?\n      if GitHub.enterprise?\n        enterprise_preview_features?\n      else\n        employee?\n      end\n    end\n\n    # Does this user have access to preview features on Enterprise? This method\n    # should be used for early access to Enterprise features that should not\n    # be visible to Enterprise admins (customers) just yet.\n    #\n    # Returns a Boolean.\n    def enterprise_preview_features?\n      GitHub.enterprise? && enterprise_preview_features_team?\n    end\n\n    # Does this user have access to some open-source maintainers-relevant\n    # early access features on GitHub.com?\n    #\n    # Returns a Boolean.\n    def maintainers_early_access?\n      !GitHub.enterprise? && maintainers_early_access_team?\n    end\n\n    # Should this user see prerelease badges for features they have early access to\n    # Currently only visible to the open source maintainers EAP and staff\n    #\n    # Returns boolean\n    def prerelease_badges?\n      !GitHub.enterprise? && (maintainers_early_access? || preview_features?)\n    end\n\n    # Public: Is the specified feature enabled for this user?\n    # We override the default Flipper behavior to also check employee mode.\n    # \"Employee only\" features are not available if employee mode is disabled;\n    # see also Flipper::EmployeeMode.\n    #\n    # Returns a Boolean\n    def feature_enabled?(feature_name)\n      enabled = super\n      feature = GitHub.flipper[feature_name]\n      enabled && !(disabled_employee_mode? && feature.enabled_for_employees_only?)\n    end\n\n    def abilities_team_enabled?\n      preview_features? && abilities_team?\n    end\n\n    # New security feature to require callback url registration and validation.\n    def oauth_registered_callback_urls_enabled?\n      feature_enabled?(:oauth_multiple_callback_urls)\n    end\n\n    # Internal: Is this an abilibuddy?\n    def abilities_team?\n      team_access? :abilities\n    end\n\n    # Internal: Is this user a stafftooler\n    def stafftools_team?\n      team_access? :stafftools\n    end\n\n    def user_security_team?\n      team_access? :user_security\n    end\n\n    def has_operator_mode?(conf)\n      site_admin? && ((!GitHub.enterprise? && (team_access?(:ops) || team_access?(:systems))) ||\n                 ![nil, \"false\"].include?(conf[\"operator_mode\"]))\n    end\n\n    def enterprise_preview_features_team?\n      team_access? :enterprise_preview_features\n    end\n\n    def maintainers_early_access_team?\n      team_access? :maintainers_early_access\n    end\n\n    # employees that are required to use admin.github.com for stafftools\n    def restricted_frontend_required?\n      feature_enabled?(:require_restricted_front_end) && GitHub.admin_host_name\n    end\n\n    def blob_comment_display_enabled?\n      feature_enabled?(:blob_comment_display)\n    end\n\n    def restricted_frontend_redirect_required?\n      restricted_frontend_required? && !GitHub.restricted_front_end?\n    end\n\n    # Does this user have access to enable per-seat billing for an organization?\n    def perseat_stafftools_enabled?\n      feature_enabled?(:perseat_stafftools)\n    end\n\n    def integrations_directory_enabled?\n      return false if GitHub.enterprise?\n      feature_enabled?(:integrations_directory)\n    end\n\n    def integrations_two_ui_enabled?\n      !GitHub.enterprise?\n    end\n\n    # Are edge languages for semantic features enabled for the current user?\n    def semantic_edge_languages_enabled?\n      feature_enabled?(:semantic_edge_languages)\n    end\n\n    # Is codesearch disabled for the current user? This feature flag is used to\n    # block users that are negatively impacting the Elasticsearch cluster.\n    #\n    # see https://github.com/devtools/features/disable_codesearch\n    #\n    # Returns a Boolean.\n    def codesearch_disabled?\n      feature_enabled?(:disable_codesearch)\n    end\n\n    # Check whether refunds are disabled for current user\n    #\n    # Returns a Boolean value.\n    def refunds_disabled?\n      feature_enabled?(:disable_refunds)\n    end\n\n    # Internal: Checks if the user is a member of a team.\n    #\n    # team - Symbol name for a Team that matches a FeatureFlagMethods class\n    #        method that loads a team.  `:early_access` will check against\n    #        FeatureFlagMethods.early_access_team.\n    #\n    # Returns a Boolean.\n    def team_access?(team)\n      GitHub::FeatureFlag.user_team_access?(team, self)\n    end\n  end\n\n  include FeatureFlagMethods\nend\n","language":"Ruby"}},{"after":{"path":"lib/github/config.rb","content":"# rubocop:disable Style/FrozenStringLiteralComment\n\nrequire \"etc\"\nrequire \"uri\"\nrequire \"set\"\nrequire \"socket\"\nrequire \"prime\"\n\nmodule GitHub\n  # GitHub global configuration\n  #\n  # This is mixed into the GitHub module such that an attribute \"blah\" defined\n  # here is available at GitHub.blah and GitHub.blah=. All GitHub specific global\n  # configuration should be defined here and set via one of the files defined\n  # below.\n  #\n  # The load order for config values is (each overriding the last):\n  # - Default values defined in this module\n  # - Overrides in config/environment.rb\n  # - Overrides in config/environments/<env>.rb\n  # - Overrides in RAILS_ROOT/config.yml\n  #\n  # The RAILS_ROOT/config.yml file may set any config attribute defined in this\n  # module. It's used primarily to customize FI installations.\n  #\n  # After boot, these properties should be treated as static and MUST NOT be\n  # altered.\n  #\n  # When adding new configuration items, please document them. Include\n  # information on what they're used for, default values, and example values\n  # for a couple different environments if possible.\n  #\n  # NOTE This file is loaded as part of the config/basic.rb lightweight environment.\n  # Do not add any additional library requires here.\n  module Config\n    ELASTICSEARCH_ACCESS_VALUES    = [:allowed, :ignored, :raises] # for validation\n    MAX_UI_PAGINATION_PAGE         = 100\n    PRIMARY_FS_TEST_DIR            = \"/data/repositories/0/lost+found\"\n    MONITORS_USER_ID               = 1162581 # the user id for our special Monitors account\n    HUBOT_USER_ID                  = 480938 # the user id for our special robot account\n    MIRROR_PUSHER                  = \"hubot\" # the login for recording mirror \"pushes\"\n    DGIT_COPIES                    = 3\n    DESKTOP_FETCH_INTERVAL         = 5 # in minutes\n\n    # Set of known sites (datacenters) that can be return values of site_from_host.\n    SITE_WHITELIST = Set[\n      \"cp1-iad\",\n      \"sdc42-sea\",\n    ]\n\n    # Raised on data access when a datastore is configured to be inaccessible,\n    # e.g. in a secondary datacenter.\n    class UnexpectedDatastoreAccess < StandardError; end\n\n    # The current runtime mode object. Used to determine whether we're running\n    # under dotcom or enterprise mode and also allows dynamically switching\n    # modes in development server environments.\n    #\n    # Returns a GitHub::Runtime object.\n    def runtime\n      @runtime ||= GitHub::Runtime.new\n    end\n\n    # Boolean attribute specifying whether the site is in SSL mode. This is\n    # typically set true explicitly in production environments.\n    #\n    # Returns true if SSL is enabled for the site, false otherwise.\n    def ssl?\n      return @ssl if defined?(@ssl)\n      ENV[\"GH_SSL\"]\n    end\n    attr_writer :ssl\n    alias ssl ssl?\n\n    # Public: Return appropriate URI scheme for SSL mode.\n    #\n    # Returns String.\n    def scheme\n      ssl? ? \"https\" : \"http\"\n    end\n\n    # Whether to run background jobs in the calling process. Useful in\n    # development / test only.\n    attr_accessor :inline_jobs\n    alias inline_jobs? inline_jobs\n\n    # Is the current environment connected to the public internet? This is\n    # useful primarily in development environments where loading gravatars and\n    # other external items may be skipped. This should always be set true\n    # everywhere except in development and enterprise instances to prevent the\n    # slow ping check.\n    #\n    # Returns true if external internet access is available, false otherwise.\n    def online?\n      return @online if defined?(@online)\n      return false if enterprise?\n      return google_reachable? if Rails.development?\n\n      true\n    end\n    attr_writer :online\n    alias online online?\n\n    def google_reachable?\n      @online = begin\n        Timeout.timeout(1) do\n          s = TCPSocket.new(\"google.com\", 80)\n          s.close\n        end\n        true\n      rescue Errno::ECONNREFUSED\n        true\n      rescue Timeout::Error, StandardError\n        false\n      end\n    end\n\n    # The test environment's parallel execution number.\n    #\n    # Returns the environment number as a string but only in test environments.\n    # In other environments this method returns nil.\n    def test_environment_number\n      Rails.env.test? && (ENV[\"TEST_ENV_NUMBER\"] || \"0\")\n    end\n\n    # Should Mysql use alternate database(s), such as read only\n    # replica's? See also GitHub::Config::Mysql\n    #\n    # Enabled by default in production\n    def alternate_db_enabled?\n      return @alternate_db_enabled if defined?(@alternate_db_enabled)\n      @alternate_db_enabled = true\n    end\n    attr_writer :alternate_db_enabled\n\n    # Enable gravatar images throughout the site. Some enterprise customers\n    # may want to disable this for security reasons.\n    #\n    # Returns true if gravatar images should be displayed, false otherwise.\n    def gravatar_enabled?\n      return @gravatar_enabled if defined?(@gravatar_enabled)\n\n      online?\n    end\n    attr_writer :gravatar_enabled\n\n    # The base URL for all avatars. This server must implement the gravatar API. If passed\n    # a string, it will determine which gravatar subdomain to use\n    # (see https://github.com/github/github/issues/13687#issuecomment-22726044)\n    #\n    # string - An optional String that will be hashed to determine which Gravatar subdomain\n    #          should be used (0, 1 or 2).\n    #\n    # Returns a gravatar base url\n    def gravatar_url(string = nil)\n      return @gravatar_url if defined? @gravatar_url\n      subdomain = string ? Zlib.crc32(string.to_s) % 3 : 0\n      \"https://#{subdomain}.gravatar.com\"\n    end\n\n    attr_writer :gravatar_url\n\n    # Whether we are using gravatar.com or a custom avatar service.\n    #\n    # Returns true when gravatar_url ends with .gravatar.com\n    def gravatar_service?\n      gravatar_url =~ /\\.gravatar\\.com$/\n    end\n\n    # GpgVerify client instance\n    #\n    # Returns a GpgVerify instance\n    def gpg\n      return @gpg if defined?(@gpg)\n      @gpg = GpgVerify.new(GitHub.gpgverify_url)\n    end\n    attr_writer :gpg\n\n    # Host where the gpgverify HTTP service is running.\n    #\n    # Returns a url String.\n    def gpgverify_url\n      @gpgverify_url ||= \"http://127.0.0.1:8686\"\n    end\n    attr_writer :gpgverify_url\n\n    def git_signing_smime_cert_store\n      @git_signing_smime_cert_store ||= begin\n        store = OpenSSL::X509::Store.new\n        store.add_file(Certifi.where)\n        store\n      end\n    end\n\n    # Returns true if repositories require explictly accepted invitations when\n    # adding a new member.\n    def repo_invites_enabled?\n      !GitHub.enterprise?\n    end\n\n    # Whether sudo mode capabilities can be enabled.\n    #\n    # Always returns true unless our authentication method supports password\n    # verification.\n    def sudo_mode_enabled?\n      GitHub.auth.sudo_mode_enabled?\n    end\n\n    # Whether Orgs SAML SSO session (external identity session) enforcement is\n    # enabled in this environment.\n    #\n    # The feature is currently only enabled for GitHub.com (as it would be\n    # redundant with GHE's SAML SSO support).\n    #\n    # Returns Boolean.\n    def external_identity_session_enforcement_enabled?\n      !enterprise?\n    end\n\n    # If we are using an external authentication mechanism, we can delegate\n    # account lockouts to them.\n    #\n    # Returns true if account lockouts are enabled, false otherwise.\n    def lockouts_enabled?\n      !GitHub.auth.external?\n    end\n\n    # Do we block JSON responses to non-XHR requests?\n    def json_xhr_requirement_enabled?\n      !Rails.test?\n    end\n\n    # The full path to the root directory where repositories are stored.\n    def repository_root\n      @repository_root ||=\n        if Rails.development?\n          env = enterprise?? \"fi\" : Rails.env\n          File.expand_path(\"#{Rails.root}/repositories/#{env}\")\n        elsif Rails.test?\n          # tests get a clean repo root and each parallel test process gets its own\n          # directory too based on the TEST_ENV_NUMBER.\n          \"#{Rails.root}/repositories/test#{ENV['TEST_ENV_NUMBER']}\"\n        else\n          \"/data/repositories\"\n        end\n    end\n    attr_writer :repository_root\n\n    # The git repository template used when creating new repositories on\n    # disk. This contains hooks and any other files that should be present\n    # in newly created or forked repositories.\n    #\n    # Returns the full path to git repo template directory.\n    def repository_template\n      @repository_template ||=\n        if Rails.production?\n          if enterprise?\n            \"/data/github/current/lib/git-core/fi-template\".freeze\n          else\n            \"/data/github/current/lib/git-core/template_shadow\".freeze\n          end\n        else\n          if enterprise?\n            \"#{Rails.root}/lib/git-core/fi-template\".freeze\n          else\n            \"#{Rails.root}/lib/git-core/template_shadow\".freeze\n          end\n        end\n    end\n    attr_writer :repository_template\n\n    # Delegated account recovery keys used to sign/verify recovery tokens\n    attr_accessor :account_provider_public_key, :account_provider_private_key,\n      :account_recovery_provider_creds, :account_provider_symmetric_key,\n      :recovery_provider_public_key, :recovery_provider_private_key\n\n    # Earthsmoke configuration\n    attr_accessor :earthsmoke_address, :earthsmoke_cert, :earthsmoke_token\n\n    # Earthsmoke client\n    def earthsmoke\n      @earthsmoke ||= begin\n        if earthsmoke_available?\n          ::Earthsmoke::Client.new(\n            token: earthsmoke_token,\n            server: earthsmoke_address,\n            ca_file: earthsmoke_cert\n          )\n        end\n      end\n    end\n\n    # Do we have the necessary configuration information to use the earthsmoke\n    # service?\n    #\n    # Returns boolean.\n    def earthsmoke_available?\n      !earthsmoke_address.blank? &&\n        !earthsmoke_token.blank? &&\n        !earthsmoke_cert.blank? &&\n        File.file?(earthsmoke_cert)\n    end\n\n    # Used only by the old RepositoriesNetshardTransition.\n    def old_gist_repository_template\n      @old_gist_repository_template ||=\n        if Rails.production?\n          \"/data/github/current/lib/git-core/gist-template\".freeze\n        else\n          \"#{Rails.root}/lib/git-core/gist-template\".freeze\n        end\n    end\n    attr_writer :old_gist_repository_template\n\n    def gist3_repository_template\n      @gist3_repository_template ||=\n        if Rails.production?\n          \"/data/github/current/lib/git-core/gist-template\".freeze\n        else\n          \"#{Rails.root}/lib/git-core/gist-template\".freeze\n        end\n    end\n    attr_writer :gist3_repository_template\n\n    # Determine if the app is running under GitHub Enterprise. This is\n    # determined by the ENTERPRISE (or FI) environment variable being set.\n    #\n    # Returns true if running under Enterprise, false otherwise.\n    def enterprise?\n      return @enterprise if defined?(@enterprise)\n      @enterprise = GitHub.runtime.enterprise?\n    end\n    attr_writer :enterprise\n    alias fi? enterprise?\n\n    # Determines if the app is running on a non-clustered Enterprise instance\n    # Enterprise non-clustered returns true\n    # Enterprise clustered returns false\n    # github.com returns false\n    def single_instance?\n      @single_instance ||= enterprise? && Rails.development?\n    end\n    attr_writer :single_instance\n\n    # Determine if the current request is not enterprise\n    def dotcom_request?\n      !enterprise?\n    end\n\n    # Determine if the current request is for GitHub Cloud.\n    #\n    # This is going away soon...\n    #\n    # Returns Boolean\n    def cloud_request?\n      false\n    end\n\n    # Determine if the app should only show the limited Admin Center UI\n    #\n    # Returns true if running under Enterprise\n    def limited_admin_center?\n      GitHub.enterprise?\n    end\n\n    # The Basic Auth password used to access the Hosted Enterprise environment\n    # in production.\n    #\n    # Defaults to `passworD1`, set in the environment as\n    # `HOSTED_BASIC_AUTH_PASSWORD`.\n    def hosted_basic_auth_password\n      return @hosted_basic_auth_password if defined?(@hosted_basic_auth_password)\n      @hosted_basic_auth_password = ENV[\"HOSTED_BASIC_AUTH_PASSWORD\"] || \"passworD1\"\n    end\n\n    def default_request_timeout\n      @default_request_timeout ||= 10\n    end\n    attr_writer :default_request_timeout\n\n    # The read timeout for GitRPC\n    attr_accessor :gitrpc_timeout\n\n    # The max duration (in seconds) a request can take before it times out.\n    def request_timeout(env)\n      env ||= {}\n\n      return default_request_timeout if env[\"REQUEST_METHOD\"].to_s == \"GET\"\n\n      case env[\"REQUEST_PATH\"].to_s\n      # These are all request paths that take payment details like credit card\n      # params and directly call Braintree APIs. They benefit from a longer timeout.\n      # See https://github.com/github/github/pull/28356 for more context.\n      when %r{^/account/billing/update_credit_card},\n           %r{^/account/cc_update}, # May charge for yearly plan changes\n           %r{^/organizations/([^/]+)(.*)/billing/cc_update}, # May charge for yearly plan changes\n           %r{^/organizations/([^/]+)(.*)/billing/update_credit_card},\n           %r{^/stafftools/users/([^/]+)(.*)/change_plan}\n        [30, default_request_timeout].max\n      when %r{^/repositories$},  # Create repo with upsell\n           %r{^/organizations$}, # Create new paid organization\n           %r{^/join/plan$},\n           %r{^/redeem/([^/]+)(.*)$},\n           %r{^/site/custom_sleeptown$}\n        [20, default_request_timeout].max\n      else\n        default_request_timeout\n      end\n    end\n\n    # The threshhold for slow web / API requests, in seconds.  Requests that\n    # take longer than this threshold are sent to a slow bucket in haystack\n    # for reporting.\n    def slow_request_threshold\n      @slow_request_threshold ||= 2.0\n    end\n    attr_writer :slow_request_threshold\n\n    # Determine if the app is running on a employee-only unicorn.\n    #\n    # Return true on staff1.rs\n    def employee_unicorn?\n      return @employee_unicorn if defined?(@employee_unicorn)\n      @employee_unicorn = false\n    end\n    attr_writer :employee_unicorn\n\n    # Determine if the app is running on the new-style employee-only unicorn.\n    #\n    # Return true on one of the garage hosts\n    def garage_unicorn?\n      return @garage_unicorn if defined?(@garage_unicorn)\n      @garage_unicorn = false\n    end\n    attr_writer :garage_unicorn\n\n    # Return the user-facing name for GitHub based on whether or not\n    # they're looking at GitHub.com or an Enterprise installation.\n    #\n    # Returns a String\n    def flavor\n      if enterprise?\n        \"GitHub Enterprise\"\n      else\n        \"GitHub\"\n      end\n    end\n\n    # committer_name to be used for web edits/merges/reverts.\n    #\n    # Returns a String.\n    def web_committer_name\n      flavor\n    end\n\n    # committer_email to be used for web edits/merges/reverts.\n    #\n    # Returns a String.\n    def web_committer_email\n      noreply_address\n    end\n\n    # Used to determine the period of time below which an account is always\n    # considered active and within which we look for activity when considering\n    # how dormant the account is. See User#recently_active? and\n    # User#exempt_from_dormancy?\n    #\n    # Returns a time period.\n    def dormancy_threshold\n      return @dormancy_threshold if defined?(@dormancy_threshold)\n      @dormancy_threshold = (GitHub.enterprise? ? 1.month : 12.months)\n    end\n    attr_writer :dormancy_threshold\n\n    # Determine if the \"Dormant users\" page in stafftools should be displayed.\n    # This performs fairly intense operations against the entire users table,\n    # so it shouldn't be used on .com.\n    def bulk_dormant_user_suspension_enabled?\n      return @bulk_dormant_user_suspension_enabled if defined?(@bulk_dormant_user_suspension_enabled)\n      @bulk_dormant_user_suspension_enabled = GitHub.enterprise?\n    end\n    attr_writer :bulk_dormant_user_suspension_enabled\n\n    # Trusted ports are used for GitHub Enterprise to allow some diagnostics\n    # scripts to hit the API and some other staff-specific routes without\n    # authenticating.\n    #\n    # Returns true if this feature is enabled, false otherwise.\n    def trusted_ports_enabled?\n      @trusted_ports_enabled ||= enterprise?\n    end\n    attr_writer :trusted_ports_enabled\n\n    # The delegated account recovery feature allows us to act as an Account Provider\n    # and a Recovery Provider. Currently, we will only be acting as an Account Provider\n    # but we fake out acting as a recovery provider in dev/test.\n    def github_as_recovery_provider_enabled?\n      !Rails.env.production?\n    end\n\n    def delegated_recovery_enabled?\n      !GitHub.enterprise?\n    end\n\n    # The ports we implicitly trust. Nginx should only be listening to\n    # these ports on localhost.\n    #\n    # Returns an array of strings.\n    def trusted_ports\n      @trusted_ports ||= if GitHub.enterprise?\n        %w(1337)\n      else\n        []\n      end\n    end\n\n    ##\n    # Host Names\n\n    # The main external GitHub hostname only. No http:// prefix or protocol\n    # information is included.\n    #\n    # Returns the hostname string (\"github.com\", \"github.dev\", etc.) or nil if\n    # no host_name has been set.\n    def host_name\n      @host_name || ENV[\"GH_HOSTNAME\"]\n    end\n    attr_writer :host_name\n\n    # The main external GitHub Cloud hostname only. No http:// prefix or\n    # protocol information is included.\n    #\n    # Returns the hostname String, defaulting to \"githubcloud.com\",\n    # \"githubcloud.dev\", or nil depending on the runtime environment.\n    def cloud_host_name\n      return @cloud_host_name if defined?(@cloud_host_name)\n      @cloud_host_name =\n        case\n        when GitHub.enterprise?\n          nil\n        when Rails.env.development?, Rails.env.test?\n          \"githubcloud.dev\"\n        else\n          \"githubcloud.com\"\n        end\n    end\n    attr_writer :cloud_host_name\n\n    # Determines if emails are sent with the configured noreply address\n    # as Enterprise always has, or the GitHub.com style of emails where\n    # they are From: a notifications@ address\n    attr_accessor :mail_use_noreply_addr\n\n    # Hostname for githubusercontent.com.\n    #\n    # production:  githubusercontent.com\n    # development: githubusercontent.dev\n    #\n    # Returns String host or nil.\n    attr_accessor :user_content_host_name\n\n    # Orgs/users that are owned by GitHub and should be allowed to use\n    # `github.com` urls.\n    #\n    # Returns an Array of String User/Organization logins.\n    def github_owned_pages\n      @github_owned_pages ||= []\n    end\n\n    # The GitHub Pages hostname only.\n    #\n    # Returns the hostname string (\"githubpages.com\", \"github.io\", etc.) or nil\n    # if no host_name has been set.\n    def pages_host_name_v1\n      @pages_host_name ||= GitHub.host_name\n    end\n    attr_writer :pages_host_name\n\n    # The GitHub Pages hostname we are migrating to\n    #\n    # Returns the hostname string (i.e. \"github.io\") if we are in an environment\n    # that supports it,  or nil if no host_name has been set.\n    def pages_host_name_v2\n      @pages_host_name_v2 ||= if enterprise?\n        if GitHub.subdomain_isolation?\n          \"pages.#{GitHub.host_name}\"\n        else\n          GitHub.host_name\n        end\n      else\n        \"github.io\".freeze\n      end\n    end\n    attr_writer :pages_host_name_v2\n\n    def pages_preview_hostname\n      @pages_preview_hostname ||= \"drafts.github.io\"\n    end\n    attr_writer :pages_preview_hostname\n\n    # The GitHub Pages themes hostname for previews in the theme chooser\n    def pages_themes_hostname\n      @pages_themes_hostname ||= \"pages-themes.#{GitHub.pages_host_name_v2}\"\n    end\n    attr_writer :pages_themes_hostname\n\n    # Do we support HTTPS redirects for pages sites?\n    #\n    # Returns boolean.\n    def pages_https_redirect_enabled?\n      !enterprise?\n    end\n\n    # Pages for repositories created after this time will require HTTPS if they\n    # are served from github.io.\n    #\n    # This is only used it tests for now, so it's set to an hour from now.\n    #\n    # Returns a Time instance.\n    def pages_https_required_after\n      @pages_https_required_after ||= Time.parse(\"2016-06-15 12:00:00 PDT\")\n    end\n\n    # Domains that we have SSL certs for on Fastly.\n    #\n    # Returns an Array of Strings.\n    def pages_https_domains\n      if enterprise?\n        []\n      else\n        %w(\n          blog.atom.io\n          electron.atom.io\n          flight-manual.atom.io\n\n          brew.sh\n          docs.brew.sh\n\n          choosealicense.com\n          codeconf.com\n          github.co.jp\n          githubengineering.com\n          githubuniverse.com\n          opensource.guide\n          svnhub.com\n        )\n      end\n    end\n\n    # Do we support creating Let's Encrypt certificates for CNAME pages.\n    def acme_enabled?\n      !enterprise?\n    end\n\n    # ACME protocol endpoint for getting Pages certificates.\n    def acme_endpoint\n      \"https://acme-v01.api.letsencrypt.org/\"\n    end\n\n    # JSON Web Key for ACME client.\n    def acme_jwk\n      @acme_jwk ||= GitHub::Earthsmoke::AcmeJwk.new(\"github:acme:lets-encrypt:account-key\")\n    end\n\n    # Key for Let's Encrypt certificates.\n    def acme_cert_key\n      @acme_cert_key ||= GitHub.earthsmoke.key(\"github:acme:lets-encrypt:cert-key\")\n    end\n\n    # ACME client for getting Pages certificates.\n    def acme\n      @acme ||= Acme::Client.new(\n        jwk: acme_jwk,\n        endpoint: acme_endpoint\n      )\n    end\n\n    # The host name where the API accepts uploads.\n    def api_upload_host_name\n      @api_upload_host_name ||= if (enterprise? || garage_unicorn?)\n        \"#{host_name}/api/uploads\".freeze\n      else\n        \"uploads.#{host_name}\".freeze\n      end\n    end\n\n    # Choose which type of URL creator we need to return\n    #\n    # Returns an instance of GitHub::UrlBuilder\n    def urls\n      default_url_builder\n    end\n\n    # Generate URLs for default GitHub instances.\n    #\n    # Returns a GitHub::UrlBuilder instance\n    def default_url_builder\n      @default_url_builder ||= GitHub::UrlBuilder.new(host_name: host_name, scheme: scheme)\n    end\n\n    # The host name that the API is served from.\n    #\n    # Retrurns a String.\n    def api_host_name\n      urls.api_host_name\n    end\n\n    # The root path of the API.\n    #\n    # Returns a String.\n    def api_root_path\n      urls.api_root_path\n    end\n\n    # The URL where the V3 API is served from. This defaults to the configured\n    # host_name with an \"api.\" prefix.\n    #\n    # Returns the API url string (e.g. \"https://api.github.com\" for production)\n    def api_url\n      urls.api_url\n    end\n    attr_writer :api_url\n\n    # The URL where the GraphQL API is served from. This defaults to the\n    # configured host_name with an \"api.\" prefix.\n    #\n    # Returns the API url string (e.g. \"https://api.github.com\" for production)\n    def graphql_api_url\n      urls.graphql_api_url\n    end\n    attr_writer :graphql_api_url\n\n    def api_upload_prefix\n      @api_upload_prefix ||= begin\n        host_and_path = api_upload_host_name\n        (ssl? ? \"https://\" : \"http://\") + host_and_path\n      end\n    end\n\n    attr_accessor :admin_host_name\n    def admin_host?\n      !!@is_admin_host\n    end\n    attr_writer :is_admin_host\n\n    # Whitelist a few environments that should expose endpoints that should not be\n    # available on public FEs. These endpoints will be available on dedicated\n    # machines that may be behind additional network-level control in the future.\n    # Also dev / test / lab / enterprise / etc. need to work. Anywhere but dotcom.\n    def restricted_front_end?\n      GitHub.admin_host? ||\n        GitHub.employee_unicorn? ||\n        GitHub.enterprise? ||\n        Rails.env.development? ||\n        Rails.env.test?\n    end\n\n    # The user id for our Monitors account, which is used to display things in the office\n    # and often has some special privilege.\n    #\n    # Returns an integer id.\n    def monitors_user_id\n      @monitors_user_id || MONITORS_USER_ID\n    end\n\n    # The user id for our Hubot account.\n    #\n    # Returns an integer id.\n    def hubot_user_id\n      @hubot_user_id || HUBOT_USER_ID\n    end\n\n    # The fetch interval in minutes for GitHub Desktop applications.\n    #\n    # Returns an integer representing minutes\n    def desktop_fetch_interval\n      @desktop_fetch_interval || DESKTOP_FETCH_INTERVAL\n    end\n    attr_writer :desktop_fetch_interval\n\n    # The login for recording mirror pushes.\n    #\n    # Returns the String login name.\n    def mirror_pusher\n      return @mirror_pusher if defined?(@mirror_pusher)\n      @mirror_pusher = MIRROR_PUSHER\n    end\n    attr_writer :mirror_pusher\n\n    # How many copies (replicas) of each repo network to aim for.\n    #\n    # Returns a small, odd integer.\n    def dgit_copies\n      @dgit_copies ||= DGIT_COPIES\n    end\n    attr_writer :dgit_copies\n\n    # How many non-voting copies of each repo network to aim for.\n    #\n    # If nil, spokes will not care how many non-voting replicas exist.\n    attr_accessor :dgit_non_voting_copies\n\n    # How frequently should the timerd job run to pre-fill the\n    # cached disk stats?\n    #\n    # This should be smaller than dgit_disk_stats_cache_ttl.\n    attr_writer :dgit_disk_stats_interval\n    def dgit_disk_stats_interval\n      @dgit_disk_stats_interval || 60\n    end\n\n    # How long should GitHub::DGit.disk_stats and GitHub::DGit.parallel_disk_stats\n    # cache their responses for?\n    attr_writer :dgit_disk_stats_cache_ttl\n    def dgit_disk_stats_cache_ttl\n      @dgit_disk_stats_cache_ttl || 90\n    end\n\n    # How frequently should the timerd job run to compare\n    # fileservers tables between the legacy and new Spokes\n    # databases?\n    attr_writer :dgit_fileservers_diffjob_interval\n    def dgit_fileservers_diffjob_interval\n      @dgit_fileservers_diffjob_interval || 60\n    end\n\n    # How many copies (replicas) of a repo are needed to accept a write.\n    #\n    # `ncopies` is an optional indication of the actual number of replicas\n    # eligible to vote.  When this is more than the number returned by\n    # `dgit_copies`, the quorum may be larger.  For example, the normal\n    # number of copies is 3, but in some cases, a repo network might have\n    # 4 copies, in which case it takes 3 (not 2) to make a quorum.\n    #\n    # Returns a strict majority of the target number of copies.\n    def dgit_quorum(ncopies = dgit_copies)\n      [ncopies, dgit_copies].max/2 + 1\n    end\n\n    def dgit_git_daemon_port\n      @dgit_git_daemon_port ||= if Rails.development?\n                                  9418\n                                elsif Rails.test?\n                                  9420 + test_environment_number.to_i\n                                else # production\n                                  9419\n                                end\n    end\n    attr_writer :dgit_git_daemon_port\n\n    # The Gist hostname. No http:// prefix or protocol information is included.\n    #\n    # Returns the Gist hostname string (\"gist.github.com\"). Defaults to host_name.\n    def gist_host_name\n      @gist_host_name ||= host_name\n    end\n    attr_writer :gist_host_name\n\n    # The Gist 3 hostname. No http:// prefix or protocol information is included.\n    # Until we make the switch to Gist 3, we'll be running both side-by-side.\n    #\n    # Returns the Gist hostname string (\"gist.github.com\"). Defaults to host_name.\n    def gist3_host_name\n      @gist3_host_name ||= host_name\n    end\n    attr_writer :gist3_host_name\n\n    # Is Gist running under its own subdomain like gist.github.com? If not, that\n    # shits is served from <url>/gists.\n    def gist_domain?\n      gist_host_name != host_name\n    end\n\n    # Is Gist 3 running under its own subdomain like gist3.github.com? If not, that\n    # shits is served from <url>/gists.\n    def gist3_domain?\n      gist3_host_name != host_name\n    end\n\n    # Gist 3 OAuth Client credentials. Used for OAuth authentication in subdomain mode.\n    attr_accessor :gist3_oauth_client_id, :gist3_oauth_secret_key\n\n    # The Subversion / Slummin hostname. No http:// prefix or protocol\n    # information is included. By default, this is the configured host_name.\n    #\n    # Returns the hostname string (\"github.com\", \"stg.github.com\", etc)\n    def subversion_host_name\n      @subversion_host_name ||= \"#{host_name}\".freeze\n    end\n    attr_writer :subversion_host_name\n\n    # The GitHub users hostname. No http:// prefix or protocol information is\n    # included. By default, this is the configured host_name with a \"users.noreply.\"\n    # prefix.  This hostname is used for \"stealth\" emails.\n    #\n    # Returns the hostname string (ex: \"users.noreply.github.com\")\n    def stealth_email_host_name\n      @stealth_email_host_name ||= \"users.noreply.#{host_name}\".freeze\n    end\n    attr_writer :stealth_email_host_name\n\n    # The short name of the machine this process is currently executing on. Writing to\n    # this config value is not recommended.\n    def local_host_name_short\n      if GitHub.kube?\n        # 'kube-unknown' protects us from processes that didn't set the\n        # env var properly, and hopefully also is greppable to find this comment\n        long = ENV[\"KUBE_NODE_HOSTNAME\"] || \"kube-unknown\"\n      else\n        long = local_host_name\n      end\n      @local_host_name_short ||= long.split(\".\", 2).first\n    end\n    attr_writer :local_host_name_short\n\n    # The name of the machine this process is currently executing on.\n    # Explicitly set on Enterprise to the configured node name.\n    def local_host_name\n      @local_host_name ||= (require \"socket\"; Socket.gethostname)\n    end\n    attr_writer :local_host_name\n\n    # The role of the currently running process, request or job. Defaults to\n    # :unassigned as a catch all for when the role is not setup. This is\n    # explicitly set before web requests, background jobs, etc. to provide\n    # context of where an action is happening from (like a sql query).\n    # Keep it a Symbol so everyone knows what they are dealing with.\n    #\n    # Returns a Symbol of the currently set role for this process, request,\n    # background job, etc.\n    def role\n      @role ||= begin\n        from_env = ENV[\"GITHUB_CONFIG_ROLE\"]\n\n        if from_env.nil? || from_env.empty?\n          :unassigned\n        else\n          from_env.to_sym\n        end\n      end\n    end\n\n    # Get a role from the host's Sites API role. You might ask \"why isn't this\n    # the default for #role\"? Because there are a bunch of places where we used\n    # to set GITHUB_CONFIG_ROLE god config and it may or may not have been picked\n    # up by processes. In those cases, we need to be more explicit so that we\n    # don't accidentally have mixed metrics.\n    def role_from_host\n      host_app = server_metadata[\"app\"]\n      host_role = server_metadata[\"role\"]\n\n      if host_app == \"github\"\n        case host_role\n        when \"api\", \"codeload\", \"registryfe\", \"stafftools\", \"dfs\"\n          host_role.to_sym\n        when \"fe\"\n          if local_host_name.start_with?(\"github-fe\")\n            :fe\n          elsif local_host_name.start_with?(\"github-staff\")\n            :lab\n          else\n            :unassigned\n          end\n        when \"arch\"\n          :codeload\n        when \"staff\"\n          :lab\n        else\n          :unassigned\n        end\n      elsif host_app == \"pages\"\n        case host_role\n        when \"dfs\"\n          # pages-dfs's timerd is a github/github process\n          :pagesdfs\n        else\n          :unassigned\n        end\n      else\n        :unassigned\n      end\n    end\n\n    def role=(role)\n      GitHub.reset_dogstats\n      @role = role\n    end\n\n    def component\n      @component ||= begin\n        from_env = ENV[\"GITHUB_CONFIG_COMPONENT\"]\n\n        if from_env.nil? || from_env.empty?\n          :unassigned\n        else\n          from_env.to_sym\n        end\n      end\n    end\n\n    def component=(component)\n      GitHub.reset_dogstats\n      @component = component\n    end\n\n    # The domain of the machine this process is currently executing on. Writing\n    # to this config value is not recommended.\n    def domain_name\n      @domain_name ||= local_host_name.split(\".\", 2).last\n    end\n    attr_writer :domain_name\n\n    # The short domain of the machine this process is currently executing on.\n    # Writing to this config value is not recommended.\n    def domain_name_short\n      @domain_name_short ||= domain_name.split(\".\", 2).first\n    end\n    attr_writer :domain_name_short\n\n    # These local git, pages and storage host names are used to avoid setting\n    # the local partitions to `localhost`.\n    def local_git_host_name\n      @local_git_host_name || \"localhost\"\n    end\n    attr_writer :local_git_host_name\n\n    def local_pages_host_name\n      @local_pages_host_name || \"localhost\"\n    end\n    attr_writer :local_pages_host_name\n\n    def local_storage_host_name\n      @local_storage_host_name || \"localhost\"\n    end\n    attr_writer :local_storage_host_name\n\n    # PRs content hostname. No http:// prefix or protocol information is included.\n    # No default b/c Enterprise might not use a FQDN.\n    #\n    # Returns String host or nil.\n    attr_accessor :prs_content_host_name\n\n    # The PRs content site URL.\n    #\n    # production:  https://prs.githubusercontent.com\n    # garage:      https://prs-garage.githubusercontent.com\n    # development: http://prs.githubusercontent.dev\n    #\n    # Returns the URL string or nil.\n    def prs_content_host_url\n      @prs_content_host_url ||= prs_content_domain? ? \"#{scheme}://#{prs_content_host_name}\".freeze : nil\n    end\n    attr_writer :prs_content_host_url\n\n    # Should pr diffs/patches be served from its own subdomain like prs.githubusercontent.com?\n    def prs_content_domain?\n      !prs_content_host_name.to_s.empty?\n    end\n\n    ##\n    # URLs\n\n    # The main GitHub site URL. It returns\n    # the http:// or https:// version of the URL based on whether the #ssl\n    # attribute is set.\n    #\n    # Returns the URL string (\"https://github.com\", \"http://github.dev\")\n    def url\n      urls.url\n    end\n\n    # Help URL - Enterprise and production serve Help docs differently\n    #\n    # Returns the URL string (\"https://help.github.com\", \"http://help.github.com/enterprise\", etc.)\n    def help_url\n      if GitHub.enterprise?\n        \"#{enterprise_help_landing_page}/user\"\n      else\n        \"https://help.github.com\"\n      end\n    end\n\n    # Developer Help URL.\n    #\n    # Returns the URL string (\"https://developer.github.com\")\n    def developer_help_url\n      if GitHub.enterprise?\n        \"https://developer.github.com/enterprise/#{major_minor_version_number}\"\n      else\n        \"https://developer.github.com\"\n      end\n    end\n\n    # Enterprise Help Admin URL.\n    #\n    # Returns the URL string (\"https://help.github.com/enterprise/2.3/admin\")\n    def enterprise_admin_help_url\n      \"#{enterprise_help_landing_page}/admin\"\n    end\n\n    # Enterprise Help landing page URL.\n    #\n    # Returns the URL string (\"https://help.github.com/enterprise/2.3\")\n    def enterprise_help_landing_page\n      \"https://help.github.com/enterprise/#{major_minor_version_number}\"\n    end\n\n    # Guides URL\n    #\n    # Returns the URL string (\"https://guides.github.com\")\n    def guides_url\n      \"https://guides.github.com\"\n    end\n\n    # Update personal credit card Help URL\n    #\n    # Returns the URL string\n    def personal_cc_help_url\n      \"https://help.github.com/articles/updating-your-personal-account-s-credit-card\"\n    end\n\n    # Update organization credit card Help URL\n    #\n    # Returns the URL string\n    def org_cc_help_url\n      \"https://help.github.com/articles/updating-your-organization-s-credit-card\"\n    end\n\n    # Update personal paypal Help URL\n    #\n    # Returns the URL string\n    def personal_paypal_help_url\n      \"https://help.github.com/articles/updating-your-personal-account-s-paypal-information/\"\n    end\n\n    # Update organization paypal Help URL\n    #\n    # Returns the URL string\n    def org_paypal_help_url\n      \"https://help.github.com/articles/updating-your-organization-s-paypal-information\"\n    end\n\n    # The meta schema for the GitHub API.\n    #\n    # Return a string path.\n    def api_schema_meta_path\n      Rails.root.join(\"app/api/schema.json\")\n    end\n\n    # The directory containing subschemas for the GitHub API.\n    #\n    # Return a string path.\n    def api_subschema_dir\n      Rails.root.join(\"app/api/schemas/v3/schemas\")\n    end\n\n    # Enable rate limiting. Disabled by default in development and Enterprise.\n    # override defaults with the RATE_LIMITING environment variable.\n    def rate_limiting_enabled?\n      return @rate_limiting_enabled if defined?(@rate_limiting_enabled)\n      @rate_limiting_enabled = ENV[\"RATE_LIMITING\"] ||\n        (!Rails.development? && !enterprise?)\n    end\n    attr_writer :rate_limiting_enabled\n\n    def apps_enabled?\n      return @apps_enabled if defined?(@apps_enabled)\n      @apps_enabled = !GitHub.enterprise?\n    end\n    attr_writer :apps_enabled\n\n    # The asset host root URL. This defaults to url and is typically\n    # overridden in production environments to enable asset loading from a\n    # CDN / separate domain.\n    #\n    # May return \"\" if assets are served from the same domain.\n    #\n    # Returns the string URL (\"https://blah.cloudfront.net\", \"\", etc)\n    def asset_host_url\n      @asset_host_url ||= url\n    end\n\n    # Allow asset_host_url to be set as just a hostname.\n    def asset_host_url=(url)\n      if url.nil? || url == \"\"\n        url = \"\"\n      elsif url && url !~ /^https?:/\n        url = \"#{scheme}://#{url}\"\n      end\n      @asset_host_url = url\n    end\n\n    # The braintree gateway URL, for #csp_connect_sources\n    def braintreegateway_url\n      @braintreegateway_url ||= if Rails.env.production?\n        \"https://api.braintreegateway.com\"\n      else\n        \"https://api.sandbox.braintreegateway.com\"\n      end\n    end\n\n    # The braintree analytics URL, for #csp_connect_sources\n    def braintree_analytics_url\n      @braintree_analytics_url ||= if Rails.env.production?\n        \"https://client-analytics.braintreegateway.com\"\n      else\n        \"https://client-analytics.sandbox.braintreegateway.com\"\n      end\n    end\n\n    # The paypal checkout URL for paypal button images, for #csp_image_sources\n    def paypal_checkout_url\n      @paypal_checkout_url ||= \"https://checkout.paypal.com\"\n    end\n\n    # The asset host to use for all email assets.\n    #\n    # GitHub.asset_host_url may be nil or blank when assets should be served from\n    # the same origin. The mailer asset host is never blank and will fallback to\n    # the full origin url.\n    #\n    # development: http://github.dev\n    # production:  https://assets-cdn.github.com\n    # labs:        https://foo.review-lab.github.com\n    #\n    # Always returns a full URL String.\n    def mailer_asset_host_url\n      if asset_host_url.present?\n        asset_host_url\n      else\n        url\n      end\n    end\n\n    # This returns the identicons host used to fetch the identicons avatar.\n    #\n    # Returns identicon hostname as a string. This string requires\n    # a '/' for joining with path parts.\n    def identicons_host\n      @identicons_host ||= if GitHub.enterprise?\n                             GitHub.url\n                           else\n                            \"https://identicons.github.com\"\n                           end\n    end\n    attr_writer :identicons_host\n\n    # This returns the identicons host used by the internal api.\n    #\n    # Returns identicon hostname as a string. This string requires\n    # a '/' for joining with path parts.\n    def internal_identicons_host\n      @internal_identicons_host ||= if GitHub.enterprise?\n                                      GitHub.url\n                                    else\n                                      \"identicon:\"\n                                    end\n    end\n    attr_writer :internal_identicons_host\n\n    # The octolytics image host URL (hosted on a CDN), for #csp_img_sources\n    def octolytics_collector_url\n      if octolytics_collector_host\n        \"#{scheme}://#{octolytics_collector_host}\"\n      end\n    end\n\n    # The hostname of the CDN that hosts the octolytics JavaScript files\n    def octolytics_collector_script_host\n      @octolytics_collector_script_host ||=\n        octolytics_collector_host ?\n          (Rails.env.production? ? \"collector-cdn.github.com\" : octolytics_collector_host) :\n          nil\n    end\n\n    # The internal hostname for octolytics_collector. This should be used to\n    # send events from inside the GitHub network to avoid transiting the\n    # internet. Note the octolytics gem requires https for non-dev environments.\n    #\n    # Defaults to octolytics_collector_host.\n    def octolytics_collector_internal_host\n      @octolytics_collector_internal_host ||= octolytics_collector_host\n    end\n\n    # The internal Hookshot hostname.\n    #\n    # Returns the URL string.\n    attr_accessor :hookshot_url, :staging_hookshot_url, :hookshot_admin_url\n    attr_accessor :hookshot_path\n\n    # Secret token for the Hookshot endpoint: \"/hooks/:guid/:id\"\n    attr_writer :hookshot_token\n\n    def hookshot_token\n      @hookshot_token ||= \"1c70a1739cf49abce047a089b7967166\"\n    end\n\n    # The OauthApplication#id for porter.\n    def porter_app_id\n      @porter_app_id ||=\n        if app = OauthApplication.where(user_id: trusted_oauth_apps_owner, name: \"GitHub Importer\").first\n          app.id\n        else\n          nil\n        end\n      if @porter_app_id.nil? && (Rails.env.development? || Rails.env.test?)\n        OauthApplication::PERSONAL_TOKENS_APPLICATION_ID\n      else\n        @porter_app_id\n      end\n    end\n    attr_writer :porter_app_id\n\n    # The URL template of an import in porter.\n    attr_accessor :porter_url_template\n\n    # The URL template of an import's stafftools in porter.\n    attr_accessor :porter_repository_admin_url_template\n\n    # The URL template of an users's stafftools in porter.\n    attr_accessor :porter_user_admin_url_template\n\n    # The token that unlocks the internal admin URLs.\n    def porter_internal_api_token\n      @porter_internal_api_token || \"porter-development-token\"\n    end\n    attr_writer :porter_internal_api_token\n\n    # Returns true if porter is configured.\n    def porter_available?\n      porter_url_template.present? &&\n        porter_repository_admin_url_template.present? &&\n        porter_user_admin_url_template.present? &&\n        !enterprise?\n    end\n\n    # Valid \"flavors\" of the `/contact` form\n    #\n    # Returns an Hash in the form of flavor-key => title\n    def contact_form_flavors\n      @contact_form_flavors ||= if enterprise?\n        {\n          \"default\" => \"Get help with GitHub\"\n        }\n      else\n        {\n          \"default\"              => \"Get help with GitHub\",\n          \"report-abuse\"         => \"Report abuse\",\n          \"dmca\"                 => \"Copyright claims (DMCA)\",\n          \"dmca-notice\"          => \"DMCA takedown notice\",\n          \"dmca-counter-notice\"  => \"DMCA counter notice\",\n          \"privacy\"              => \"Report a privacy issue\",\n          \"terms-of-service\"     => \"New Terms of Service feedback\"\n        }\n      end\n    end\n\n    # GitHub's physical office address for inclusion into\n    # email footers, invoices, legal docs, etc.\n    #\n    # multiline - true or false.\n    #\n    # Returns an Array if multiline. Returns a String otherwise.\n    def physical_address(multiline: false)\n      address_parts = [\"GitHub, Inc. 88 Colin P Kelly Jr Street\", \"San Francisco, CA 94107\"]\n      multiline ? address_parts : address_parts.join(\", \")\n    end\n\n    # Email for Marketplace messages\n    #\n    # Returns the email String.\n    def marketplace_email\n      @marketplace_email = \"marketplace@github.com\"\n    end\n    attr_writer :marketplace_email\n\n    # Email for sending out user engagement and learning materials\n    #\n    # Returns the email String.\n    def guides_email\n      @guides_email = \"guides@github.com\"\n    end\n    attr_writer :guides_email\n\n    # Email for business development\n    #\n    # Returns the email string\n    def partnerships_email\n      @partnerships_email = \"partnerships@github.com\"\n    end\n    attr_writer :partnerships_email\n\n    ##\n    # Resque config\n\n    # A prefix used for all resque queues. Used to segregate workers in lab\n    # on staff1.\n    #\n    # Returns a string prefix if set, otherwise the empty string.\n    def resque_queue_prefix\n      @resque_queue_prefix ||= \"\"\n    end\n    attr_writer :resque_queue_prefix\n\n    # Resident memory limit for resque worker processes. If memory usage exceeds\n    # this value after a job is performed the process is shut down so that a\n    # fresh process can take its place.\n    #\n    # Returns the memory limit in bytes or nil to signify no limit.\n    def resque_graceful_memory_limit\n      if defined?(@resque_graceful_memory_limit)\n        @resque_graceful_memory_limit\n      else\n        @resque_graceful_memory_limit = nil\n      end\n    end\n    attr_writer :resque_graceful_memory_limit\n\n    # Number of resque jobs to retry each pass through the retry queue.\n    #\n    # Returns an Integer.\n    def resque_retry_quantity\n      if config_max_string = GitHub.environment[\"RESQUE_RETRY_QUANTITY\"]\n        config_max = begin\n          Integer(config_max_string)\n        rescue ArgumentError => e\n          err = e.exception(\"RESQUE_RETRY_QUANTITY must be an Integer encoding\")\n          err.set_backtrace(caller)\n          Failbot.report!(err)\n          nil\n        end\n        return config_max unless config_max.nil?\n      end\n      return 100 * 100\n    end\n\n    # The camo image proxy URL. This is used to rewrite HTTP <img> tag URLs left\n    # in user content (like comments and issue bodies) through the SSL image\n    # proxy, avoiding browser mixed content warnings.\n    #\n    # This value defaults to the <asset_host_url>/img when not set explicitly.\n    #\n    # Returns the image proxy root URL string.\n    #\n    # See Also:\n    #   https://github.com/atmos/camo\n    #   https://github.com/github/camo\n    def image_proxy_url\n      @image_proxy_url ||= \"#{asset_host_url}/img\".freeze\n    end\n    attr_writer :image_proxy_url\n\n    # The secret token key used to sign generated image proxy URLs.\n    #\n    # Returns the key as a String, or nil when no secret is set.\n    attr_accessor :image_proxy_key\n\n    # Determine whether img URLs should be rewritten through the camo image\n    # proxy. This defaults to true when SSL is enabled and the\n    # image_proxy_key value is set.\n    #\n    # Returns true when img URLs should be rewritten, false otherwise.\n    def image_proxy_enabled?\n      ssl? && image_proxy_key\n    end\n\n    # Domains who'se images will not be proxied through camo when used in user\n    # content.\n    def image_proxy_host_whitelist\n      @image_proxy_host_whitelist ||= begin\n        hosts = []\n\n        # Allow any github.com image references. This needs to be cleaned up\n        # if we want to remove 'self' from CSP img-src.\n        hosts << host_name\n\n        # Allow any references to *.githubusercontent.com sources.\n        if user_content_host_name && user_content_host_name != host_name\n          hosts << Regexp.new(Regexp.escape(user_content_host_name) + \"\\\\z\")\n        end\n\n        hosts\n      end\n    end\n\n    # Should external images be allowed to be loaded as subresouces outside\n    # of our whitelisted set?\n    #\n    # Enabling this enforces the img-src CSP.\n    #\n    # Requires Camo image proxy configuration.\n    def restrict_external_images?\n      return @restrict_external_images if defined?(@restrict_external_images)\n      @restrict_external_images = true\n    end\n    attr_writer :restrict_external_images\n\n    # Should we included our whitelisted set of third party connect hosts in our\n    # connect-src CSP directive?\n    #\n    # Enabling this results in a set of whitelisted third party hosts being\n    # added to the connect-src CSP directive.\n    def allow_third_party_connect_sources?\n      return @allow_third_party_connect_sources if defined?(@allow_third_party_connect_sources)\n      @allow_third_party_connect_sources = true\n    end\n    attr_writer :allow_third_party_connect_sources\n\n    # Should we pin the certificate authority root certificates that are allowed\n    # to sign GitHub certificates? As of now this only makes sense on dotcom, as\n    # we only use Digicert and Verisign(Symantec) extended validation certificates. On any\n    # other environment (enterprise, development, test, etc) this option should\n    # be `false`.\n    #\n    # Enabling this results in a set of whitelisted certificate authorities\n    # being added to the Public-Key-Pins header policy.\n    def public_key_pinning_enabled?\n      return @public_key_pinning_enabled if defined?(@public_key_pinning_enabled)\n      @public_key_pinning_enabled = false\n    end\n    attr_writer :public_key_pinning_enabled\n\n    ##\n    # Gist\n\n    # Gist is enabled by default at /gist and can be run under a subdomain by\n    # setting the Gist.host_name option. Explicitly disabling gist by setting\n    # this option false removes all links in the UI.\n    def gist_enabled\n      return @gist_enabled if defined?(@gist_enabled)\n      @gist_enabled = true\n    end\n    alias gist_enabled? gist_enabled\n    attr_writer :gist_enabled\n\n    # The main gist raw URL. This value typically isn't written directly but\n    # should be read anywhere the raw URL for gist is required. It returns the\n    # http:// or https:// version of the raw URL based on whether the #ssl attribute\n    # is set.\n    #\n    # Returns the gist raw URL string (\"https://gist.githubusercontent.com\",\n    # \"http://gist.github.dev\", etc)\n    def gist_raw_url\n      ssl? ? gist_raw_https_url : gist_url\n    end\n\n    # The main gist site URL. This value typically isn't written directly but\n    # should be read anywhere the root URL for gist is required. It returns the\n    # http:// or https:// version of the URL based on whether the #ssl attribute\n    # is set.\n    #\n    # Returns the gist URL string (\"https://gist.github.com\",\n    # \"http://gist.github.dev\", etc)\n    def gist_url\n      ssl? ? gist_https_url : gist_http_url\n    end\n\n    # The non-SSL http version of the Gist URL. Not typically used directly. Use\n    # gist_url instead so that http vs. https is determined dynamically.\n    def gist_http_url\n      if gist_domain?\n        \"http://#{gist_host_name}\".freeze\n      else\n        \"#{url}/gist\"\n      end\n    end\n\n    # The https version of the Gist URL. Not typically used directly. Use\n    # gist_url instead so that http vs. https is determined dynamically.\n    def gist_https_url\n      if gist_domain?\n        \"https://#{gist_host_name}\".freeze\n      else\n        \"#{url}/gist\"\n      end\n    end\n\n    # The https version of the raw Gist URL. Not typically used directly. Use\n    # gist_raw_url instead so that http vs. https is determined dynamically.\n    def gist_raw_https_url\n      if gist_domain?\n        \"https://gist.#{GitHub.user_content_host_name}\".freeze\n      else\n        gist_https_url\n      end\n    end\n\n    # The URL to GitHub's graphite instance.\n    attr_accessor :graphite_url\n\n    # The URL of the Graphme app.\n    attr_accessor :graphme_url\n\n    ##\n    # Caching\n\n    # View fragment cache prefix.\n    #\n    # Bump this to expire all view caches.\n    def fragment_cache_version\n      :views10\n    end\n\n    # Cache key for task lists\n    #\n    # Bump this if task list rendering has changed and you need to\n    # expire any cached items w/ task lists\n    def task_list_cache_version\n      :task_list_1\n    end\n\n    # Ajax Poller version\n    #\n    # Bumping this will kill any active poller clients.\n    #\n    # See also ajax_poll.coffee\n    def ajax_poller_version\n      \"2\"\n    end\n\n    def audit_log_export_enabled?\n      !GitHub.enterprise?\n    end\n\n    ##\n    # elasticsearch\n\n    # Internal: Indicates the configured level of access to Elasticsearch.\n    #\n    # Allows ENV config to define what level of access to Elasticsearch is\n    # available. ENV[\"ELASTICSEARCH_ACCESS\"] can be set to one of:\n    #   allowed - Default, all Elasticsearch functionality is available.\n    #   ignored - A \"soft\" disable: the app will do its best to not issue\n    #             queries, and will try to display user-friendly error messages\n    #             when possible.\n    #   raises  - All Elasticsearch access is disabled, and any attempts to\n    #             use it will result in an exception.\n    #\n    # The \"ignored\" mode is intended for site recovery in a secondary datacenter\n    # rather than as a general control rod for normal operation. The \"raises\"\n    # mode is intended for deployment in a read-only datacenter when ES indexes\n    # are not available, and where any requests to search indexes are explicitly\n    # not supported.\n    #\n    # Returns the currently configured mode as a symbol.\n    # Raises TypeError if an invalid mode is configured.\n    def elasticsearch_access\n      if !defined?(@elasticsearch_access)\n        value = GitHub.environment[\"ELASTICSEARCH_ACCESS\"] || \"allowed\"\n        self.elasticsearch_access = value.to_sym\n      end\n      @elasticsearch_access\n    end\n\n    # Set the access level for Elasticsearch. Used by an enterprise setup script\n    # as well as the test suite.\n    #\n    # Raises TypeError if an invalid mode is provided.\n    def elasticsearch_access=(mode)\n      if ELASTICSEARCH_ACCESS_VALUES.include?(mode)\n        @elasticsearch_access = mode\n      else\n        raise TypeError, \"Invalid elasticsearch access mode: #{mode.inspect}\"\n      end\n    end\n\n    # FIXME rename\n    # Convenience query methods for determining elasticsearch_access levels:\n    def elasticsearch_access_allowed?\n      elasticsearch_access == :allowed\n    end\n\n    def elasticsearch_access_ignored?\n      elasticsearch_access == :ignored\n    end\n\n    def elasticsearch_access_raises?\n      elasticsearch_access == :raises\n    end\n\n    # The elasticsearch http host and port. This is actually hitting HA Proxy which\n    # will load-balance across the cluster.\n    attr_accessor :elasticsearch_host\n\n    # The elasticsearch host to use for audit logs.\n    attr_accessor :elasticsearch_audit_log_host\n\n    # Returns the URL (as a String) for communicating with ElasticSearch or\n    # `nil` if the elasticsearch_host has not been set.\n    def elasticsearch_url\n      elasticsearch_host ? \"http://#{elasticsearch_host}\" : nil\n    end\n\n    # The elasticsearch query timeout.\n    def es_query_timeout\n      @es_query_timeout ||= \"250ms\"\n    end\n    attr_writer :es_query_timeout\n\n    # The elasticsearch cluster to use for audit logs.\n    def es_audit_log_cluster\n      @es_audit_log_cluster ||= \"default\"\n    end\n    attr_writer :es_audit_log_cluster\n\n    # The Hash containing the name / URL mapping for the available\n    # ElasticSearch clusters.\n    def es_clusters\n      @es_clusters ||= {}\n    end\n\n    # The number of shards to use when creating the `audit_log` index.\n    def es_shard_count_for_audit_log\n      @es_shard_count_for_audit_log ||= 1\n    end\n    attr_writer :es_shard_count_for_audit_log\n\n    # The number of shards to use when creating the `code_search` index.\n    def es_shard_count_for_code_search\n      @es_shard_count_for_code_search ||= 1\n    end\n    attr_writer :es_shard_count_for_code_search\n\n    # The number of shards to use when creating the `commits` index.\n    def es_shard_count_for_commits\n      @es_shard_count_for_commits ||= 1\n    end\n    attr_writer :es_shard_count_for_commits\n\n    # The number of shards to use when creating the `issues` index.\n    def es_shard_count_for_issues\n      @es_shard_count_for_issues ||= 1\n    end\n    attr_writer :es_shard_count_for_issues\n\n    # The number of shards to use when creating the `issues` index.\n    def es_shard_count_for_pull_requests\n      @es_shard_count_for_pull_requests ||= 1\n    end\n    attr_writer :es_shard_count_for_pull_requests\n\n    # The number of shards to use when creating the `repos` index.\n    def es_shard_count_for_repos\n      @es_shard_count_for_repos ||= 1\n    end\n    attr_writer :es_shard_count_for_repos\n\n    # The number of shards to use when creating the `users` index.\n    def es_shard_count_for_users\n      @es_shard_count_for_users ||= 1\n    end\n    attr_writer :es_shard_count_for_users\n\n    # The number of shards to use when creating the `blog` index.\n    def es_shard_count_for_blog\n      @es_shard_count_for_blog ||= 1\n    end\n    attr_writer :es_shard_count_for_blog\n\n    # The number of shards to use when creating the `blog` index.\n    def es_shard_count_for_showcases\n      @es_shard_count_for_showcases ||= 1\n    end\n    attr_writer :es_shard_count_for_showcases\n\n    # The number of shards to use when creating the `gists` index.\n    def es_shard_count_for_gists\n      @es_shard_count_for_gists ||= 1\n    end\n    attr_writer :es_shard_count_for_gists\n\n    # The number of shards to use when creating the `job_postings` index.\n    def es_shard_count_for_job_postings\n      @es_shard_count_for_job_postings ||= 1\n    end\n    attr_writer :es_shard_count_for_job_postings\n\n    # The number of shards to use when creating the `locations` index.\n    def es_shard_count_for_locations\n      @es_shard_count_for_locations ||= 1\n    end\n    attr_writer :es_shard_count_for_locations\n\n    # The number of shards to use when creating the `wikis` index.\n    def es_shard_count_for_wikis\n      @es_shard_count_for_wikis ||= 1\n    end\n    attr_writer :es_shard_count_for_wikis\n\n    # The number of shards to use when creating the `projects` index.\n    def es_shard_count_for_projects\n      @es_shard_count_for_projects ||= 1\n    end\n    attr_writer :es_shard_count_for_projects\n\n    # The number of shards to use when creating the `non_marketplace_listings` index.\n    def es_shard_count_for_non_marketplace_listings\n      @es_shard_count_for_non_marketplace_listings ||= 1\n    end\n    attr_writer :es_shard_count_for_non_marketplace_listings\n\n    # The number of shards to use when creating the `marketplace_listings` index.\n    def es_shard_count_for_marketplace_listings\n      @es_shard_count_for_marketplace_listings ||= 1\n    end\n    attr_writer :es_shard_count_for_marketplace_listings\n\n    # The number of shards to use when creating the `registry_packages` index.\n    def es_shard_count_for_registry_packages\n      @es_shard_count_for_registry_packages ||= 1\n    end\n    attr_writer :es_shard_count_for_registry_packages\n\n    # The number of replicas to maintain for each search index.\n    def es_number_of_replicas\n      @es_number_of_replicas ||= 1\n    end\n    attr_writer :es_number_of_replicas\n\n    # The read timeout for Elasticsearch connections in seconds.\n    # Defaults to 7 seconds.\n    def es_read_timeout\n      @es_read_timeout ||= 7\n    end\n    attr_writer :es_read_timeout\n\n    # The connection open timeout for Elasticsearch connections in seconds.\n    # Defaults to 2 seconds.\n    def es_open_timeout\n      @es_open_timeout ||= 2\n    end\n    attr_writer :es_open_timeout\n\n    # The maximum file size that we will index in the code-search index. Source\n    # code files larger than this limit will _not_ have their contents indexed\n    # and searchable. Other meta-data about the source code files (filename,\n    # extension, language, etc) will still be searchable.\n    def es_max_doc_size\n      @es_max_doc_size ||= 384*1024  # 384KB\n    end\n    attr_writer :es_max_doc_size\n\n    # Flag indicating whether codeload is available in this environment. This\n    # is currently set true in the Enterprise chef cookbooks.\n    #\n    # Returns true if codeload is available.\n    def codeload_enabled?\n      @codeload_enabled ||= !enterprise?\n    end\n    attr_writer :codeload_enabled\n\n    ##\n    # Subversion\n\n    # The Subversion / Slummin root URL. This value typically isn't written\n    # directly but should be read anywhere the root URL for the subversion\n    # server is required. It returns the http:// or https:// version of the\n    # URL based on whether the #ssl config attribute is set.\n    #\n    # Returns the svn URL string (\"https://svn.github.com\",\n    # \"http://svn.github.dev\", etc)\n    def subversion_url\n      @subversion_url ||= \"#{scheme}://#{subversion_host_name}\".freeze\n    end\n    attr_writer :subversion_url\n\n    ##\n    # Pages\n\n    # Flag indicating whether Pages are available in this environment. This is\n    # disabled by default under FI environments but enabled everywhere else.\n    #\n    # Returns true if pages are enabled, false otherwise.\n    def pages_enabled?\n      return @pages_enabled if defined?(@pages_enabled)\n      @pages_enabled = true\n    end\n    attr_writer :pages_enabled\n\n    # Root directory where fully-built Pages sites are served from. This\n    # defaults to the tmp/pages directory under RAILS_ROOT, but is typically\n    # overridden in production environments.\n    #\n    # Returns the full path to the Pages directory as a String.\n    def pages_dir\n      @pages_dir ||=\n        if Rails.test?\n          File.expand_path(\"#{Rails.root}/tmp/pages#{test_environment_number}\").freeze\n        else\n          File.expand_path(\"#{Rails.root}/tmp/pages\").freeze\n        end\n    end\n    attr_writer :pages_dir\n\n    # Temporary directory where Pages sites are built before being copied to the\n    # pages_dir. This defaults to the tmp/pagebuild/<environment> directory, but\n    # is typically overridden in production environments.\n    #\n    # Returns the full path to the Pages build directory as a String.\n    def pages_build_dir\n      @pages_build_dir ||=\n        if Rails.test?\n          File.expand_path(\"#{Rails.root}/tmp/pagebuild/#{Rails.env}#{test_environment_number}\").freeze\n        else\n          File.expand_path(\"#{Rails.root}/tmp/pagebuild/#{Rails.env}\").freeze\n        end\n    end\n    attr_writer :pages_build_dir\n\n    # Location of Pages jekyll command. This is overriden in development\n    # environments.\n    def pages_jekyll_bin\n      @pages_jekyll_bin ||= \"/data/pages-jekyll/bin/jekyll\"\n    end\n    attr_writer :pages_jekyll_bin\n\n    # The maximum size of a built pages site in bytes. Set to 0 to disable\n    # the size limit.\n    def pages_site_size_limit\n      @pages_site_size_limit ||= (10 * 1024 * 1024 * 1024) # 10 GB\n    end\n    attr_writer :pages_site_size_limit\n\n    # ID of the GitHub Pages Oauth App\n    #\n    # Returns int ID the application ID, or nil if app doesn't exist\n    def pages_app_id\n      @pages_app_id ||= OauthApplication.where(\n        :user_id => trusted_oauth_apps_owner,\n        :name    => \"GitHub Pages\"\n      ).pluck(:id).first\n    end\n    attr_writer :pages_app_id\n\n    def pages_replica_count\n      @pages_replica_count ||= Rails.production? ? 3 : 1\n    end\n    attr_writer :pages_replica_count\n\n    # Gets the number of readonly replicas that are included in a page build,\n    # but not required for a successful consensus.\n    attr_accessor :pages_non_voting_replica_count\n\n    # Do we support custom pages CNAMEs in this environment?\n    #\n    # When custom CNAMEs are enabled, pages sites are served from\n    # USERNAME.github.io, or a custom domain the user provides in a `CNAME` file.\n    #\n    # When custom CNAMEs are disabled, pages sites are served from\n    # /pages/USERNAME/REPO and any `CNAME` file is ignored.\n    #\n    def pages_custom_cnames?\n      !enterprise?\n    end\n\n    def site_status_url\n      \"https://status.github.com\"\n    end\n\n    def show_site_status?\n      !enterprise?\n    end\n\n    ##\n    # Google Analytics\n\n    # The Google Analytics account in \"UA-XXXXXXX-X\" form. This is used in the\n    # JavaScript tracking code inserted into pages with analytics enabled.\n    attr_accessor :analytics_account\n    attr_accessor :gist_analytics_account\n\n    # Determine if Google Analytics tracking information should be inserted into\n    # page output. Analytics tracking is considered on if the analytics_account\n    # attribute is set.\n    #\n    # Returns true if tracking is enabled, false otherwise.\n    def analytics_enabled?\n      !analytics_account.nil?\n    end\n\n    # Get base URL for Google Analytics.\n    #\n    # Returns String URL or nil if Google Analytics is disabled.\n    def google_analytics_url\n      if analytics_enabled?\n        \"#{scheme}://www.google-analytics.com\"\n      end\n    end\n\n    # Third party hosts being added to the connect-src CSP directive.\n    #\n    # Needs to be enabled via allow_third_party_connect_sources.\n    #\n    # IMPORTANT!!! CC @github/dotcom-security if you need to change this.\n    def third_party_connect_sources\n      return @third_party_connect_sources if defined?(@third_party_connect_sources)\n\n      @third_party_connect_sources = [\n        google_analytics_url,\n        \"https://github-cloud.s3.amazonaws.com\",\n        \"https://#{RepositoryFile.storage_s3_new_bucket_host}\",\n        \"https://#{UploadManifestFile.storage_s3_new_bucket_host}\",\n        \"https://#{UserAsset.storage_s3_new_bucket_host}\",\n      ].freeze\n    end\n\n    # Custom setter to freeze the Object before setting it,\n    # to prevent future modifications.\n    def third_party_connect_sources=(sources)\n      @third_party_connect_sources = Array(sources).freeze\n    end\n\n    # LiveReload server URL that is added to the connect-src CSP directive in development.\n    def livereload_url\n      \"ws://127.0.0.1:35729/livereload\".freeze if Rails.development?\n    end\n\n    ##\n    # Octolytics, the new traffic analyisis tool.\n    # App ID\n    attr_accessor :octolytics_app_id\n    # Collector host for external clients\n    attr_accessor :octolytics_collector_host\n    # Collector host for internal clients (inside the GitHub network)\n    attr_writer   :octolytics_collector_internal_host\n    # Secret, for signing content that passes through the browser (e.g. the user id).\n    attr_accessor :octolytics_secret\n    # What octolytics environment should be used to pull report data from.\n    attr_accessor :octolytics_reporter_env\n    # Gist App ID\n    attr_accessor :gist_octolytics_app_id\n    # Gist Secret, for signing content that passes through the browser (e.g. the user id).\n    attr_accessor :gist_octolytics_secret\n\n    # Returns true if tracking on analytics is configured, false otherwise.\n    def octolytics_enabled?\n      !!octolytics_collector_host\n    end\n\n    ##\n    # Pond\n    attr_accessor :pond_shared_secret\n\n    # The Google Analytics username and password. This is used to fetch traffic\n    # data for specific repositories only.\n    attr_accessor :analytics_user\n    attr_accessor :analytics_pass\n\n    ##\n    # Twitter\n\n    # The Twitter OAuth access key as a String.\n    attr_accessor :twitter_key\n\n    # The Twitter OAuth secret key as a String.\n    attr_accessor :twitter_secret\n\n    ##\n    # Billing/Braintree\n\n    # Determine whether billing is enabled. Typically disabled under\n    # the enterprise environment. Enable via `gh-config` by setting\n    # BILLING_ENABLED to `1`, and disable with `0`. Defaults to true if\n    # no value is set.\n    #\n    # Returns true if billing is enabled, false otherwise.\n    def billing_enabled?\n      return false if enterprise?\n      return @billing_enabled if defined?(@billing_enabled)\n      @billing_enabled = ENV.fetch(\"BILLING_ENABLED\", \"1\") == \"1\"\n    end\n    attr_writer :billing_enabled\n\n    # Determine whether we want to make a request to Braintree for a client token use in PayPal\n    # forms. Usually false for the :test environment.\n    #\n    # Returns true if client tokens are enabled\n    def braintree_client_token_enabled?\n      billing_enabled? && @braintree_client_token_enabled\n    end\n    attr_accessor :braintree_client_token_enabled\n\n    # Determine the plan name assigned to users by default. Usually set to\n    # \"enterprise\" under enterprise or \"free\" for others.\n    #\n    # See also GitHub::Plan and User#plan.\n    #\n    # Returns the String plan name.\n    def default_plan_name\n      return @default_plan_name if defined?(@default_plan_name)\n      @default_plan_name =\n        if enterprise?\n          GitHub::Plan::ENTERPRISE\n        else\n          GitHub::Plan::FREE\n        end\n    end\n    attr_writer :default_plan_name\n\n    # Restrict signup to the default plan when enabled. Enabled by default\n    # under FI environments, disabled everywhere else.\n    #\n    # Returns true if enabled, false otherwise.\n    def enforce_default_plan?\n      return @enforce_default_plan if defined?(@enforce_default_plan)\n      @enforce_default_plan = enterprise?\n    end\n    attr_writer :enforce_default_plan\n\n    # Braintree configuration.\n    attr_accessor :braintree_environment\n    attr_accessor :braintree_merchant_id\n    attr_accessor :braintree_public_key\n    attr_accessor :braintree_private_key\n    attr_accessor :braintree_logger\n    attr_accessor :braintree_client_side_encryption_key\n\n    # Open Exchange Rates\n    attr_accessor :open_exchange_rates_app_id\n\n    ##\n    # NetSuite\n\n    # Netsuite login and account information.\n    attr_accessor :netsuite_login_email\n    attr_accessor :netsuite_password\n    attr_accessor :netsuite_account\n    attr_accessor :netsuite_role\n\n    # Ghost user login used to replace associated users of Issues-related\n    # records (Issue, IssueComment and IssueEvent) when the original user\n    # is deleted.\n    #\n    # Returns the String ghost User login.\n    def ghost_user_login\n      @ghost_user_login ||= \"ghost\"\n    end\n\n    # Staff user login used to be the actor for staff events\n    #\n    # Returns the String staff User login\n    def staff_user_login\n      @staff_user_login ||= \"github-staff\"\n    end\n\n    ##\n    # Authentication\n\n    attr_accessor :cas_url\n\n    attr_accessor :ldap_host, :ldap_port, :ldap_base,\n                  :ldap_bind_dn, :ldap_password, :ldap_method,\n                  :ldap_search_strategy,\n                  :ldap_virtual_attributes, :ldap_virtual_attribute_member,\n                  :ldap_recursive_group_search_fallback,\n                  :ldap_posix_support,\n                  :ldap_sync_enabled,\n                  :ldap_user_sync_emails, :ldap_user_sync_keys, :ldap_user_sync_gpg_keys,\n                  :ldap_profile_uid, :ldap_profile_name, :ldap_profile_mail,\n                  :ldap_profile_key, :ldap_profile_gpg_key\n\n    attr_accessor :saml_sso_url,           # idP http endpoint for sso. We redirect to here with an AuthnRequest.\n                  :saml_idp_initiated_sso, # if this is on, responses will not be checked for corresponding requests\n                  :saml_disable_admin_demote, # if this is on, admin bit is ignored and users won't promoted or demoted.\n                  :saml_issuer,            # idP issuer. Used to validate responses\n                  :saml_name_id_format,    # NameID format to use, (:persistent or unspecified). Unspecified should be discouraged\n                  :saml_certificate_file,  # idP certificate. Public key to validate idP responses.\n                  :saml_signature_method,  # algorithm to use for AuthnRequest signatures.\n                  :saml_digest_method,     # algotithm to use for AuthnRequest digests.\n                  :saml_sp_pkcs12_file,    # SP keypair for signing AuthnRequests and Metadata.\n                  :saml_admin,             # attribute name in saml response for promoting/demoting admins. Default: 'administrator'\n                  :saml_username_attr,      # attribute username in saml response for account login name. Default: 'NameID'\n                  :saml_profile_name,      # attribute name in saml response for user full name. Default: 'full_name'\n                  :saml_profile_mail,      # attribute name in saml response for user emails. Default: 'emails'\n                  :saml_profile_ssh_key,       # attribute name in saml response for user public keys. Default: 'public_keys'\n                  :saml_profile_gpg_key    # attribute name in saml response for user GPG keys. Default: 'gpg_keys'\n\n    # Public: Returns the verify_mode value used for SSL communications with\n    # LDAP server.\n    #\n    # See http://ruby-doc.org/stdlib/libdoc/openssl/rdoc/OpenSSL/SSL/SSLContext.html#verify_mode\n    # for available verify_mode values\n    def ldap_tls_verify_mode\n      @ldap_tls_verify_mode ||= OpenSSL::SSL::VERIFY_NONE\n    end\n\n    # Public: Sets the TLS verification mode. Value is expected to be an integer\n    #\n    # See http://ruby-doc.org/stdlib/libdoc/openssl/rdoc/OpenSSL/SSL/SSLContext.html#verify_mode\n    # for available verify_mode values\n    def ldap_tls_verify_mode=(verify_mode)\n      @ldap_tls_verify_mode = verify_mode.to_i\n    end\n\n    # Public: Returns true when LDAP authentication is configured and LDAP Sync is enabled.\n    # Managed via enterprise-manage.\n    def ldap_sync_enabled?\n      auth.ldap? && ldap_sync_enabled\n    end\n\n    # Public: Returns true if Emails are LDAP Synced.\n    def user_sync_emails?\n      ldap_sync_enabled? && ldap_user_sync_emails\n    end\n\n    # Public: Returns true if SSH Keys are LDAP Synced.\n    def user_sync_keys?\n      ldap_sync_enabled? && ldap_user_sync_keys\n    end\n\n    # Public: Returns true if SSH Keys are LDAP Synced.\n    def user_sync_gpg_keys?\n      ldap_sync_enabled? && ldap_user_sync_gpg_keys\n    end\n\n    # Authentication adapter options hash. See the adapter implementations under\n    # GitHub::Authentication for information on possible options.\n    def auth_options\n      if auth_mode.to_sym == :saml\n        {\n          :sso_url => saml_sso_url,\n          :idp_initiated_sso => saml_idp_initiated_sso,\n          :disable_admin_demote => saml_disable_admin_demote,\n          :issuer => saml_issuer,\n          :name_id_format => saml_name_id_format,\n          :signature_method => saml_signature_method,\n          :digest_method => saml_digest_method,\n          :idp_certificate_file => saml_certificate_file,\n          :sp_pkcs12_file => saml_sp_pkcs12_file,\n          :admin => saml_admin,\n          :username_attr => saml_username_attr,\n          :profile_fullname => saml_profile_name,\n          :profile_mail => saml_profile_mail,\n          :profile_ssh_key => saml_profile_ssh_key,\n          :profile_gpg_key => saml_profile_gpg_key,\n          :sp_url => url\n        }\n      else\n        {\n          # Used for SAML metdata, which should be available through non-SAML\n          # auth adaptors so that it can be retrieved before fully configuring SAML.\n          :sp_url => url,\n          :name_id_format => saml_name_id_format || \"urn:oasis:names:tc:SAML:2.0:nameid-format:persistent\"\n        }\n      end\n    end\n\n    def reactivate_suspended_user?\n      return false if !GitHub.enterprise?\n      return false if !GitHub.auth.external?\n\n      unless GitHub.config.get(\"auth.reactivate-suspended\").nil?\n        return GitHub.config.enabled?(\"auth.reactivate-suspended\")\n      end\n\n      #LDAP defaults to true\n      return true if GitHub.auth.ldap?\n\n      #Everything else defaults to false\n      return false\n    end\n\n    # Setting to disable password authentication for LDAP for Git operations\n    def external_auth_token_required\n      return false if !GitHub.enterprise?\n      return false if !GitHub.auth.external?\n      # External auth mechs other than LDAP do not support password auth\n      return true if !GitHub.auth.ldap?\n\n      return @external_auth_token_required if defined?(@external_auth_token_required)\n      return false\n    end\n    attr_writer :external_auth_token_required\n    alias :external_auth_token_required? :external_auth_token_required\n\n    # Algorithm to use for the SAML signature.\n    #\n    # As per the spec, https://www.w3.org/TR/xmldsig-core1/#sec-AlgID, there are\n    # several values to cater for with: rsa-sha1 (discouraged), rsa-sha256,\n    # rsa-sha384 and rsa-sha512 being the most commonly implemented.\n    #\n    # Default to rsa-sha256 as this is the recommended replacement for rsa-sha1.\n    def saml_signature_method\n      @saml_signature_method ||= \"http://www.w3.org/2001/04/xmldsig-more#rsa-sha256\"\n    end\n\n    # Allow the setting of one of four options with rsa-sha256 being enforced if\n    # an invalid value is given.\n    def saml_signature_method=(value)\n      @saml_signature_method =\n        case value\n        when \"rsa-sha1\"\n          \"http://www.w3.org/2000/09/xmldsig#rsa-sha1\"\n        when \"rsa-sha384\", \"rsa-sha512\"\n          \"http://www.w3.org/2001/04/xmldsig-more##{value}\"\n        else\n          \"http://www.w3.org/2001/04/xmldsig-more#rsa-sha256\"\n        end\n    end\n\n    # Algorithm to use for the SAML digest.\n    #\n    # As per the spec, https://www.w3.org/TR/xmldsig-core1/#sec-AlgID, there are\n    # several values to cater for with: sha1 (discouraged), sha256, and sha512\n    # being the most commonly implemented.\n    #\n    # Default to sha256 as this is the recommended replacement for sha1.\n    def saml_digest_method\n      @saml_digest_method ||= \"http://www.w3.org/2001/04/xmlenc#sha256\"\n    end\n\n    # Allow the setting of one of five options with sha256 being enforced if\n    # an invalid value is given.\n    def saml_digest_method=(value)\n      @saml_digest_method =\n        if value == \"sha1\"\n          \"http://www.w3.org/2000/09/xmldsig#sha1\"\n        elsif value == \"sha512\"\n          \"http://www.w3.org/2001/04/xmlenc#sha512\"\n        else\n          \"http://www.w3.org/2001/04/xmlenc#sha256\"\n        end\n    end\n\n    def saml_name_id_format=(value)\n      @saml_name_id_format =\n        if value == \"unspecified\"\n          \"urn:oasis:names:tc:SAML:1.1:nameid-format:unspecified\"\n        else\n          \"urn:oasis:names:tc:SAML:2.0:nameid-format:persistent\"\n        end\n    end\n\n    def sso_credential_authorization_help_url\n      ENV.fetch(\n        \"GITHUB_SSO_CREDENTIAL_AUTHORIZATION_HELP_URL\",\n        \"#{GitHub.help_url}/articles/authenticating-to-a-github-organization-with-saml-single-sign-on/\"\n      )\n    end\n\n    def iam_with_saml_sso_help_url\n      ENV.fetch(\n        \"GITHUB_IAM_WITH_SAML_SSO_HELP_URL\",\n        GitHub.help_url\n      )\n    end\n\n    def ldap_base=(ldap_base)\n      if !ldap_base.respond_to?(:each)\n        # If the domain base list comes from an environment variable we need to split it up.\n        ldap_base = String(ldap_base).split(\";\")\n      end\n      @ldap_base = ldap_base\n    end\n    attr_reader :ldap_base\n\n    # Public: LDAP Admin group defines which users are administrators based on\n    # group membership.\n    def ldap_admin_group=(group)\n      @ldap_auth_groups = nil\n      @ldap_admin_group = group\n    end\n    attr_reader :ldap_admin_group\n\n    # Public: LDAP user groups defines membership requirements for\n    # authenticating users.\n    def ldap_user_groups=(ldap_user_groups)\n      if !ldap_user_groups.respond_to?(:each)\n        # If the user groups list comes from an environment variable we need to split it up.\n        ldap_user_groups = String(ldap_user_groups).split(\";\")\n      end\n      ldap_user_groups.compact!\n      @ldap_auth_groups = nil\n      @ldap_user_groups = ldap_user_groups\n    end\n    attr_reader :ldap_user_groups\n\n    # Public: LDAP Groups users must belong to in order to successfully\n    # authenticate.\n    #\n    # Returns an empty Array if authentication is not scoped to groups.\n    # Returns an Array of group String names, including the admin group.\n    def ldap_auth_groups\n      return [] if ldap_user_groups.blank?\n      @ldap_auth_groups ||= begin\n        groups = ldap_user_groups + Array(ldap_admin_group)\n        groups.uniq!\n        groups.reject!(&:blank?)\n        groups\n      end\n    end\n\n    # Public: LDAP Search Strategy for Team Sync Member Search and\n    # authentication restricted group Membership Validation.\n    #\n    # Defaults to `detect` to force detection of the optimal strategy.\n    def ldap_search_strategy\n      @ldap_search_strategy ||= \"detect\"\n    end\n\n    # Public: Defines the maximum depth of recursion the Recursive search\n    # strategy can descend. Only used to the Recursive strategy.\n    #\n    # Pulls the value from the `ldap.search_strategy_depth` global config.\n    #\n    # Returns nil or the configured Integer depth.\n    def ldap_search_strategy_depth\n      if depth = GitHub.config.get(\"ldap.search_strategy_depth\")\n        depth.to_i\n      end\n    end\n\n    # The LDAP User Sync job interval in Integer of hours.\n    # Defaults to every 4 hours. See: GitHub::Jobs::LdapUserSync.\n    def ldap_user_sync_interval\n      @ldap_user_sync_interval ||= 4\n    end\n\n    # Set the LDAP User Sync job interval.\n    # Requires an interval greater than zero.\n    def ldap_user_sync_interval=(interval)\n      @ldap_user_sync_interval = interval.to_i if interval.to_i > 0\n    end\n\n    # The LDAP Team Sync job interval in Integer of hours.\n    # Defaults to every 4 hours. See: GitHub::Jobs::LdapTeamSync.\n    def ldap_team_sync_interval\n      @ldap_team_sync_interval ||= 4\n    end\n\n    # Set the LDAP Team Sync job interval.\n    # Requires an interval greater than zero.\n    def ldap_team_sync_interval=(interval)\n      @ldap_team_sync_interval = interval.to_i if interval.to_i > 0\n    end\n\n    # Whether the LDAP server supports virtual attributes like memberOf.\n    def ldap_virtual_attributes\n      return @ldap_virtual_attributes if defined?(@ldap_virtual_attributes)\n      @ldap_virtual_attributes = false\n    end\n\n    # Whether the LDAP group membership check should fallback to the slow non\n    # virtual attribute implementation when virtual attributes are disabled.\n    # This is false by default to prevent bad performance.\n    def ldap_recursive_group_search_fallback\n      return @ldap_recursive_group_search_fallback if defined?(@ldap_recursive_group_search_fallback)\n      @ldap_recursive_group_search_fallback = false\n    end\n\n    # Whether the LDAP group membership check should include posixGroup\n    # conditions.\n    # This is true by default.\n    def ldap_posix_support\n      return @ldap_posix_support if defined?(@ldap_posix_support)\n      @ldap_posix_support = true\n    end\n\n    # The amount of time we allow for LDAP authentication requests before timing out\n    def ldap_auth_timeout\n      @ldap_auth_timeout ||= 10\n    end\n\n    # Set the amount of time we allow for LDAP authentication requests before timing out\n    def ldap_auth_timeout=(value)\n      @ldap_auth_timeout = value if value > 0 && value <= GitHub.default_request_timeout\n    end\n\n    def auth_mode\n      @auth_mode ||= :default\n    end\n\n    def auth_mode=(mode)\n      @auth_adaptor = nil\n      @auth_mode = mode\n    end\n\n    # default password for user\n    attr_accessor :default_password\n\n    # Instantiate the Authentication object for handling auth configuration and inquiries.\n    #\n    # Returns an Authentication.\n    def auth_modes\n      @auth_modes ||= {\n        :default      => GitHub::Authentication::Default,\n        :ldap         => GitHub::Authentication::LDAP,\n        :cas          => GitHub::Authentication::CAS,\n        :github_oauth => GitHub::Authentication::GitHubOauth,\n        :saml         => GitHub::Authentication::SAML\n      }\n    end\n\n    # The instantiated Authentication adapter.\n    def auth\n      @auth_adaptor ||= auth_modes[auth_mode.to_sym].new(auth_options)\n    end\n\n    # Determines whether this is the very first time an Enterprise installation\n    # is being accessed. This is primarily used to determine whether or not the\n    # user being created should be auto-promoted to site admin status (the first\n    # user on installations are auto-promoted). You can pass in the env variable\n    # ENTERPRISE_FIRST_RUN to emulate this in development (hence the attr_writer).\n    #\n    # Returns true if no users have been created yet on the installation.\n    def enterprise_first_run?\n      # This nil check instead of `defined?` allows the attr_writer to reset\n      # this memoized value in tests by setting first_run to nil.\n      if @first_run.nil?\n        if GitHub::Enterprise.license.seats_used == 0\n          # Don't memoize a true value, this needs to be checked until\n          # seats_used is greater than zero.\n          true\n        else\n          # Now that there is at least one seat used, no more checks are\n          # required. Memoize the result.\n          @first_run = false\n        end\n      else\n        @first_run\n      end\n    end\n    attr_writer :first_run\n\n    # Available log levels.\n    RAILS_LOG_LEVELS = [:debug, :info, :warn, :error, :fatal]\n\n    # The log level used by the application. Possible log levels are :debug, :info,\n    # :warn, :error, and :fatal. This value is set by github/config/environments/<env>.rb\n    # scripts but can be adjusted under enterprise by the ENTERPRISE_RAILS_LOG_LEVEL\n    # environment variable or by modifying the RAILS_ROOT/config.yml file.\n    #\n    # Returns the configured log level as a symbol. If no log level is set\n    # explicitly, :info is returned.\n    def rails_log_level\n      @rails_log_level ||= :info\n    end\n\n    # Set the rails_log_level, verifying the value given.\n    #\n    # value - One of the LOG_LEVEL symbol values or a number between 0 and 4.\n    #\n    # Raises a TypeError when the value is not a supported log level.\n    def rails_log_level=(value)\n      value = value.to_i if value.is_a?(String) && value =~ /[0-4]/\n      value = value.to_sym if value.is_a?(String)\n      value = RAILS_LOG_LEVELS[value] if value.is_a?(Integer)\n\n      if RAILS_LOG_LEVELS.include?(value)\n        @rails_log_level = value\n      else\n        raise TypeError, \"Illegal value: #{value.inspect}\"\n      end\n    end\n\n    # Unicorn master/worker attributes\n    attr_accessor :unicorn_master_start_time\n    attr_accessor :unicorn_worker_start_time\n    attr_accessor :unicorn_master_pid\n    attr_accessor :unicorn_worker_request_count\n\n    # Determine whether Private Mode is enabled for GitHub (FI). Private Mode\n    # locks down the site- users must be logged in to view and use GitHub, and\n    # new user signups are restricted to admins only. This also disables\n    # various other functionality for the sake of a private GitHub (such as\n    # serving repositories over git://). It also causes all atom feeds to include\n    # login/token parameters, just like private feeds (see github/enterprise#244).\n    #\n    # Returns a Boolean.\n    def private_mode\n      return @private_mode if defined?(@private_mode)\n      @private_mode = GitHub.enterprise? && !(ENV[\"PRIVATE_MODE\"]).to_s.empty?\n    end\n    attr_writer :private_mode\n\n    # Is Private Mode enabled?\n    def private_mode_enabled?\n      private_mode\n    end\n\n    # Determine whether subdomain isolation is enabled for GitHub (FI).\n    # Subdomain isolation places various components of GitHub (raw, uploads,\n    # pages, etc) on their own subdomain. This prevents user controlled content\n    # from executing in the same origin as the rest of GitHub. As a result,\n    # attacks such as XSS on these subdomains are much less critical as they\n    # will be unable to access content on the main GitHub site and will not be\n    # able to perform security sensitive operations (accessing repos, etc).\n    #\n    # Returns a Boolean.\n    def subdomain_isolation\n      return @subdomain_isolation if defined?(@subdomain_isolation)\n      @subdomain_isolation = true\n    end\n    attr_writer :subdomain_isolation\n    alias :subdomain_isolation? :subdomain_isolation\n\n    # Using Private Mode and Subdomains for maximum privacy and security.\n    #\n    # Causes private mode authentication cookies to be set on *.githubhostname.\n    #\n    # Enabled when both using Enterprise isolated subdomains and Private Mode.\n    def subdomain_private_mode_enabled?\n      private_mode_enabled? && subdomain_isolation?\n    end\n\n    # Secret used for HMACing request information for proxy site detection.\n    attr_accessor :proxy_site_detection_secret\n\n    # Determine whether to create repositories in DGit by default\n    #\n    # Returns true if it's enabled, false otherwise\n    def dgit_intake_enabled?\n      if defined?(@dgit_intake_enabled)\n        return @dgit_intake_enabled\n      end\n      @dgit_intake_enabled = true  # defaults to true on dotcom\n    end\n    attr_writer :dgit_intake_enabled\n\n    # ID of the GitHub Enterprise Site Administrator Oauth App ID, which is\n    # the owner of Api::Admin::UsersManager tokens used for user impersonation.\n    #\n    # Returns int ID, or nil if the app doesn't exist and can't be created\n    def enterprise_admin_oauth_app_id\n      return nil unless GitHub.enterprise?\n      @enterprise_admin_oauth_app_id ||=\n        if app = OauthApplication.where({\n          user_id: GitHub.trusted_oauth_apps_owner,\n          name: \"GitHub Site Administrator\",\n          full_trust: true\n          }).first\n          app.id\n        elsif app = OauthApplication.register_trusted_application(\n          \"Site Administrator\",\n          SecureRandom.hex(10),\n          SecureRandom.hex(20),\n          \"https://developer.github.com/v3/enterprise/users/\",\n          \"https://developer.github.com/v3/enterprise/users/\"\n          )\n          app.id\n        else\n          nil\n        end\n    end\n\n    ##\n    # Custom Hooks (Enterprise)\n\n    # Location where custom git hooks data lives.\n    def custom_hooks_dir\n      @custom_hooks_dir ||= if Rails.production?\n                              \"/data/user/git-hooks\"\n                            elsif Rails.test?\n                              ENV[\"TEST_HOOK_DIR\"] || \"#{Rails.root}/git-hooks\"\n                            else\n                              \"#{Rails.root}/git-hooks\"\n                            end\n    end\n    attr_writer :custom_hooks_dir\n\n    def pre_receive_hooks_enabled?\n      GitHub.enterprise? || !Rails.production?\n    end\n\n    # The password cost factor for Bcrypt\n    def password_cost\n      @password_cost ||= BCrypt::Engine::DEFAULT_COST\n    end\n    attr_writer :password_cost\n\n    # The key we use to encrypt two-factor secrets in the database\n    attr_accessor :two_factor_salt\n\n    # The key we use to encrypt SAML provider recovery keys in the database\n    attr_accessor :saml_provider_salt\n\n    # U2F instance for FIDO U2F authentication.\n    #\n    # Returns a U2F::U2F instance.\n    def u2f\n      @u2f ||= U2F::U2F.new(u2f_app_id)\n    end\n\n    # The app id to use for FIDO U2F. This points to\n    # u2f_registrations#trusted_facets which tells U2F devices to trust a set\n    # of domains to share registrations.\n    #\n    # Returns a String URL.\n    def u2f_app_id\n      \"#{url}/u2f/trusted_facets\"\n    end\n\n    # The list of domains that are trusted to share U2F devices. In production\n    # this includes staging/admin domains. On enterprise and development this\n    # is just the app's URL itself.\n    #\n    # Returns an Array of String URLs.\n    def u2f_trusted_facets\n      @u2f_trusted_facets ||= [url].freeze\n    end\n    attr_writer :u2f_trusted_facets\n\n    # Constant BCrypt salt to be able to get the same hash for the same\n    # password. Used for tracking passwords from failed login attempts.\n    def constant_bcrypt_salt\n      @constant_bcrypt_salt ||= BCrypt::Engine.generate_salt(password_cost)\n    end\n    attr_writer :constant_bcrypt_salt\n\n    ##\n    # Failbot / Exceptions reporting.\n\n    # Failbot customization. Under most environments, the default config\n    # that's provided out of the box by the Failbot library is sensible but in\n    # some cases (FI), it is useful to override it.\n    #\n    # Default to writing JSON-encoded exceptions to log/exceptions.log under FI\n    # environments. Other environments use whatever the default Failbot config\n    # of the current RAILS_ENV is.\n    #\n    # Returns the Failbot custom config Hash to be passed to Failbot.setup.\n    def failbot\n      @failbot ||=\n        if Rails.test?\n          {\n            \"FAILBOT_BACKEND\" => \"memory\"\n          }\n        elsif Rails.development? || enterprise?\n          {\n            \"FAILBOT_BACKEND\" => \"file\",\n            \"FAILBOT_BACKEND_FILE_PATH\" => failbot_log_path\n          }\n        else\n          {\n            \"FAILBOT_BACKEND\" => \"json\",\n            \"FAILBOT_BACKEND_JSON_HOST\" => \"localhost\",\n            \"FAILBOT_BACKEND_JSON_PORT\" => 6668\n          }\n        end\n    end\n    attr_writer :failbot\n\n    # Failbot log file location, if applicable.\n    def failbot_log_path\n      \"#{Rails.root}/log/exceptions.log\"\n    end\n\n    ##\n    # Miscellaneous feature flags typically disabled under FI environments.\n\n    # Determine whether the blog is enabled. This is disabled under FI\n    # environments but enabled everywhere else.\n    #\n    # Returns true if it is enabled, false otherwise.\n    def blog_enabled?\n      return @blog_enabled if defined?(@blog_enabled)\n      @blog_enabled = !enterprise?\n    end\n    attr_writer :blog_enabled\n\n    # Determine whether to display terms/security/privacy in footer. This is\n    # disabled under FI environments but enabled everywhre else.\n    #\n    # Returns true if it's enabled, false otherwise\n    def footer_legalese_enabled?\n      if defined?(@footer_legalese_enabled)\n        return @footer_legalese_enabled\n      end\n      @footer_legalese_enabled = !enterprise?\n    end\n    attr_writer :footer_legalese_enabled\n\n    # Determine whether to show things related to licensing in GitHub. This is\n    # primarily the license picker and auto-license population during repository\n    # creation.\n    #\n    # Returns true if the license picker should be displayed, false otherwise.\n    def license_picker_enabled?\n      return @license_picker_enabled if defined?(@license_picker_enabled)\n\n      @license_picker_enabled = !enterprise?\n    end\n    attr_writer :license_picker_enabled\n\n    # Determine whether to show the Code of Conduct editor.\n    #\n    # Returns true if the code of conduct picker should be displayed, false otherwise.\n    def code_of_conduct_picker_enabled?\n      @code_of_conduct_picker_enabled ||= !enterprise?\n    end\n    attr_writer :code_of_conduct_picker_enabled\n\n    # Custom tabs allow repository admins to configure custom repository tabs\n    # displayed in the repository navigation, that point to an arbitraty URL.\n    # This is enabled under Enterprise environments but disabled everywhere else.\n    #\n    # Returns true if enabled, false otherwise.\n    def custom_tabs_enabled?\n      return @custom_tabs_enabled if defined?(@custom_tabs_enabled)\n      @custom_tabs_enabled = enterprise?\n    end\n    attr_writer :custom_tabs_enabled\n\n    # Allow users to enter a short professional bio and mark themselves as being\n    # hireable. This is disabled by default under FI environments and enabled\n    # everywhere else, altough we're not taking advantage of this data yet.\n    #\n    # Returns true if enabled, false otherwise.\n    def job_profiles_enabled?\n      return @job_profiles_enabled if defined?(@job_profiles_enabled)\n      @job_profiles_enabled = !enterprise?\n    end\n    attr_writer :job_profiles_enabled\n\n    # Determine whether restrictions around spammy users are enforced\n    # throughout the site. Disabled by default under Enterpise environments, enabled\n    # everywhere else.\n    #\n    # Returns true if enabled, false otherwise.\n    def spamminess_check_enabled?\n      return @spamminess_check_enabled if defined?(@spamminess_check_enabled)\n      @spamminess_check_enabled = !enterprise?\n    end\n    attr_writer :spamminess_check_enabled\n\n    # How long do we memoize spam patterns during Spam checking?\n    #\n    # We default to 0 if no value is set in the environment.\n    #\n    # Returns an integer.\n    def spam_pattern_memoization_ttl_in_seconds\n      return @spam_pattern_memoization_ttl_in_seconds if defined?(@spam_pattern_memoization_ttl_in_seconds)\n      @spam_pattern_memoization_ttl_in_seconds = (ENV[\"SPAM_PATTERNS_MEMOIZED_TTL_IN_SECONDS\"] || 0).to_i\n    end\n    attr_writer :spam_pattern_memoization_ttl_in_seconds\n\n    # Should we report user-creation data to Octolytics?\n    #\n    # Returns false in enterprise.\n    def user_creation_analytics_enabled?\n      octolytics_enabled? && !enterprise?\n    end\n\n    # Determine whether suspended users are hidden from other users. Enabled\n    # by default under all environments.\n    #\n    # Returns true if enabled, false otherwise.\n    def suspended_users_visible?\n      return @suspended_users_visible if defined?(@suspended_users_visible)\n      @suspended_users_visible = true\n    end\n    attr_writer :suspended_users_visible\n\n    # Determine whether /admin is enabled. Redirects to Staff Tools when\n    # disabled. Disable by default under Enterprise environments, enabled everywhere\n    # else.\n    #\n    # Returns true if enabled, false otherwise.\n    def admin_enabled?\n      return @admin_enabled if defined?(@admin_enabled)\n      @admin_enabled = !enterprise?\n    end\n    attr_writer :admin_enabled\n\n    # Determine whether /setup is enabled. Enabled by default in Enterprise,\n    # disabled for dotcom.\n    #\n    # Returns true if enabled, false otherwise.\n    def management_console_enabled?\n      return @management_console_enabled if defined?(@management_console_enabled)\n      @management_console_enabled = enterprise?\n    end\n    attr_writer :management_console_enabled\n\n    # Determine whether Haystack is available. Currently dotcom only.\n    #\n    # Returns true if haystack is enabled, false otherwise.\n    def haystack_enabled?\n      return @haystack_enabled if defined?(@haystack_enabled)\n      @haystack_enabled = !enterprise?\n    end\n    attr_writer :haystack_enabled\n\n    # Determine whether the instance wide audit log is enabled. Currently dotcom\n    # only.\n    #\n    # Returns true if enabled, false otherwise.\n    def instance_audit_log_enabled?\n      return @instance_audit_log_enabled if defined?(@instance_audit_log_enabled)\n      @instance_audit_log_enabled = enterprise?\n    end\n    attr_writer :instance_audit_log_enabled\n\n    # Determine whether reports are enabled. Current only used\n    # in Enterprise.\n    #\n    # Returns true if enabled, false otherwise.\n    def reports_enabled?\n      return @reports_enabled if defined?(@reports_enabled)\n      @reports_enabled = GitHub.enterprise?\n    end\n    attr_writer :reports_enabled\n\n    # Determine whether large blobs should be rejected or not.\n    # We currently don't reject large blobs in Enterprise.\n    #\n    # Returns true if enabled, false otherwise.\n    def large_blob_rejection_enabled?\n      return @large_blob_rejection_enabled if defined?(@large_blob_rejection_enabled)\n      @large_blob_rejection_enabled = true\n    end\n    attr_writer :large_blob_rejection_enabled\n\n    # Is the rejection of 40 character hex names for refs enabled?\n    def reject_sha_like_refs?\n      return @reject_sha_like_refs if defined?(@reject_sha_like_refs)\n      @reject_sha_like_refs = true\n    end\n    attr_writer :reject_sha_like_refs\n\n    # The maximum length of reference names.\n    #\n    # This is defined as the minimum size for the `pushes.refs` and\n    # `reflog_entries.refs` database columns. Refs longer than this will be\n    # truncated and cause query warnings.\n    def maximum_ref_length\n      @maximum_ref_length ||= 255\n    end\n    attr_writer :maximum_ref_length\n\n    # Whether repository health checks are available. Only available in\n    # dotcom environments right now.\n    #\n    # Returns true if enabled, false otherwise.\n    def repository_health_enabled?\n      !enterprise?\n    end\n\n    # Determine whether organization OAuth application policies are available.\n    # (This feature is currently available only in dotcom environments.)\n    #\n    # Returns true if enabled, false otherwise.\n    def oauth_application_policies_enabled?\n      !enterprise?\n    end\n\n    # Determines if we should scan for sensitive tokens in repositories.\n    # (This feature is currently available only in dotcom environments.)\n    #\n    # Returns true if enabled, false otherwise.\n    def token_scanning_enabled?\n      !enterprise?\n    end\n\n    # Determine if site admins can initiate a site-wide ssh key audit.\n    # Enabled by default in Enterprise, disabled for dotcom.\n    #\n    # Returns true if enabled, false otherwise.\n    def ssh_audit_enabled?\n      return @ssh_audit_enabled if defined?(@ssh_audit_enabled)\n      @ssh_audit_enabled = enterprise?\n    end\n    attr_writer :ssh_audit_enabled\n\n    # Determine whether repo transfers require approval.\n    #\n    # Returns true if enabled, false otherwise.\n    def repository_transfer_requests_enabled?\n      return @repository_transfer_requests_enabled if defined?(@repository_transfer_requests_enabled)\n      @repository_transfer_requests_enabled = !enterprise?\n    end\n    attr_writer :repository_transfer_requests_enabled\n\n    # Determine whether employee-only features are available. Disabled by\n    # default under Enterprise environments, enabled everywhere else.\n    #\n    # Returns true if enabled, false otherwise.\n    def preview_features_enabled?\n      return @preview_features_enabled if defined?(@preview_features_enabled)\n      @preview_features_enabled = !enterprise?\n    end\n    attr_writer :preview_features_enabled\n\n    # Whether public-push repositories are enabled.\n    # See: https://github.com/github/github/pull/15785\n    def public_push_enabled?\n      GitHub.enterprise?\n    end\n\n    # Whether browser stats collecting is enabled\n    def browser_stats_enabled?\n      return @browser_stats_enabled if defined?(@browser_stats_enabled)\n      @browser_stats_enabled = true\n    end\n    attr_writer :browser_stats_enabled\n\n    # The API URL to post browser stats to.\n    def browser_stats_url\n      [api_url, \"_private\", \"browser\", \"stats\"].join(\"/\")\n    end\n\n    # The API URL that JavaScript exceptions are reported to.\n    def browser_errors_url\n      [api_url, \"_private\", \"browser\", \"errors\"].join(\"/\")\n    end\n\n    # Is SMTP enabled in this environment?\n    #\n    # Returns true by default.\n    # Can return false in Enterprise environments if an admin has disabled SMTP\n    # on the appliance.\n    def smtp_enabled?\n      return @smtp_enabled if defined?(@smtp_enabled)\n      @smtp_enabled = true\n    end\n    attr_writer :smtp_enabled\n\n    # The SMTP domain name.\n    def smtp_domain\n      @smtp_domain ||= host_name\n    end\n    attr_writer :smtp_domain\n\n    # SMTP server address.\n    attr_accessor :smtp_address\n\n    # SMTP port.\n    def smtp_port\n      @smtp_port ||= 25\n    end\n    attr_writer :smtp_port\n\n    # The secret token used in the generation of the recipient code for\n    # reply emails.\n    #\n    # Returns 'hubbernaut' by default.\n    def smtp_secret\n      return @smtp_secret if defined?(@smtp_secret)\n      @smtp_secret ||= \"hubbernaut\"\n    end\n    attr_writer :smtp_secret\n\n    # Additional SMTP configuration.\n    attr_accessor :smtp_user_name\n    attr_accessor :smtp_password\n    attr_accessor :smtp_authentication\n\n    # Default .com to having it disabled because the\n    # front-end & worker machines talk to an MTA on localhost\n    def smtp_enable_starttls_auto\n      enterprise? ? @smtp_enable_starttls_auto : false\n    end\n    attr_writer :smtp_enable_starttls_auto\n\n    # Determine if this environment send campfire notifications.\n    #\n    # Returns true unless this is an enterprise instance.\n    def campfire_notifications?\n      !enterprise?\n    end\n\n    # The name of the session cookie used for rails sessions.\n    #\n    # Returns '_gh_sess' by default under dotcom mode and '_gh_ent' under\n    # enterprise mode.\n    def session_key\n      @session_key ||=\n        if GitHub.runtime.enterprise?\n          \"_gh_ent\"\n        else\n          \"_gh_sess\"\n        end\n    end\n    attr_writer :session_key\n\n    # The secret token for both rails and rack session signatures. This value is\n    # also used by enterprise-manage's sessions.\n    attr_accessor :session_secret\n\n    ##\n    # Network Graph\n\n    # Maximum number of commits (dots) to show on the Network Graph.\n    def network_graph_history_limit\n      @network_graph_history_limit ||= enterprise?? 50_000 : 5_000\n    end\n    attr_writer :network_graph_history_limit\n\n    # The limit of how many times an email check request can happen per\n    # ip address.\n    #\n    # Returns a fixnum limit that can be combined with a ttl.\n    def email_check_rate_limit\n      @email_check_rate_limit ||= enterprise? ? 120 : 5000\n    end\n    attr_writer :email_check_rate_limit\n\n    # The lifespan of an email check rate limit.\n    #\n    # Returns a fixnum representing time in seconds.\n    def email_check_ttl\n      @email_check_ttl ||= enterprise? ? 1.minute : 1.hour\n    end\n    attr_writer :email_check_ttl\n\n    # The Enterprise configuration id. An integer timestamp representing the\n    # last time the configuration chef run was started. This is exposed at\n    # /status.json and is useful for determining if the app is running under\n    # the expected or newer configuration version.\n    def configuration_id\n      @configuration_id.to_i rescue nil\n    end\n    attr_writer :configuration_id\n\n    # The port the git daemon in listening on locally. In production the default\n    # git port (9418) is used. On enterprise git_proxy needs to consume 9418 so\n    # the daemon must listen on something else.\n    #\n    # Returns 9418 in production.\n    def git_daemon_port\n      @git_daemon_port ||= 9418\n    end\n    attr_writer :git_daemon_port\n\n    # The fingerprint of the RSA host key. Constant on production, unique per\n    # server on enterprise.\n    #\n    # Return the fingerprint of the RSA host key.\n    def rsa_fingerprint\n      if enterprise?\n        local_hostkey_fingerprint\n      else\n        \"16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48\"\n      end\n    end\n\n    # Fingerprint of the local RSA host key. Used on enterprise instances.\n    #\n    # Return the fingerprint of the RSA host key.\n    def local_hostkey_fingerprint\n      @local_hostkey_fingerprint ||= begin\n        %x{ssh-keygen -l -f /etc/ssh/ssh_host_rsa_key}.split[1]\n      end\n    end\n\n    # New accounts are created through the signup page on enterprise instances.\n    # Not used by some external auth providers, or when in private mode, or when\n    # explicitly disabled during setup.\n    #\n    # Returns boolean\n    def signup_enabled?\n      return true unless enterprise?\n\n      !GitHub.private_mode_enabled? && GitHub.auth.signup_enabled? && GitHub.signup_enabled\n    end\n\n    # In Enterprise, admins can explicitly disable signups.\n    def signup_enabled\n      @signup_enabled\n    end\n    attr_writer :signup_enabled\n\n    # In Enterprise, realtime backups are manually enabled\n    def realtime_backups_enabled?\n      !!@realtime_backups_enabled\n    end\n    attr_writer :realtime_backups_enabled\n\n    # In Enterprise we hide the ability to block users and report\n    # abuse.\n    def user_abuse_mitigation_enabled?\n      return @user_abuse_mitigation_enabled if defined?(@user_abuse_mitigation_enabled)\n      @user_abuse_mitigation_enabled = !enterprise?\n    end\n    attr_writer :user_abuse_mitigation_enabled\n\n    # Timeout for long running Git operations in templates (e.g.,\n    # rendering diffs and commit lists in pull requests).\n    def git_template_timeout\n      @git_template_timeout ||= 10\n    end\n    attr_writer :git_template_timeout\n\n    # Enterpise customers may want to customize the email address used as the\n    # noreply sender.\n    #\n    # Returns an email address as a string. Default is noreply@<host_name>.\n    def noreply_address\n      @noreply_address ||= \"noreply@#{smtp_domain}\"\n    end\n    attr_writer :noreply_address\n\n    # Stealth email is disabled on Enterprise instances.\n    def stealth_email_enabled?\n      !enterprise?\n    end\n\n    # Allow turning on/off email replies to notifications.\n    #\n    # Defaults to true.\n    def email_replies_enabled?\n      return @email_replies_enabled if defined?(@email_replies_enabled)\n      @email_replies_enabled = true\n    end\n    attr_writer :email_replies_enabled\n\n    # Email verification is disabled on Enterprise instances\n    def email_verification_enabled?\n      return false if enterprise?\n      true\n    end\n\n    # Mandatory email verification is turned off in dev and test, and anywhere\n    # email verification is disabled. NOTE: Enforcement still requires the\n    # presence of the mandatory_email_verification experiment and feature.\n    #\n    # Force with the ENABLE_MANDATORY_VERIFICATION environment variable, e.g.:\n    #\n    #   ENABLE_MANDATORY_VERIFICATION=1 script/server\n    def mandatory_email_verification_enabled?\n      return true if !!ENV[\"ENABLE_MANDATORY_VERIFICATION\"]\n      email_verification_enabled? && !(Rails.test? || Rails.development?)\n    end\n\n    # Email preference center is disabled on Enterprise instances\n    # because we don't need to send marketing newsletters to those users.\n    def email_preference_center_enabled?\n      !enterprise?\n    end\n\n    # The MailChimp integration is is disabled on Enterprise.\n    def mailchimp_enabled?\n      !enterprise?\n    end\n\n    # We require a password confirmation on signup in Enterprise\n    # because email delivery might not be enabled for the instance,\n    # which means that a user couldn't reset their password via email.\n    def password_confirmation_required?\n      enterprise?\n    end\n\n    # We ask users identity questions on dotcom during signup.\n    # Disabled on Enterprise.\n    def user_identification_enabled?\n      !enterprise?\n    end\n\n    # Live Update XHR Socket poller\n    #\n    # Can be flipped off if the web socket connections are going nuts.\n    def live_updates_enabled?\n      return @live_updates_enabled if defined?(@live_updates_enabled)\n      @live_updates_enabled = true\n    end\n    attr_writer :live_updates_enabled\n\n    # Should Live Update configuration delegate to flipper.\n    #\n    # Flipper configuration is only setup in github.com production.\n    def live_updates_flipper_controlled?\n      return @live_updates_flipper_controlled if defined?(@live_updates_flipper_controlled)\n      @live_updates_flipper_controlled = false\n    end\n    attr_writer :live_updates_flipper_controlled\n\n    # Check to see if we are restriced by licenses, in other words if we are an\n    # enterprise install.  Determines what to show in the root of stafftools\n    def licensed_mode?\n      enterprise?\n    end\n\n    # The path to the local .ghl file on Enterprise instances.\n    def license_path\n      return unless enterprise?\n\n      @license_path ||= File.join(enterprise_config_dir, \"enterprise.ghl\")\n    end\n    attr_writer :license_path unless Rails.production?\n\n    # Path to the license .gpg key shipped as part of an Enterprise .ova.\n    def license_key\n      @license_key ||= File.join(enterprise_config_dir, \"license.gpg\")\n    end\n    attr_writer :license_key unless Rails.production?\n\n    # Path to the customer .gpg key uploaded as part of the Enterprise license.\n    def customer_key\n      @customer_key ||= File.join(enterprise_config_dir, \"customer.gpg\")\n    end\n    attr_writer :customer_key unless Rails.production?\n\n    # The configuration directory holding Enterprise related files like the\n    # .ghl license, customer gpg key, and license gpg key.\n    #\n    # Returns the path to the config dir for the current Enterprise series.\n    def enterprise_config_dir\n      \"/data/enterprise\"\n    end\n\n    # Placeholder to abstract the fact that GitHub access control is done\n    # through GitHub::AccessControl.\n    def access\n      Egress::AccessControl\n    end\n\n    # enterprise-web URL\n    attr_accessor :enterprise_web_url\n\n    # Sets the API token for accessing the enterprise-web API\n    attr_accessor :enterprise_web_token\n\n    # S3 Access key for alambic\n    attr_accessor :s3_alambic_access_key\n\n    # S3 Secret key for alambic\n    attr_accessor :s3_alambic_secret_key\n\n    # Sets the URL for accessing Alambic.\n    # TODO(storage): deprecated by alambic cluster\n    attr_accessor :alambic_url\n\n    # Sets the URL for purging CDN keys.\n    attr_accessor :alambic_cdn_url\n\n    # Sets the API token for purging CDN data through Alambic.\n    attr_accessor :alambic_cdn_token\n\n    # Sets the URL prefix for uploading assets to the \"assets\" Alambic service.\n    # TODO(storage): deprecated by alambic cluster\n    attr_accessor :alambic_uploads_url\n\n    # Sets the URL for accessing the LFS server.\n    attr_accessor :lfs_server_url\n\n    # Sets the HMAC key used to verify request bodies sent to the Internal API.\n    attr_accessor :internal_api_hmac_key\n\n    # Sets the ?v param on avatar urls.  Changing this will force break all\n    # avatar server and browser caches.\n    attr_accessor :alambic_avatar_version\n\n    # Sets the ?v param on avatar urls for a portion of URLS\n    attr_accessor :alambic_next_avatar_version\n\n    # Sets the ?b param on avatar urls.  Changing this will force break all\n    # browser caches.\n    attr_accessor :alambic_browser_avatar_version\n\n    # Sets the ?b param on avatar urls for a portion of URLS\n    attr_accessor :alambic_next_browser_avatar_version\n\n    # Sets the % chance that the next avatar version is used\n    attr_accessor :alambic_next_avatar_chance\n\n    # Sets the string user login\n    attr_accessor :alambic_fallback_user\n\n    # Sets whether gravatars are being uploaded to alambic.\n    # Currently only works with Enterprise.\n    attr_accessor :alambic_avatar_upgrading\n\n    # Sets the URL path to purge (using GitHub.alambic_cdn_url as the host)\n    attr_writer :alambic_cdn_purge_path\n\n    # Sets the number of seconds to delay an avatar purge.\n    attr_accessor :alambic_cdn_delay\n\n    # Sets the default path prefix for alambic content.  See the defaults set\n    # in the different runtime environments (test, dev, prod, enterprise).\n    # TODO(storage): deprecated by alambic cluster\n    attr_accessor :alambic_path_prefix\n\n    # Sets whether to force the Media::Blob prefix or use the default one.\n    # Defaults to false in production, and true everywhere else.\n    # TODO(storage): deprecated by alambic cluster\n    attr_accessor :alambic_use_media_prefix\n\n    # Sets the API token for replicating assest through Alambic\n    attr_accessor :alambic_replication_token\n\n    # Sets a shared token with github/render for creating RenderBlobs in GHE.\n    attr_accessor :render_blob_storage_token\n\n    # Sets a shared token with github/lfs-server for internal api actions\n    attr_accessor :lfs_server_token\n\n    attr_accessor :git_lfs_enabled\n\n    def alambic_cdn_purge_path\n      @alambic_cdn_purge_path ||= \"purge\"\n    end\n\n    # Gets the CSP host to grant access to Alambic services.\n    def alambic_csp_host\n      url_origin(alambic_uploads_url)\n    end\n\n    # Sets the URL prefix for downloading assets from the \"assets\" Alambic\n    # service.\n    #\n    # TODO(storage): deprecated by alambic cluster\n    #\n    # ex: https://alambic-origin.github.com/assets\n    attr_accessor :alambic_assets_url\n\n    # Sets the URL prefix for uploading and downloading objects through the\n    # \"storage\" Alambic service.\n    attr_accessor :storage_cluster_url\n\n    # Get the storage cluster host for CSP purposes.\n    def storage_cluster_host\n      url_origin(storage_cluster_url)\n    end\n\n    # Sets the URL prefix for downloading objects through the \"storage\"\n    # Alambic service. If nil, fall back to #storage_cluster_url. GHE with\n    # Private mode should set this to a route that verifies private mode through\n    # cookies, instead of the API.\n    attr_accessor :storage_private_mode_url\n\n    # Sets the URL format for the root url for Alambic to replicate objects.\n    # Should yield a full URL.\n    #\n    # ex: \"http://%s:8080/storage/replicate\"\n    #\n    #   GitHub.storage_replicate_fmt % \"ghe-alambic-fe1\"\n    #   # => http://ghe-alambic-fe1:8080/storage/replicate\n    attr_accessor :storage_replicate_fmt\n\n    # Sets the path for the EnterpriseStorageClusterUpgrade transition.\n    attr_accessor :storage_transition_path\n\n    # Gets the number of readonly replicas that are included in a storage upload,\n    # but not required for a successful cluster consensus.\n    attr_accessor :storage_non_voting_replica_count\n\n    attr_writer :storage_cluster_enabled\n    attr_writer :storage_replica_count\n    attr_writer :storage_auto_localhost_replica\n    attr_writer :storage_legacy_path\n\n    def storage_cluster_enabled?\n      @storage_cluster_enabled\n    end\n\n    def storage_replica_count\n      @storage_replica_count ||= 1\n    end\n\n    def storage_auto_localhost_replica?\n      if @storage_auto_localhost_replica.nil?\n        @storage_auto_localhost_replica = !Rails.production?\n      end\n      @storage_auto_localhost_replica\n    end\n\n    def storage_legacy_path\n      @storage_legacy_path ||= File.join(Rails.root, \"tmp/objects\")\n    end\n\n    # Sets the URL prefix for the Avatar proxy\n    #\n    # ex: https://avatars.github.com\n    attr_writer :alambic_avatar_url\n\n    def alambic_assets_host\n      url_origin(alambic_assets_url)\n    end\n\n    # Gets just the scheme + host + port of a URL for the CSP policy.\n    def url_origin(url)\n      origin = Addressable::URI.parse(url).origin if url\n      origin == \"null\" ? nil : origin\n    end\n\n    # The base URL for all Alambic avatars. If passed a string, it will\n    # determine which subdomain to use.\n    #\n    # string - An optional String that will be hashed to determine which avatar\n    #          subdomain should be used (0, 1, 2, or 3).\n    #\n    # Returns a full avatar url\n    def alambic_avatar_url(string = nil)\n      return @alambic_avatar_url % nil unless string\n      string_s = string.to_s\n      n = Zlib.crc32(string_s) % 4\n      @alambic_avatar_url % n\n    end\n\n    # Get all possible Alambic avatar URLs.\n    #\n    # Returns a Array of available Alambic avatar URLs. Returns an empty Array\n    # if Alambic avatars are disabled.\n    def alambic_avatar_urls\n      (0..3).map { |n| url_origin(@alambic_avatar_url % n) }.uniq\n    end\n\n    def avatar_version(key = nil)\n      nxt = alambic_next_avatar_version\n      return alambic_avatar_version if !(nxt && next_avatar_version?(key))\n      nxt\n    end\n\n    def browser_avatar_version(key = nil)\n      nxt = alambic_next_browser_avatar_version\n      return alambic_browser_avatar_version if !(nxt && next_avatar_version?(key))\n      nxt\n    end\n\n    def next_avatar_version?(key = nil)\n      chance = alambic_next_avatar_chance.to_i\n      return false unless chance > 0\n\n      if key\n        Zlib.crc32(key) % 100 < chance\n      else\n        rand(100) < chance\n      end\n    end\n\n    # Prefetch DNS entries for our asset domains.\n    #\n    # https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-DNS-Prefetch-Control\n    #\n    #     <link rel=\"dns-prefetch\" href=\"//assets-cdn.github.com\">\n    #\n    # Returns an Array of String host names to prefetch.\n    def dns_prefetch_hosts\n      @dns_prefetch_hosts ||= [\n        asset_host_url,\n        *alambic_avatar_urls,\n        s3_asset_bucket_host,\n        user_images_cdn_url\n      ].select(&:present?).freeze\n    end\n\n    # Public - disable NetGraph generation\n    # The network graph generation makes the Enterprise VM unusable.\n    # Using this flag we can disable the building for each push.\n    #\n    # Return true if the graph can be built.\n    def network_graph_building_enabled?\n      !enterprise?\n    end\n\n    # Whether any uploads are accepted.\n    #\n    # Returns true if enabled, false otherwise.\n    def uploads_enabled?\n      storage_cluster_enabled? || s3_uploads_enabled?\n    end\n\n    # Upload assets to S3, so that they may be served by Amazon and not us.\n    # Disabled by default under FI environments, enabled everwhere else.\n    #\n    # Returns true if enabled, false otherwise.\n    def s3_uploads_enabled?\n      return @s3_uploads_enabled unless @s3_uploads_enabled.nil?\n      @s3_uploads_enabled = s3_uploads_enabled!\n    end\n    attr_writer :s3_uploads_enabled\n\n    def s3_uploads_enabled!\n      !enterprise? && online?\n    end\n\n    def asset_url_host\n      @asset_url_host ||= s3_asset_host\n    end\n    attr_writer :asset_url_host\n\n    def s3_asset_host\n      @s3_asset_host ||= begin\n        if s3_environment_config[:asset_host_name]\n          \"https://#{s3_environment_config[:asset_host_name]}/\"\n        else\n          \"#{s3_asset_bucket_host}/\"\n        end\n      end\n    end\n    attr_writer :s3_asset_host\n\n    def s3_asset_bucket_host\n      @s3_asset_bucket_host ||= \"https://#{s3_environment_config[:asset_bucket_name]}.s3.amazonaws.com\"\n    end\n\n    def file_asset_host\n      @file_asset_host ||= \"/\"\n    end\n    attr_writer :file_asset_host\n\n    # Sets the local file system path to store uploaded files.\n    #\n    # Returns a String path.\n    def file_asset_path\n      @file_asset_path ||= if Rails.test?\n        (Rails.root + \"test/fixtures/assets#{test_environment_number}\").to_s\n      elsif enterprise? && Rails.production?\n        \"/data/assets\"\n      else\n        (Rails.root + \"public\").to_s\n      end\n    end\n    attr_writer :file_asset_path\n\n    # Sets the local file system path to store storage files.\n    # This is only used in enterprise.\n    #\n    # Returns a String path\n    def storage_data_path\n      @storage_data_path ||= if enterprise?\n        \"/data/user/storage\"\n      else\n        file_asset_path\n      end\n    end\n    attr_writer :storage_data_path\n\n    # Uri base path to the external assets.\n    #\n    # Returns a String path\n    def asset_base_path\n      return @asset_base_path if defined?(@asset_base_path)\n      @asset_base_path = \"assets\"\n    end\n    attr_writer :asset_base_path\n\n    # Uri base path to the external task logs.\n    #\n    # Returns a String path\n    def task_log_base_path\n      return @task_log_base_path if defined?(@task_log_base_path)\n      @task_log_base_path = \"task-logs\"\n    end\n    attr_writer :task_log_base_path\n\n    # Uri base path to the external releases.\n    #\n    # Returns a String path\n    def release_asset_base_path\n      return @release_asset_base_path if defined?(@release_asset_base_path)\n      @release_asset_base_path = \"releases\"\n    end\n    attr_writer :release_asset_base_path\n\n    # Uri base path to marketplace listing assets.\n    #\n    # Returns a String path\n    def marketplace_listing_asset_base_path\n      if defined? @marketplace_listing_asset_base_path\n        return @marketplace_listing_asset_base_path\n      end\n      @marketplace_listing_asset_base_path = \"marketplace_listings\"\n    end\n    attr_writer :marketplace_listing_asset_base_path\n\n    # Uri base path to the external showcase assets\n    #\n    # Returns a String path\n    def showcase_asset_base_path\n      return @showcase_asset_base_path if defined?(@showcase_asset_base_path)\n      @showcase_asset_base_path = \"showcases\"\n    end\n    attr_writer :showcase_asset_base_path\n\n    # Configuration attributes to use github.com as SSO for GitHub Enterprise.\n    attr_accessor :github_oauth_client_id\n    attr_accessor :github_oauth_secret_key\n    attr_accessor :github_oauth_organization\n    attr_accessor :github_oauth_team\n\n    # Rotate among a few numbers for international recipients.\n    def sms_numbers\n      @sms_numbers ||= {\n        :twilio => [\n          \"4152339579\",\n          \"4152339591\",\n          \"4152339592\",\n          \"4152339559\",\n          \"4152339562\",\n          \"4152339556\",\n          \"4152339119\",\n          \"4152339144\",\n          \"4152339117\",\n          \"4152339138\",\n          \"4152339155\",\n          \"4152339104\",\n          \"4154888210\",\n          \"4154888243\",\n          \"4154888269\",\n          \"4154888273\",\n          \"4154888272\",\n          \"4154888317\",\n          \"4154888313\",\n          \"4154888399\",\n          \"4154888349\",\n          \"4154888318\"\n        ],\n        :nexmo => [\n          \"github\"\n        ],\n        :test => [\n          \"1231231234\",\n          \"2342342345\",\n          \"3453453456\"\n        ],\n        :local => [\n          \"1010101010\"\n        ]\n      }\n    end\n    attr_writer :sms_numbers\n\n    def sms_short_code\n      @sms_short_code ||= 448482\n    end\n    attr_writer :sms_short_code\n\n    # Twilio API information\n    attr_accessor :twilio_sid\n    attr_accessor :twilio_token\n\n    # Nexmo API information\n    attr_accessor :nexmo_api_key\n    attr_accessor :nexmo_api_secret\n\n    # Determine whether site_admin scope is required for API resources that make\n    # use of the site_admin scope. (This scope is used by API resources that are\n    # only accessible to site admins).\n    #\n    # site_admin scope is NOT required by default in Enterprise environments. It\n    # is required by default everywhere else.\n    #\n    # Returns a Boolean.\n    def require_site_admin_scope\n      return @require_site_admin_scope if defined?(@require_site_admin_scope)\n      @require_site_admin_scope = (!!ENV[\"REQUIRE_SITE_ADMIN_SCOPE\"] || !enterprise?)\n    end\n    attr_writer :require_site_admin_scope\n    alias :require_site_admin_scope? :require_site_admin_scope\n\n    attr_writer :stafftools_sessions_enabled\n    def stafftools_sessions_enabled?\n      return @stafftools_sessions_enabled if defined?(@stafftools_sessions_enabled)\n      @stafftools_sessions_enabled = !enterprise?\n    end\n\n    attr_writer :hookshot_enabled\n    def hookshot_enabled?\n      @hookshot_enabled ||= !enterprise?\n    end\n\n    attr_writer :hook_limit\n    def hook_limit\n      @hook_limit ||= enterprise? ? 250 : 20\n    end\n\n    attr_writer :downloads_enabled\n    def downloads_enabled?\n      @downloads_enabled ||= !enterprise?\n    end\n\n    attr_writer :mirror_replicants\n    def mirror_replicants?\n      @mirror_replicants ||= Rails.development?\n    end\n\n    # Are repositories stored in name-with-owner order on disk?\n    attr_writer :nwo_repo_storage\n    def nwo_repo_storage?\n      enterprise?\n    end\n\n    def trusted_oauth_apps_org_name\n      if GitHub.enterprise? && !Rails.test?\n        \"github-enterprise\"\n      else\n        \"github\"\n      end\n    end\n\n    # Find the trusted Organization.  This Organization is expected to exist already.\n    #\n    # Returns an Organization or nil\n    def trusted_oauth_apps_owner\n      # Use Organization.unscoped to avoid inheriting any temporary scopes.\n      # For example, in the following code:\n      #\n      #     current_user.organizations.oauth_app_policy_met_by(current_app)\n      #\n      # Organization.find_by_login(\"github\") runs this query:\n      #\n      #     SELECT `users`.*\n      #       FROM `users`\n      #       WHERE `users`.`type` IN ('Organization') AND\n      #             `users`.`id` IN (<current_user.id>) AND\n      #             `users`.`login` = 'github'\n      #       LIMIT 1\n      #\n      # and Organization.unscoped.find_by_login runs this query:\n      #\n      #    SELECT `users`.*\n      #      FROM `users`\n      #      WHERE `users`.`type` IN ('Organization') AND\n      #            `users`.`login` = 'github'\n      #      LIMIT 1\n      Organization.unscoped.find_by_login(trusted_oauth_apps_org_name)\n    end\n\n    def two_factor_auth_enabled?\n      return @two_factor_auth_enabled if defined?(@two_factor_auth_enabled)\n      @two_factor_auth_enabled = true\n    end\n    attr_writer :two_factor_auth_enabled\n\n    # Allow TOTPs to be reused within the window for which they are valid?\n    #\n    # Returns boolean.\n    def two_factor_allow_reuse?\n      true\n    end\n\n    def traffic_graphs_enabled?\n      @traffic_graphs_enabled ||= !enterprise?\n    end\n    attr_writer :traffic_graphs_enabled\n\n    # Whether to use and show git preview features or not.\n    # For instance bitmaps.\n    #\n    # Returns false for enterprise.\n    def git_preview_features?\n      !enterprise?\n    end\n\n    # Whether a (non admin) user can create organizations on the install\n    # The user handling bits are in model_settings_dependency.\n    #\n    # Returns true for .com, uses setting if it exists.\n    def user_can_create_organizations?\n      !GitHub.enterprise? || GitHub.org_creation_enabled?\n    end\n\n    # Whether Enterprise only API functionality should be enabled\n    def enterprise_only_api_enabled?\n      GitHub.enterprise?\n    end\n\n    # Whether or not you can disable git ssh access controls\n    def can_disable_git_ssh_access?\n      GitHub.enterprise?\n    end\n\n    def git_repld_enabled?\n      return @git_repld_enabled if defined? @git_repld_enabled\n      @git_repld_enabled = false\n    end\n    attr_writer :git_repld_enabled\n\n    # Whether organization invitations can be bypassed.\n    #\n    # This feature is enabled on Enterprise in order to\n    # allow Owners to add employees directly to their Organizations.\n    def bypass_org_invites_enabled?\n      GitHub.enterprise?\n    end\n\n    # The organization invitation rate limit for new organizations (less than\n    # a month old).\n    def org_invite_rate_limit_untrusted\n      @org_invite_rate_limit_untrusted ||= (ENV[\"ORG_INVITE_RATE_LIMIT_UNTRUSTED\"] || 50).to_i\n    end\n\n    # The organization invitation rate limit for organizations older than the\n    # required age minimum.\n    def org_invite_rate_limit_trusted\n      @org_invite_rate_limit_trusted ||= (ENV[\"ORG_INVITE_RATE_LIMIT_TRUSTED\"] || 500).to_i\n    end\n\n    # The organization invitation rate limit for organizations on paying plans.\n    def org_invite_rate_limit_paying\n      @org_invite_rate_limit_paying ||= (ENV[\"ORG_INVITE_RATE_LIMIT_PAYING\"] || 500).to_i\n    end\n\n    def repository_invitation_rate_limit\n      @repository_invitation_rate_limit ||= (ENV[\"REPOSITORY_INVITATION_RATE_LIMIT\"] || 50).to_i\n    end\n\n    # Are user invitations enabled in this environment?\n    #\n    # User invitations are currently only enabled on Enterprise, when using\n    # non-external authentication.\n    def user_invites_enabled?\n      GitHub.enterprise? && !GitHub.auth.external?\n    end\n\n    # Devtools don't currently exist in Enterprise\n    def devtools_enabled?\n      @devtools_enabled = !enterprise?\n    end\n    attr_writer :devtools_enabled\n\n    # If graphite is disabled, `GitHub.stats` is configured with a client that\n    # is a no-op for every operation.\n    def graphite_disabled?\n      return true if Rails.test?\n      ENV[\"GRAPHITE_DISABLED\"] == \"1\"\n    end\n\n    # The list of stats hosts to connect to.\n    # Configured in `environments/*.rb`\n    attr_accessor :stats_hosts\n\n    # A whitelist of allowed stats keys. Only applied if this is set, otherwise\n    # no whitelisting occurs.\n    attr_accessor :stats_whitelist\n\n    def production_stats_hosts\n      [\"metrics-collector-a-cp1-prd.iad.github.net.:8226\",\n       \"metrics-collector-b-cp1-prd.iad.github.net.:8226\",\n       \"metrics-collector-c-cp1-prd.iad.github.net.:8226\"]\n    end\n\n    # Is datadog metric reporting enabled or not. dogstats is configured with a\n    # client that noops all calls if this is not true.\n    def datadog_enabled?\n      return @datadog_enabled if defined?(@datadog_enabled)\n      @datadog_enabled = true\n    end\n    attr_accessor :datadog_enabled\n\n    # String URL of the semiotic service (golang webserver that shells out to semantic).\n    def semiotic_url\n      @semiotic_url ||= ENV.fetch(\"SEMIOTIC_URL\", \"http://127.0.0.1:8001\")\n    end\n    attr_writer :semiotic_url\n\n    # String URL of the semiotic service running on kubernetes.\n    def semiotic_kubes_url\n      @semiotic_kubes_url ||= ENV.fetch(\"SEMIOTIC_KUBE_URL\", \"http://127.0.0.1:8001\")\n    end\n    attr_writer :semiotic_kubes_url\n\n    # String shared token with github/semiotic for all api actions\n    def semiotic_token\n      @semiotic_token ||= ENV.fetch(\"SEMIOTIC_TOKEN\", \"octocat\")\n    end\n    attr_writer :semiotic_token\n\n    # ======================================================================== #\n    #                         END OF CONFIG OPTIONS                            #\n    # ======================================================================== #\n\n    ##\n    # Utilities\n\n    # The environment configuration. In dotcom production, this is backed by the\n    # gpanel `.app-config/production.plain` file directly rather than using ENV,\n    # and supports per-datacenter prefixes.\n    # In all other cases it's simply a wrapper for ENV.\n    def environment\n      return @environment if @environment\n      plain_gpanel_config = \"#{Rails.root}/.app-config/#{Rails.env}.plain\"\n      if Rails.production? && !enterprise? && File.file?(plain_gpanel_config)\n        @environment = Config::DatacenterPrefixEnvironment.new \\\n          environment: Config::GpanelConfig.new(File.read(plain_gpanel_config))\n      else\n        @environment = Config::DatacenterPrefixEnvironment.new # just wrap ENV\n      end\n    end\n    attr_writer :environment\n\n    # Reload the config.yml values and set each config attribute.\n    def reload_config\n      import_yaml_config \"#{Rails.root}/config.yml\"\n    end\n\n    # Load config written to disk by heaven gPanel support\n    def reload_gpanel_config\n      gpanel_config = \"#{Rails.root}/.app-config/#{Rails.env}.rb\"\n      if File.file? gpanel_config\n        load gpanel_config\n        @environment = nil\n      end\n    end\n\n    # Reset all memoized configuration variables to an undefined state, causing\n    # them to be re-established the next time their accessed. This also calls\n    # #reload_config to load in config values from the global and environment\n    # config.yml files.\n    def reset_config!\n      instance_variables.each { |varname| remove_instance_variable(varname) }\n      # reset ldap so we can reload the config.\n      load_environment_config\n    end\n\n    # Loads the environment specific config file. The RAILS_ROOT/config.yml\n    # values are loaded twice: before the environment config so that global\n    # config is initially available for the environment file, and after the\n    # environment config so that global values override environment values.\n    def load_environment_config\n      if defined? Rails.env\n        reload_config\n\n        reload_gpanel_config\n\n        # Enterprise doesn't ship production.rb environment file to avoid exposing\n        # sensitive credentials.\n        load \"github/config/environments/#{Rails.env}.rb\" unless Rails.production? && enterprise?\n        load \"github/config/environments/enterprise.rb\" if enterprise?\n\n        # load the config.yml values in over the environment specific config.\n        reload_config\n      else\n        raise LoadError, \"Rails.env is not set\"\n      end\n    end\n\n    # Imports config values from the YAML file specified into the current\n    # config. The config file may include values for any attributes defined in\n    # this module.\n    #\n    # file - The string path to the YAML file to load.\n    #\n    # Returns nothing.\n    # Raises RuntimeError when the config file includes an unknown key.\n    #\n    # Examples:\n    #   The following YAML file would cause the ssl config attribute to be set\n    #   true and the host_name attribute to be set to \"github.apple.com\":\n    #\n    #   ssl:       true\n    #   host_name: github.apple.com\n    def import_yaml_config(file)\n      load_yaml_config(file).each do |key, value|\n        if respond_to?(\"#{key}=\")\n          __send__(\"#{key}=\", value)\n        else\n          fail \"unknown config value: #{key.inspect}\"\n        end\n      end\n    end\n\n    # Load a YAML file if it exists and return its deserialized contents.\n    #\n    # Returns a Hash of config values.\n    def load_yaml_config(file)\n      if !Rails.test? && File.exist?(file)\n        require \"yaml\"\n        YAML.load_file(file)\n      else\n        {}\n      end\n    end\n\n    # Public: Determine whether the limit in mentioned users in\n    # comments/issues/pull request... is enabled or no.\n    #\n    # Enterprise is the most common case where we want to disable the spam\n    # validation because the number of users are determined by the license.\n    def prevent_mention_spam?\n      !enterprise?\n    end\n\n    # Revoke OAuth accesses and SSH keys for new staff?\n    def new_staff_precautions?\n      !enterprise?\n    end\n\n    # We only want to enforce employee requirements when this is *not*\n    # Enterprise.\n    def require_employee_for_site_admin?\n      !GitHub.enterprise?\n    end\n\n    def require_two_factor_for_site_admin?\n      return @require_two_factor_for_site_admin if defined? @require_two_factor_for_site_admin\n      @require_two_factor_for_site_admin = !GitHub.enterprise? && !Rails.development? && !Rails.test?\n    end\n    attr_writer :require_two_factor_for_site_admin\n\n    # No 2FA SMS in enterprise\n    def two_factor_sms_enabled?\n      !enterprise?\n    end\n\n    # Disable Mirror repos on Enterprise\n    def mirrors_enabled?\n      !enterprise?\n    end\n\n    # Enable unlimited git.maxobjectsize in Enterprise\n    def unlimited_max_object_size_enabled?\n      enterprise?\n    end\n\n    def cluster_web_server?\n      return @cluster_web_server if defined? @cluster_web_server\n      @cluster_web_server = false\n    end\n    attr_writer :cluster_web_server\n\n    def cluster_git_server?\n      return @cluster_git_server if defined? @cluster_git_server\n      @cluster_git_server = false\n    end\n    attr_writer :cluster_git_server\n\n    def cluster_pages_server?\n      return @cluster_pages_server if defined? @cluster_pages_server\n      @cluster_pages_server = false\n    end\n    attr_writer :cluster_pages_server\n\n    # IP addresses that service hooks are sent from.\n    #\n    # This is returned from the API endpoint\n    # and listed on the service hooks page.\n    def hook_ips\n      [\n        \"192.30.252.0/22\",\n        \"185.199.108.0/22\"\n      ]\n    end\n\n    # IP addresses that users connect to for git operations\n    def git_ips\n      [\n        \"192.30.252.0/22\",\n        \"185.199.108.0/22\"\n      ]\n    end\n\n    # IP addresses for GitHub Pages' A records.\n    def a_record_ips\n      [\n        \"192.30.252.153/32\",\n        \"192.30.252.154/32\"\n      ]\n    end\n\n    # IP addresses that the importer connects from.\n    def porter_worker_ips\n      [\n        \"54.87.5.173\",     # porter-worker13-ue1-prd.aws.github.net\n        \"54.166.52.62\",    # porter-worker14-ue1-prd.aws.github.net\n        \"23.20.92.3\",      # porter-worker15-ue1-prd.aws.github.net\n      ]\n    end\n\n    attr_accessor :spamurai_key\n\n    def spamurai_url\n      \"https://spamurai:#{spamurai_key}@spamurai.breadsticks.kube-service.github.net\"\n    end\n\n    # are we running on the primary node of a fileserver pair?\n    def on_primary_file_server?\n      File.directory?(PRIMARY_FS_TEST_DIR) || local_host_name_short =~ /^github-dfs/\n    end\n\n    # Public: Is Backscatter enabled?\n    #\n    # In enterprise, returns false\n    # In production, checks the configured datacenter\n    # Otherwise returns true\n    def backscatter_enabled?\n      if GitHub.enterprise?\n        false\n      elsif Rails.production?\n        backscatter_datacenter.to_s.downcase == GitHub.datacenter\n      else\n        true\n      end\n    end\n\n    # Public: What datacenter is backscatter enabled for?\n    #\n    # Until such time as backscatter's back-end storage system (currently\n    # transient redis) changed to handle multiple datacenters, only run\n    # backscatter in the primary datacenter, configured via BACKSCATTER_DATACENTER.\n    def backscatter_datacenter\n      GitHub.environment[\"BACKSCATTER_DATACENTER\"]\n    end\n\n    # Public: Is scientist enabled?\n    #\n    # In enterprise, returns false\n    # In production, checks the configured datacenter\n    # Otherwise returns true\n    def scientist_enabled?\n      if GitHub.enterprise?\n        false\n      elsif Rails.production?\n        scientist_datacenter.to_s.downcase == GitHub.datacenter\n      else\n        true\n      end\n    end\n\n    # Public: What datacenter is scientist enabled for?\n    #\n    # Until such time as scientist's back-end storage system (currently\n    # transient redis) changed to handle multiple datacenters, only run\n    # scientist in the primary datacenter, configured via SCIENTIST_DATACENTER.\n    def scientist_datacenter\n      GitHub.environment[\"SCIENTIST_DATACENTER\"]\n    end\n\n    # Public: Is performance profiling enabled?\n    attr_accessor :profiling_enabled\n    alias profiling_enabled? profiling_enabled\n\n    # Public: Is the performance stats UI enabled?\n    attr_accessor :stats_ui_enabled\n    alias stats_ui_enabled? stats_ui_enabled\n\n    # Public: which repository networks do we never want to be considered public?\n    #\n    # This allows us to provide an extra level of protection to make sure GitHub's\n    # most sensitive repositories aren't accidentally turned public.  So, even\n    # if visibility is toggled on these, they will always be treated as private\n    # repositories.\n    def never_public_networks\n      return [].freeze if GitHub.enterprise?\n\n      [\"github/github\", \"github/puppet\"].freeze\n    end\n\n   # Public: the ids of the repository networks we never want to be considered public\n   def never_public_network_ids\n     return @never_public_network_ids if defined? @never_public_network_ids\n\n     networks = GitHub.never_public_networks\n     ids = networks.map { |nwo| Repository.nwo(nwo).try(:network_id) }\n     @never_public_network_ids = ids.compact.uniq.freeze\n   end\n\n   def reset_never_public_network_ids\n     remove_instance_variable \"@never_public_network_ids\" if defined? @never_public_network_ids\n   end\n\n    # Accounts or people that work for GitHub that we don't want\n    # to publicly display as staff or be present on the team page.\n    def hidden_teamsters\n      @hidden_teamsters ||= %w(evilshawn ghmonitor gregose-tmp hubot ice799 maki1022 mayashino monitors StreamingEagle boxen-ci btoews)\n    end\n\n    def hidden_teamster?(user)\n      hidden_teamsters.include?(user.login)\n    end\n\n    # Public: feature flag for DetectCredentialsInPush.\n    def credential_detection_enabled?\n      !GitHub.enterprise?\n    end\n\n    def max_ui_pagination_page\n      MAX_UI_PAGINATION_PAGE\n    end\n\n    # We're using the Shopify/verdict gem for storing associations for A/B tests (and other\n    # science experiments on users that have test/control groups). The storage for experiments\n    # is pluggable in verdict; currently, we'll write to MySQL tables behind the scenes.\n    def user_experiment_storage\n      @user_experiment_storage ||= GitHub::UserResearch::ExperimentDatabaseStorage.new\n    end\n\n    def user_experiments_enabled?\n      return @user_experiments_enabled if defined?(@user_experiments_enabled)\n      @user_experiments_enabled = true\n    end\n    attr_writer :user_experiments_enabled\n\n    def content_creation_rate_limiting_enabled?\n      return @content_creation_rate_limiting_enabled if defined?(@content_creation_rate_limiting_enabled)\n      @content_creation_rate_limiting_enabled = !GitHub.enterprise?\n    end\n    attr_writer :content_creation_rate_limiting_enabled\n\n    # Request parameters to filter from logs and exceptions\n    #\n    # These are filtered by Rails based on a substring match\n    def filtered_params\n      [:password, :token, :credit_card, :value, :oauth_verifier, :bt_signature]\n    end\n\n    def merge_matrix_pull_request\n      if ENV[\"MERGE_BUTTON_MATRIX_PULL_REQUEST_ID\"]\n        pull = PullRequest.find(ENV[\"MERGE_BUTTON_MATRIX_PULL_REQUEST_ID\"])\n      elsif Rails.env.development?\n        repo = Repository.find_by_name_with_owner(\"github/linguist\")\n        pull = repo.pull_requests.last\n      end\n    end\n\n    def rails_3_2?\n      rails_version_major == 3 && rails_version_minor == 2\n    end\n\n    def rails_4?\n      rails_version_major == 4 && rails_version_minor == 0\n    end\n    alias_method :rails_4_0?, :rails_4?\n\n    def rails_4_1?\n      rails_version_major == 4 && rails_version_minor == 1\n    end\n\n    def rails_4_2?\n      rails_version_major == 4 && rails_version_minor == 2\n    end\n\n    def rails_5?\n      rails_version_major == 5 && rails_version_minor == 0\n    end\n    alias_method :rails_5_0?, :rails_5?\n\n    def rails_version_major\n      Rails::VERSION::MAJOR\n    end\n    private :rails_version_major\n\n    def rails_version_minor\n      Rails::VERSION::MINOR\n    end\n    private :rails_version_minor\n\n    def origin_verification_enabled?\n      !enterprise?\n    end\n\n    # When SameSite cookie support is first deployed, any initial request that\n    # does CSRF validation will fail, since the strict SameSite cookie will not\n    # be set yet. This isn't a problem for dotcom, as we currently hide this\n    # feature behind a feature flag. So, we will have several weeks to allow all\n    # users to start receiving both the normal session cookie AND the new strict\n    # SameSite cookie. As a result, we can be confident everyone already has\n    # both cookies when we ship the feature. But, on Enterprise, this isn't the\n    # case. So, for now, we will disable support. Maybe we can enable it after a\n    # few releases and/or if we warn people when they upgrade.\n    def same_site_cookie_verification_enabled?\n      !enterprise? && same_site_cookie_enabled?\n    end\n\n    # Even if we are not validating SameSite cookies (i.e.\n    # `same_site_cookie_verification_enabled?` is `false`), we can still set the\n    # cookie for future use. However, since we are using cookie prefixes with\n    # our SameSite cookie implementation, we choose to only set the SameSite\n    # cookie for installations that have SSL enabled.\n    def same_site_cookie_enabled?\n      ssl?\n    end\n\n    def flipper_ui_enabled?\n      return @flipper_ui_enabled if defined?(@flipper_ui_enabled)\n      @flipper_ui_enabled = true\n    end\n    attr_writer :flipper_ui_enabled\n\n    def request_tracing_enabled?\n      return @request_tracing_enabled if defined?(@request_tracing_enabled)\n      @request_tracing_enabled = true\n    end\n    attr_writer :request_tracing_enabled\n\n    def request_limiting_enabled?\n      @request_limiting_enabled\n    end\n    attr_writer :request_limiting_enabled\n\n    def chatterbox_enabled?\n      return @chatterbox_enabled if defined?(@chatterbox_enabled)\n      @chatterbox_enabled = true\n    end\n    attr_writer :chatterbox_enabled\n\n    # Use small_primes to get a list of small primes that can be used for basic\n    # RSA modulus validation.\n    def small_primes\n      @small_primes ||= Prime.first(10000).freeze\n    end\n\n    def allow_cross_origin_referrer_leak?\n      !enterprise?\n    end\n\n    def read_only?\n      return true if Thread.current[:github_read_only_mode]\n      return @read_only if defined?(@read_only)\n\n      @read_only = File.exist?(Rails.root.join(\"tmp/readonly.txt\"))\n    end\n    attr_writer :read_only\n\n    def resque_redis_disabled?\n      @resque_redis_disabled ||= GitHub.environment[\"#{GitHub.role.upcase}_RESQUE_REDIS_DISABLED\"] == \"1\"\n    end\n\n    def reset_resque_redis_disabled\n      @resque_redis_disabled = nil\n    end\n\n    def websocket_redis_disabled?\n      @websocket_redis_disabled ||= GitHub.environment[\"#{GitHub.role.upcase}_WEBSOCKET_REDIS_DISABLED\"] == \"1\"\n    end\n\n    def reset_websocket_redis_disabled\n      @websocket_redis_disabled = nil\n    end\n\n    def mysql_primary_disabled?\n      @mysql_primary_disabled ||= GitHub.environment[\"#{GitHub.role.upcase}_MYSQL_PRIMARY_DISABLED\"] == \"1\"\n    end\n\n    def reset_mysql_primary_disabled\n      @mysql_primary_disabled = nil\n    end\n\n    # Given a github host, attempt to determine the site. Originally added to\n    # allow for tagging the rpc_site on all MySQL queries to aid in determining\n    # cross-site queries.\n    #\n    # Examples:\n    #\n    #   GitHub.site_from_host(\"db-mysql-9082342.cp1-iad.github.net\") => \"cp1-iad\"\n    #   GitHub.site_from_host(\"db-mysql-c0c881d.sdc42-sea.github.net\") => \"sdc42-sea\"\n    #\n    # Returns String representing the site of the host.\n    def site_from_host(host)\n      site = if host =~ /cp1-prd\\.iad\\.github\\.net/\n        \"cp1-iad\"\n      else\n        match = /(?<site>[^\\.]+)\\.github\\.net\\Z/i.match(host)\n        match && match[:site]\n      end\n\n      site && SITE_WHITELIST.include?(site) ? site : \"unknown\"\n    end\n\n    def areas_of_responsibility\n      @areas_of_responsibility ||= begin\n        yaml_path = Rails.root.join(\"docs\", \"areas-of-responsibility.yaml\")\n        YAML.load_file(yaml_path).freeze\n      end\n    end\n\n    # Is operator mode enabled for all users?\n    #\n    # When operator mode is enabled, debugging output is displayed to the\n    # client during Git push operations.\n    def global_operator_mode_enabled?\n      !!@global_operator_mode_enabled\n    end\n    attr_writer :global_operator_mode_enabled\n\n    # Is the local version of ssh-keygen old enough to use MD5 fingerprints\n    # by default?\n    def old_ssh_keygen?\n      @old_ssh_keygen\n    end\n    attr_writer :old_ssh_keygen\n\n    # Ops gets paged if there's < 10 GB available\n    SHARD_SLACK_SPACE = 15.0 * (1 << 30)\n\n    ENTERPRISE_SHARD_SLACK_SPACE = 2 * (1 << 30)\n\n    # The amount of slack disk space required\n    # on fileservers, in KB.\n    def shard_slack_space\n      gb = if GitHub.enterprise?\n        ENTERPRISE_SHARD_SLACK_SPACE\n      else\n        SHARD_SLACK_SPACE\n      end\n\n      gb / (1 << 10)\n    end\n\n    # What port should we use in the upstream for proxies when pointing mysql\n    # in the app at toxiproxy. Checks for env var, then falls back to mysql's\n    # default port.\n    #\n    # NOTE: This is only used for develompment, test and ci to simulate network\n    # issues by proxying through toxiproxy.\n    def toxiproxy_upstream_mysql_port\n      @toxiproxy_upstream_mysql_port ||= ENV.fetch(\"TOXIPROXY_UPSTREAM_MYSQL_PORT\", 3306)\n    end\n    attr_writer :toxiproxy_upstream_mysql_port\n\n    def cas_host\n      url_origin(cas_url)\n    end\n\n    # Header image for Google Inbox repository bundles.\n    #\n    # See: https://github.com/github/workflow/issues/402\n    def google_inbox_header_image\n      \"https://cloud.githubusercontent.com/assets/143418/17495839/a5054eac-5d88-11e6-95fc-7290892c7bb5.png\"\n    end\n\n    # Avatar image for Google Inbox repository bundles used to identify\n    # GitHub-specific bundes.\n    #\n    # See: https://github.com/github/workflow/issues/402\n    def google_inbox_avatar_image\n      \"https://cloud.githubusercontent.com/assets/143418/15842166/7c72db34-2c0b-11e6-9aed-b52498112777.png\"\n    end\n\n    # Allow overriding the number of accesses an OAuth application is allowed to\n    # create for a given app/user/scope combination.\n    def oauth_access_limit_overrides_enabled?\n      Rails.production? && !enterprise?\n    end\n\n    # Whether or not this server will primarily run gitauth requests\n    def gitauth_host?\n      !!ENV[\"GITAUTH\"]\n    end\n\n    # The number of unicorn workers to run on an enterprise instance.\n    def enterprise_unicorn_worker_count\n      if gitauth_host?\n        (ENV[\"ENTERPRISE_GITAUTH_WORKERS\"] || 1).to_i\n      else\n        (ENV[\"ENTERPRISE_GITHUB_WORKERS\"] || 4).to_i\n      end\n    end\n\n    # This host is a staff host\n    def staff_host?\n      ENV[\"STAFF_ENVIRONMENT\"] != nil || local_host_name.split(\".\").first =~ /^github-staff\\d+/\n    end\n\n    # This host is an arch host\n    def arch_host?\n      local_host_name =~ /^github-arch/\n    end\n\n    # This host is a babeld host\n    def babeld_host?\n      local_host_name =~ /^github-babel/\n    end\n\n    # The parsed contents of /etc/github/metadata.json (a Hash), or nil\n    def server_metadata\n      return @_parsed_metadata_json if defined?(@_parsed_metadata_json)\n      begin\n        @_parsed_metadata_json = read_metadata\n      rescue\n        @_parsed_metadata_json = {}\n      end\n    end\n\n    # The region where the server is located\n    def server_region\n      server_metadata[\"region\"]\n    end\n\n    # This host is running in production\n    def production_host?\n      server_metadata[\"env\"] == \"production\"\n    end\n\n    # The number of unicorn workers to spin up for this server.\n    def unicorn_worker_count\n      if (worker_count = ENV[\"GH_UNICORN_WORKER_COUNT\"])\n        return worker_count.to_i\n      end\n\n      worker_count = begin\n        Integer(File.read(\"/etc/github/unicorn_worker_count\"))\n      rescue Errno::ENOENT, Errno::EPERM, ArgumentError\n        nil\n      end\n      unless worker_count.nil?\n        return worker_count\n      end\n\n      if GitHub.enterprise? && Rails.production?\n        return enterprise_unicorn_worker_count\n      end\n\n      if staff_host?\n        return 3\n      end\n\n      if gitauth_host?\n        return 1 unless Rails.production?\n        return (3 * Etc.nprocessors) if babeld_host?\n        return 12 if production_host?\n        return 2\n      end\n\n      if Rails.production?\n        return (2 * Etc.nprocessors) if production_host?\n        return 4\n      end\n      2\n    end\n\n    # Should unicorn do its check_client_connection thing?\n    #   https://engineering.shopify.com/17489012-what-does-your-webserver-do-when-a-user-hits-refresh#axzz2q3YWu2Jr\n    def unicorn_check_client_connection?\n      Rails.development? || Rails.test? || arch_host?\n    end\n\n    def dependency_graph_enabled?\n      !GitHub.enterprise? && (GitHub.dependency_graph_api_url.present? ||\n                              Rails.development?)\n    end\n\n    def dependency_graph_api_url\n      ENV[\"DEPENDENCY_GRAPH_API_URL\"] || @dependency_graph_api_url\n    end\n    attr_writer :dependency_graph_api_url\n\n    # Munger is an application that provides access to data from the data\n    # science pipeline: https://github.com/github/munger\n    # It is used for things like getting topic suggestions in the GitHub.com\n    # environment and doesn't run on Enterprise.\n    def munger_available?\n      !enterprise?\n    end\n\n    # The topics data API is supplied by the github/munger application\n    attr_accessor :munger_url\n\n    # Whether to log the call stack when auto_fqdn is called\n    attr_accessor :log_auto_fqdn_caller\n\n    # Whether or not this is a Kubernetes cluster. To determine this, we look\n    # for a file created by the ServiceAccountAdmissionController.\n    # https://kubernetes.io/docs/admin/service-accounts-admin/#service-account-admission-controller\n    def kube?\n      return @kube if defined?(@kube)\n      namespace_file = \"/var/run/secrets/kubernetes.io/serviceaccount/namespace\"\n      @kube = File.file?(namespace_file)\n    end\n\n    def kubernetes_cluster_name\n      read_metadata[\"kubernetes_cluster_name\"]\n    end\n\n    # Whether or not the requests are to a host that has been enabled\n    # specifically for api read-only traffic\n    def api_read_only?\n      GitHub.resque_redis_disabled? &&\n        GitHub.websocket_redis_disabled? &&\n        GitHub.mysql_primary_disabled? &&\n        GitHub.elasticsearch_access_raises?\n    end\n\n    def platform_graphql_service_tokens=(tokens)\n      @platform_graphql_service_tokens = tokens.split(\",\")\n    end\n\n    def platform_graphql_service_tokens\n      @platform_graphql_service_tokens ||= []\n    end\n\n    def platform_graphql_logging_enabled?\n      @platform_graphql_logging_enabled || !GitHub.enterprise?\n    end\n    attr_writer :platform_graphql_logging_enabled\n\n    def valid_graphql_service_token?(token)\n      valid_token = false\n      GitHub.platform_graphql_service_tokens.each do |t|\n        if SecurityUtils.secure_compare(t, token)\n          valid_token = true\n        end\n      end\n      valid_token\n    end\n\n    def mysql_read_only_connection?\n      Thread.current[:mysql_read_only_connection] == true\n    end\n\n    def mysql_read_only_connection=(value)\n      Thread.current[:mysql_read_only_connection] = value\n    end\n\n    def mysql_switched_from_read_to_write_connection?\n      Thread.current[:mysql_switched_from_read_to_write_connection] == true\n    end\n\n    def mysql_switched_from_read_to_write_connection=(value)\n      Thread.current[:mysql_switched_from_read_to_write_connection] = value\n    end\n\n    def nsq_enabled?\n      @nsq_enabled ||= ENV.fetch(\"NSQ_ENABLED\", \"0\") == \"1\"\n    end\n    attr_writer :nsq_enabled\n\n    def nsqlookupd_urls\n      @nsqlookupd_urls ||= ENV.fetch(\"NSQLOOKUPD_URLS\", \"127.0.0.1:4161\").split(\",\")\n    end\n    attr_writer :nsqlookupd_urls\n\n    def nsqd_url\n      @nsqd_url ||= ENV.fetch(\"NSQD_URL\", \"127.0.0.1:4150\")\n    end\n    attr_writer :nsqd_url\n  end\nend\n\n# bring in otherwise untouched modules\nrequire \"github/config/gpanel_config\"\nrequire \"github/config/datacenter\"\nrequire \"github/config/datacenter_prefix_environment\"\nrequire \"github/config/fastly\"\nrequire \"github/config/importers\"\nrequire \"github/config/legacy_textile_formatting\"\nrequire \"github/config/migration\"\nrequire \"github/config/render\"\nrequire \"github/config/spokes\"\nrequire \"github/config/support_link\"\nrequire \"github/config/logging\"\nrequire \"github/config/request_limits\"\nrequire \"github/config/rate_limits\"\nrequire \"github/config/tracer\"\n","language":"Ruby"},"before":{"path":"lib/github/config.rb","content":"# rubocop:disable Style/FrozenStringLiteralComment\n\nrequire \"etc\"\nrequire \"uri\"\nrequire \"set\"\nrequire \"socket\"\nrequire \"prime\"\n\nmodule GitHub\n  # GitHub global configuration\n  #\n  # This is mixed into the GitHub module such that an attribute \"blah\" defined\n  # here is available at GitHub.blah and GitHub.blah=. All GitHub specific global\n  # configuration should be defined here and set via one of the files defined\n  # below.\n  #\n  # The load order for config values is (each overriding the last):\n  # - Default values defined in this module\n  # - Overrides in config/environment.rb\n  # - Overrides in config/environments/<env>.rb\n  # - Overrides in RAILS_ROOT/config.yml\n  #\n  # The RAILS_ROOT/config.yml file may set any config attribute defined in this\n  # module. It's used primarily to customize FI installations.\n  #\n  # After boot, these properties should be treated as static and MUST NOT be\n  # altered.\n  #\n  # When adding new configuration items, please document them. Include\n  # information on what they're used for, default values, and example values\n  # for a couple different environments if possible.\n  #\n  # NOTE This file is loaded as part of the config/basic.rb lightweight environment.\n  # Do not add any additional library requires here.\n  module Config\n    ELASTICSEARCH_ACCESS_VALUES    = [:allowed, :ignored, :raises] # for validation\n    MAX_UI_PAGINATION_PAGE         = 100\n    PRIMARY_FS_TEST_DIR            = \"/data/repositories/0/lost+found\"\n    MONITORS_USER_ID               = 1162581 # the user id for our special Monitors account\n    HUBOT_USER_ID                  = 480938 # the user id for our special robot account\n    MIRROR_PUSHER                  = \"hubot\" # the login for recording mirror \"pushes\"\n    DGIT_COPIES                    = 3\n    DESKTOP_FETCH_INTERVAL         = 5 # in minutes\n\n    # Set of known sites (datacenters) that can be return values of site_from_host.\n    SITE_WHITELIST = Set[\n      \"cp1-iad\",\n      \"sdc42-sea\",\n    ]\n\n    # Raised on data access when a datastore is configured to be inaccessible,\n    # e.g. in a secondary datacenter.\n    class UnexpectedDatastoreAccess < StandardError; end\n\n    # The current runtime mode object. Used to determine whether we're running\n    # under dotcom or enterprise mode and also allows dynamically switching\n    # modes in development server environments.\n    #\n    # Returns a GitHub::Runtime object.\n    def runtime\n      @runtime ||= GitHub::Runtime.new\n    end\n\n    # Boolean attribute specifying whether the site is in SSL mode. This is\n    # typically set true explicitly in production environments.\n    #\n    # Returns true if SSL is enabled for the site, false otherwise.\n    def ssl?\n      return @ssl if defined?(@ssl)\n      ENV[\"GH_SSL\"]\n    end\n    attr_writer :ssl\n    alias ssl ssl?\n\n    # Public: Return appropriate URI scheme for SSL mode.\n    #\n    # Returns String.\n    def scheme\n      ssl? ? \"https\" : \"http\"\n    end\n\n    # Whether to run background jobs in the calling process. Useful in\n    # development / test only.\n    attr_accessor :inline_jobs\n    alias inline_jobs? inline_jobs\n\n    # Is the current environment connected to the public internet? This is\n    # useful primarily in development environments where loading gravatars and\n    # other external items may be skipped. This should always be set true\n    # everywhere except in development and enterprise instances to prevent the\n    # slow ping check.\n    #\n    # Returns true if external internet access is available, false otherwise.\n    def online?\n      return @online if defined?(@online)\n      return false if enterprise?\n      return google_reachable? if Rails.development?\n\n      true\n    end\n    attr_writer :online\n    alias online online?\n\n    def google_reachable?\n      @online = begin\n        Timeout.timeout(1) do\n          s = TCPSocket.new(\"google.com\", 80)\n          s.close\n        end\n        true\n      rescue Errno::ECONNREFUSED\n        true\n      rescue Timeout::Error, StandardError\n        false\n      end\n    end\n\n    # The test environment's parallel execution number.\n    #\n    # Returns the environment number as a string but only in test environments.\n    # In other environments this method returns nil.\n    def test_environment_number\n      Rails.env.test? && (ENV[\"TEST_ENV_NUMBER\"] || \"0\")\n    end\n\n    # Should Mysql use alternate database(s), such as read only\n    # replica's? See also GitHub::Config::Mysql\n    #\n    # Enabled by default in production\n    def alternate_db_enabled?\n      return @alternate_db_enabled if defined?(@alternate_db_enabled)\n      @alternate_db_enabled = true\n    end\n    attr_writer :alternate_db_enabled\n\n    # Enable gravatar images throughout the site. Some enterprise customers\n    # may want to disable this for security reasons.\n    #\n    # Returns true if gravatar images should be displayed, false otherwise.\n    def gravatar_enabled?\n      return @gravatar_enabled if defined?(@gravatar_enabled)\n\n      online?\n    end\n    attr_writer :gravatar_enabled\n\n    # The base URL for all avatars. This server must implement the gravatar API. If passed\n    # a string, it will determine which gravatar subdomain to use\n    # (see https://github.com/github/github/issues/13687#issuecomment-22726044)\n    #\n    # string - An optional String that will be hashed to determine which Gravatar subdomain\n    #          should be used (0, 1 or 2).\n    #\n    # Returns a gravatar base url\n    def gravatar_url(string = nil)\n      return @gravatar_url if defined? @gravatar_url\n      subdomain = string ? Zlib.crc32(string.to_s) % 3 : 0\n      \"https://#{subdomain}.gravatar.com\"\n    end\n\n    attr_writer :gravatar_url\n\n    # Whether we are using gravatar.com or a custom avatar service.\n    #\n    # Returns true when gravatar_url ends with .gravatar.com\n    def gravatar_service?\n      gravatar_url =~ /\\.gravatar\\.com$/\n    end\n\n    # GpgVerify client instance\n    #\n    # Returns a GpgVerify instance\n    def gpg\n      return @gpg if defined?(@gpg)\n      @gpg = GpgVerify.new(GitHub.gpgverify_url)\n    end\n    attr_writer :gpg\n\n    # Host where the gpgverify HTTP service is running.\n    #\n    # Returns a url String.\n    def gpgverify_url\n      @gpgverify_url ||= \"http://127.0.0.1:8686\"\n    end\n    attr_writer :gpgverify_url\n\n    def git_signing_smime_cert_store\n      @git_signing_smime_cert_store ||= begin\n        store = OpenSSL::X509::Store.new\n        store.add_file(Certifi.where)\n        store\n      end\n    end\n\n    # Returns true if repositories require explictly accepted invitations when\n    # adding a new member.\n    def repo_invites_enabled?\n      !GitHub.enterprise?\n    end\n\n    # Whether sudo mode capabilities can be enabled.\n    #\n    # Always returns true unless our authentication method supports password\n    # verification.\n    def sudo_mode_enabled?\n      GitHub.auth.sudo_mode_enabled?\n    end\n\n    # Whether Orgs SAML SSO session (external identity session) enforcement is\n    # enabled in this environment.\n    #\n    # The feature is currently only enabled for GitHub.com (as it would be\n    # redundant with GHE's SAML SSO support).\n    #\n    # Returns Boolean.\n    def external_identity_session_enforcement_enabled?\n      !enterprise?\n    end\n\n    # If we are using an external authentication mechanism, we can delegate\n    # account lockouts to them.\n    #\n    # Returns true if account lockouts are enabled, false otherwise.\n    def lockouts_enabled?\n      !GitHub.auth.external?\n    end\n\n    # Do we block JSON responses to non-XHR requests?\n    def json_xhr_requirement_enabled?\n      !Rails.test?\n    end\n\n    # The full path to the root directory where repositories are stored.\n    def repository_root\n      @repository_root ||=\n        if Rails.development?\n          env = enterprise?? \"fi\" : Rails.env\n          File.expand_path(\"#{Rails.root}/repositories/#{env}\")\n        elsif Rails.test?\n          # tests get a clean repo root and each parallel test process gets its own\n          # directory too based on the TEST_ENV_NUMBER.\n          \"#{Rails.root}/repositories/test#{ENV['TEST_ENV_NUMBER']}\"\n        else\n          \"/data/repositories\"\n        end\n    end\n    attr_writer :repository_root\n\n    # The git repository template used when creating new repositories on\n    # disk. This contains hooks and any other files that should be present\n    # in newly created or forked repositories.\n    #\n    # Returns the full path to git repo template directory.\n    def repository_template\n      @repository_template ||=\n        if Rails.production?\n          if enterprise?\n            \"/data/github/current/lib/git-core/fi-template\".freeze\n          else\n            \"/data/github/current/lib/git-core/template_shadow\".freeze\n          end\n        else\n          if enterprise?\n            \"#{Rails.root}/lib/git-core/fi-template\".freeze\n          else\n            \"#{Rails.root}/lib/git-core/template_shadow\".freeze\n          end\n        end\n    end\n    attr_writer :repository_template\n\n    # Delegated account recovery keys used to sign/verify recovery tokens\n    attr_accessor :account_provider_public_key, :account_provider_private_key,\n      :account_recovery_provider_creds, :account_provider_symmetric_key,\n      :recovery_provider_public_key, :recovery_provider_private_key\n\n    # Earthsmoke configuration\n    attr_accessor :earthsmoke_address, :earthsmoke_cert, :earthsmoke_token\n\n    # Earthsmoke client\n    def earthsmoke\n      @earthsmoke ||= begin\n        if earthsmoke_available?\n          ::Earthsmoke::Client.new(\n            token: earthsmoke_token,\n            server: earthsmoke_address,\n            ca_file: earthsmoke_cert\n          )\n        end\n      end\n    end\n\n    # Do we have the necessary configuration information to use the earthsmoke\n    # service?\n    #\n    # Returns boolean.\n    def earthsmoke_available?\n      !earthsmoke_address.blank? &&\n        !earthsmoke_token.blank? &&\n        !earthsmoke_cert.blank? &&\n        File.file?(earthsmoke_cert)\n    end\n\n    # Used only by the old RepositoriesNetshardTransition.\n    def old_gist_repository_template\n      @old_gist_repository_template ||=\n        if Rails.production?\n          \"/data/github/current/lib/git-core/gist-template\".freeze\n        else\n          \"#{Rails.root}/lib/git-core/gist-template\".freeze\n        end\n    end\n    attr_writer :old_gist_repository_template\n\n    def gist3_repository_template\n      @gist3_repository_template ||=\n        if Rails.production?\n          \"/data/github/current/lib/git-core/gist-template\".freeze\n        else\n          \"#{Rails.root}/lib/git-core/gist-template\".freeze\n        end\n    end\n    attr_writer :gist3_repository_template\n\n    # Determine if the app is running under GitHub Enterprise. This is\n    # determined by the ENTERPRISE (or FI) environment variable being set.\n    #\n    # Returns true if running under Enterprise, false otherwise.\n    def enterprise?\n      return @enterprise if defined?(@enterprise)\n      @enterprise = GitHub.runtime.enterprise?\n    end\n    attr_writer :enterprise\n    alias fi? enterprise?\n\n    # Determines if the app is running on a non-clustered Enterprise instance\n    # Enterprise non-clustered returns true\n    # Enterprise clustered returns false\n    # github.com returns false\n    def single_instance?\n      @single_instance ||= enterprise? && Rails.development?\n    end\n    attr_writer :single_instance\n\n    # Determine if the current request is not enterprise\n    def dotcom_request?\n      !enterprise?\n    end\n\n    # Determine if the current request is for GitHub Cloud.\n    #\n    # This is going away soon...\n    #\n    # Returns Boolean\n    def cloud_request?\n      false\n    end\n\n    # Determine if the app should only show the limited Admin Center UI\n    #\n    # Returns true if running under Enterprise\n    def limited_admin_center?\n      GitHub.enterprise?\n    end\n\n    # The Basic Auth password used to access the Hosted Enterprise environment\n    # in production.\n    #\n    # Defaults to `passworD1`, set in the environment as\n    # `HOSTED_BASIC_AUTH_PASSWORD`.\n    def hosted_basic_auth_password\n      return @hosted_basic_auth_password if defined?(@hosted_basic_auth_password)\n      @hosted_basic_auth_password = ENV[\"HOSTED_BASIC_AUTH_PASSWORD\"] || \"passworD1\"\n    end\n\n    def default_request_timeout\n      @default_request_timeout ||= 10\n    end\n    attr_writer :default_request_timeout\n\n    # The read timeout for GitRPC\n    attr_accessor :gitrpc_timeout\n\n    # The max duration (in seconds) a request can take before it times out.\n    def request_timeout(env)\n      env ||= {}\n\n      return default_request_timeout if env[\"REQUEST_METHOD\"].to_s == \"GET\"\n\n      case env[\"REQUEST_PATH\"].to_s\n      # These are all request paths that take payment details like credit card\n      # params and directly call Braintree APIs. They benefit from a longer timeout.\n      # See https://github.com/github/github/pull/28356 for more context.\n      when %r{^/account/billing/update_credit_card},\n           %r{^/account/cc_update}, # May charge for yearly plan changes\n           %r{^/organizations/([^/]+)(.*)/billing/cc_update}, # May charge for yearly plan changes\n           %r{^/organizations/([^/]+)(.*)/billing/update_credit_card},\n           %r{^/stafftools/users/([^/]+)(.*)/change_plan}\n        [30, default_request_timeout].max\n      when %r{^/repositories$},  # Create repo with upsell\n           %r{^/organizations$}, # Create new paid organization\n           %r{^/join/plan$},\n           %r{^/redeem/([^/]+)(.*)$},\n           %r{^/site/custom_sleeptown$}\n        [20, default_request_timeout].max\n      else\n        default_request_timeout\n      end\n    end\n\n    # The threshhold for slow web / API requests, in seconds.  Requests that\n    # take longer than this threshold are sent to a slow bucket in haystack\n    # for reporting.\n    def slow_request_threshold\n      @slow_request_threshold ||= 2.0\n    end\n    attr_writer :slow_request_threshold\n\n    # Determine if the app is running on a employee-only unicorn.\n    #\n    # Return true on staff1.rs\n    def employee_unicorn?\n      return @employee_unicorn if defined?(@employee_unicorn)\n      @employee_unicorn = false\n    end\n    attr_writer :employee_unicorn\n\n    # Determine if the app is running on the new-style employee-only unicorn.\n    #\n    # Return true on one of the garage hosts\n    def garage_unicorn?\n      return @garage_unicorn if defined?(@garage_unicorn)\n      @garage_unicorn = false\n    end\n    attr_writer :garage_unicorn\n\n    # Return the user-facing name for GitHub based on whether or not\n    # they're looking at GitHub.com or an Enterprise installation.\n    #\n    # Returns a String\n    def flavor\n      if enterprise?\n        \"GitHub Enterprise\"\n      else\n        \"GitHub\"\n      end\n    end\n\n    # committer_name to be used for web edits/merges/reverts.\n    #\n    # Returns a String.\n    def web_committer_name\n      flavor\n    end\n\n    # committer_email to be used for web edits/merges/reverts.\n    #\n    # Returns a String.\n    def web_committer_email\n      noreply_address\n    end\n\n    # Used to determine the period of time below which an account is always\n    # considered active and within which we look for activity when considering\n    # how dormant the account is. See User#recently_active? and\n    # User#exempt_from_dormancy?\n    #\n    # Returns a time period.\n    def dormancy_threshold\n      return @dormancy_threshold if defined?(@dormancy_threshold)\n      @dormancy_threshold = (GitHub.enterprise? ? 1.month : 12.months)\n    end\n    attr_writer :dormancy_threshold\n\n    # Determine if the \"Dormant users\" page in stafftools should be displayed.\n    # This performs fairly intense operations against the entire users table,\n    # so it shouldn't be used on .com.\n    def bulk_dormant_user_suspension_enabled?\n      return @bulk_dormant_user_suspension_enabled if defined?(@bulk_dormant_user_suspension_enabled)\n      @bulk_dormant_user_suspension_enabled = GitHub.enterprise?\n    end\n    attr_writer :bulk_dormant_user_suspension_enabled\n\n    # Trusted ports are used for GitHub Enterprise to allow some diagnostics\n    # scripts to hit the API and some other staff-specific routes without\n    # authenticating.\n    #\n    # Returns true if this feature is enabled, false otherwise.\n    def trusted_ports_enabled?\n      @trusted_ports_enabled ||= enterprise?\n    end\n    attr_writer :trusted_ports_enabled\n\n    # The delegated account recovery feature allows us to act as an Account Provider\n    # and a Recovery Provider. Currently, we will only be acting as an Account Provider\n    # but we fake out acting as a recovery provider in dev/test.\n    def github_as_recovery_provider_enabled?\n      !Rails.env.production?\n    end\n\n    def delegated_recovery_enabled?\n      !GitHub.enterprise?\n    end\n\n    # The ports we implicitly trust. Nginx should only be listening to\n    # these ports on localhost.\n    #\n    # Returns an array of strings.\n    def trusted_ports\n      @trusted_ports ||= if GitHub.enterprise?\n        %w(1337)\n      else\n        []\n      end\n    end\n\n    ##\n    # Host Names\n\n    # The main external GitHub hostname only. No http:// prefix or protocol\n    # information is included.\n    #\n    # Returns the hostname string (\"github.com\", \"github.dev\", etc.) or nil if\n    # no host_name has been set.\n    def host_name\n      @host_name || ENV[\"GH_HOSTNAME\"]\n    end\n    attr_writer :host_name\n\n    # The main external GitHub Cloud hostname only. No http:// prefix or\n    # protocol information is included.\n    #\n    # Returns the hostname String, defaulting to \"githubcloud.com\",\n    # \"githubcloud.dev\", or nil depending on the runtime environment.\n    def cloud_host_name\n      return @cloud_host_name if defined?(@cloud_host_name)\n      @cloud_host_name =\n        case\n        when GitHub.enterprise?\n          nil\n        when Rails.env.development?, Rails.env.test?\n          \"githubcloud.dev\"\n        else\n          \"githubcloud.com\"\n        end\n    end\n    attr_writer :cloud_host_name\n\n    # Determines if emails are sent with the configured noreply address\n    # as Enterprise always has, or the GitHub.com style of emails where\n    # they are From: a notifications@ address\n    attr_accessor :mail_use_noreply_addr\n\n    # Hostname for githubusercontent.com.\n    #\n    # production:  githubusercontent.com\n    # development: githubusercontent.dev\n    #\n    # Returns String host or nil.\n    attr_accessor :user_content_host_name\n\n    # Orgs/users that are owned by GitHub and should be allowed to use\n    # `github.com` urls.\n    #\n    # Returns an Array of String User/Organization logins.\n    def github_owned_pages\n      @github_owned_pages ||= []\n    end\n\n    # The GitHub Pages hostname only.\n    #\n    # Returns the hostname string (\"githubpages.com\", \"github.io\", etc.) or nil\n    # if no host_name has been set.\n    def pages_host_name_v1\n      @pages_host_name ||= GitHub.host_name\n    end\n    attr_writer :pages_host_name\n\n    # The GitHub Pages hostname we are migrating to\n    #\n    # Returns the hostname string (i.e. \"github.io\") if we are in an environment\n    # that supports it,  or nil if no host_name has been set.\n    def pages_host_name_v2\n      @pages_host_name_v2 ||= if enterprise?\n        if GitHub.subdomain_isolation?\n          \"pages.#{GitHub.host_name}\"\n        else\n          GitHub.host_name\n        end\n      else\n        \"github.io\".freeze\n      end\n    end\n    attr_writer :pages_host_name_v2\n\n    def pages_preview_hostname\n      @pages_preview_hostname ||= \"drafts.github.io\"\n    end\n    attr_writer :pages_preview_hostname\n\n    # The GitHub Pages themes hostname for previews in the theme chooser\n    def pages_themes_hostname\n      @pages_themes_hostname ||= \"pages-themes.#{GitHub.pages_host_name_v2}\"\n    end\n    attr_writer :pages_themes_hostname\n\n    # Do we support HTTPS redirects for pages sites?\n    #\n    # Returns boolean.\n    def pages_https_redirect_enabled?\n      !enterprise?\n    end\n\n    # Pages for repositories created after this time will require HTTPS if they\n    # are served from github.io.\n    #\n    # This is only used it tests for now, so it's set to an hour from now.\n    #\n    # Returns a Time instance.\n    def pages_https_required_after\n      @pages_https_required_after ||= Time.parse(\"2016-06-15 12:00:00 PDT\")\n    end\n\n    # Domains that we have SSL certs for on Fastly.\n    #\n    # Returns an Array of Strings.\n    def pages_https_domains\n      if enterprise?\n        []\n      else\n        %w(\n          blog.atom.io\n          electron.atom.io\n          flight-manual.atom.io\n\n          brew.sh\n          docs.brew.sh\n\n          choosealicense.com\n          codeconf.com\n          github.co.jp\n          githubengineering.com\n          githubuniverse.com\n          opensource.guide\n          svnhub.com\n        )\n      end\n    end\n\n    # Do we support creating Let's Encrypt certificates for CNAME pages.\n    def acme_enabled?\n      !enterprise?\n    end\n\n    # ACME protocol endpoint for getting Pages certificates.\n    def acme_endpoint\n      \"https://acme-v01.api.letsencrypt.org/\"\n    end\n\n    # JSON Web Key for ACME client.\n    def acme_jwk\n      @acme_jwk ||= GitHub::Earthsmoke::AcmeJwk.new(\"github:acme:lets-encrypt:account-key\")\n    end\n\n    # Key for Let's Encrypt certificates.\n    def acme_cert_key\n      @acme_cert_key ||= GitHub.earthsmoke.key(\"github:acme:lets-encrypt:cert-key\")\n    end\n\n    # ACME client for getting Pages certificates.\n    def acme\n      @acme ||= Acme::Client.new(\n        jwk: acme_jwk,\n        endpoint: acme_endpoint\n      )\n    end\n\n    # The host name where the API accepts uploads.\n    def api_upload_host_name\n      @api_upload_host_name ||= if (enterprise? || garage_unicorn?)\n        \"#{host_name}/api/uploads\".freeze\n      else\n        \"uploads.#{host_name}\".freeze\n      end\n    end\n\n    # Choose which type of URL creator we need to return\n    #\n    # Returns an instance of GitHub::UrlBuilder\n    def urls\n      default_url_builder\n    end\n\n    # Generate URLs for default GitHub instances.\n    #\n    # Returns a GitHub::UrlBuilder instance\n    def default_url_builder\n      @default_url_builder ||= GitHub::UrlBuilder.new(host_name: host_name, scheme: scheme)\n    end\n\n    # The host name that the API is served from.\n    #\n    # Retrurns a String.\n    def api_host_name\n      urls.api_host_name\n    end\n\n    # The root path of the API.\n    #\n    # Returns a String.\n    def api_root_path\n      urls.api_root_path\n    end\n\n    # The URL where the V3 API is served from. This defaults to the configured\n    # host_name with an \"api.\" prefix.\n    #\n    # Returns the API url string (e.g. \"https://api.github.com\" for production)\n    def api_url\n      urls.api_url\n    end\n    attr_writer :api_url\n\n    # The URL where the GraphQL API is served from. This defaults to the\n    # configured host_name with an \"api.\" prefix.\n    #\n    # Returns the API url string (e.g. \"https://api.github.com\" for production)\n    def graphql_api_url\n      urls.graphql_api_url\n    end\n    attr_writer :graphql_api_url\n\n    def api_upload_prefix\n      @api_upload_prefix ||= begin\n        host_and_path = api_upload_host_name\n        (ssl? ? \"https://\" : \"http://\") + host_and_path\n      end\n    end\n\n    attr_accessor :admin_host_name\n    def admin_host?\n      !!@is_admin_host\n    end\n    attr_writer :is_admin_host\n\n    # Whitelist a few environments that should expose endpoints that should not be\n    # available on public FEs. These endpoints will be available on dedicated\n    # machines that may be behind additional network-level control in the future.\n    # Also dev / test / lab / enterprise / etc. need to work. Anywhere but dotcom.\n    def restricted_front_end?\n      GitHub.admin_host? ||\n        GitHub.employee_unicorn? ||\n        GitHub.enterprise? ||\n        Rails.env.development? ||\n        Rails.env.test?\n    end\n\n    # The user id for our Monitors account, which is used to display things in the office\n    # and often has some special privilege.\n    #\n    # Returns an integer id.\n    def monitors_user_id\n      @monitors_user_id || MONITORS_USER_ID\n    end\n\n    # The user id for our Hubot account.\n    #\n    # Returns an integer id.\n    def hubot_user_id\n      @hubot_user_id || HUBOT_USER_ID\n    end\n\n    # The fetch interval in minutes for GitHub Desktop applications.\n    #\n    # Returns an integer representing minutes\n    def desktop_fetch_interval\n      @desktop_fetch_interval || DESKTOP_FETCH_INTERVAL\n    end\n    attr_writer :desktop_fetch_interval\n\n    # The login for recording mirror pushes.\n    #\n    # Returns the String login name.\n    def mirror_pusher\n      return @mirror_pusher if defined?(@mirror_pusher)\n      @mirror_pusher = MIRROR_PUSHER\n    end\n    attr_writer :mirror_pusher\n\n    # How many copies (replicas) of each repo network to aim for.\n    #\n    # Returns a small, odd integer.\n    def dgit_copies\n      @dgit_copies ||= DGIT_COPIES\n    end\n    attr_writer :dgit_copies\n\n    # How many non-voting copies of each repo network to aim for.\n    #\n    # If nil, spokes will not care how many non-voting replicas exist.\n    attr_accessor :dgit_non_voting_copies\n\n    # How frequently should the timerd job run to pre-fill the\n    # cached disk stats?\n    #\n    # This should be smaller than dgit_disk_stats_cache_ttl.\n    attr_writer :dgit_disk_stats_interval\n    def dgit_disk_stats_interval\n      @dgit_disk_stats_interval || 60\n    end\n\n    # How long should GitHub::DGit.disk_stats and GitHub::DGit.parallel_disk_stats\n    # cache their responses for?\n    attr_writer :dgit_disk_stats_cache_ttl\n    def dgit_disk_stats_cache_ttl\n      @dgit_disk_stats_cache_ttl || 90\n    end\n\n    # How frequently should the timerd job run to compare\n    # fileservers tables between the legacy and new Spokes\n    # databases?\n    attr_writer :dgit_fileservers_diffjob_interval\n    def dgit_fileservers_diffjob_interval\n      @dgit_fileservers_diffjob_interval || 60\n    end\n\n    # How many copies (replicas) of a repo are needed to accept a write.\n    #\n    # `ncopies` is an optional indication of the actual number of replicas\n    # eligible to vote.  When this is more than the number returned by\n    # `dgit_copies`, the quorum may be larger.  For example, the normal\n    # number of copies is 3, but in some cases, a repo network might have\n    # 4 copies, in which case it takes 3 (not 2) to make a quorum.\n    #\n    # Returns a strict majority of the target number of copies.\n    def dgit_quorum(ncopies = dgit_copies)\n      [ncopies, dgit_copies].max/2 + 1\n    end\n\n    def dgit_git_daemon_port\n      @dgit_git_daemon_port ||= if Rails.development?\n                                  9418\n                                elsif Rails.test?\n                                  9420 + test_environment_number.to_i\n                                else # production\n                                  9419\n                                end\n    end\n    attr_writer :dgit_git_daemon_port\n\n    # The Gist hostname. No http:// prefix or protocol information is included.\n    #\n    # Returns the Gist hostname string (\"gist.github.com\"). Defaults to host_name.\n    def gist_host_name\n      @gist_host_name ||= host_name\n    end\n    attr_writer :gist_host_name\n\n    # The Gist 3 hostname. No http:// prefix or protocol information is included.\n    # Until we make the switch to Gist 3, we'll be running both side-by-side.\n    #\n    # Returns the Gist hostname string (\"gist.github.com\"). Defaults to host_name.\n    def gist3_host_name\n      @gist3_host_name ||= host_name\n    end\n    attr_writer :gist3_host_name\n\n    # Is Gist running under its own subdomain like gist.github.com? If not, that\n    # shits is served from <url>/gists.\n    def gist_domain?\n      gist_host_name != host_name\n    end\n\n    # Is Gist 3 running under its own subdomain like gist3.github.com? If not, that\n    # shits is served from <url>/gists.\n    def gist3_domain?\n      gist3_host_name != host_name\n    end\n\n    # Gist 3 OAuth Client credentials. Used for OAuth authentication in subdomain mode.\n    attr_accessor :gist3_oauth_client_id, :gist3_oauth_secret_key\n\n    # The Subversion / Slummin hostname. No http:// prefix or protocol\n    # information is included. By default, this is the configured host_name.\n    #\n    # Returns the hostname string (\"github.com\", \"stg.github.com\", etc)\n    def subversion_host_name\n      @subversion_host_name ||= \"#{host_name}\".freeze\n    end\n    attr_writer :subversion_host_name\n\n    # The GitHub users hostname. No http:// prefix or protocol information is\n    # included. By default, this is the configured host_name with a \"users.noreply.\"\n    # prefix.  This hostname is used for \"stealth\" emails.\n    #\n    # Returns the hostname string (ex: \"users.noreply.github.com\")\n    def stealth_email_host_name\n      @stealth_email_host_name ||= \"users.noreply.#{host_name}\".freeze\n    end\n    attr_writer :stealth_email_host_name\n\n    # The short name of the machine this process is currently executing on. Writing to\n    # this config value is not recommended.\n    def local_host_name_short\n      if GitHub.kube?\n        # 'kube-unknown' protects us from processes that didn't set the\n        # env var properly, and hopefully also is greppable to find this comment\n        long = ENV[\"KUBE_NODE_HOSTNAME\"] || \"kube-unknown\"\n      else\n        long = local_host_name\n      end\n      @local_host_name_short ||= long.split(\".\", 2).first\n    end\n    attr_writer :local_host_name_short\n\n    # The name of the machine this process is currently executing on.\n    # Explicitly set on Enterprise to the configured node name.\n    def local_host_name\n      @local_host_name ||= (require \"socket\"; Socket.gethostname)\n    end\n    attr_writer :local_host_name\n\n    # The role of the currently running process, request or job. Defaults to\n    # :unassigned as a catch all for when the role is not setup. This is\n    # explicitly set before web requests, background jobs, etc. to provide\n    # context of where an action is happening from (like a sql query).\n    # Keep it a Symbol so everyone knows what they are dealing with.\n    #\n    # Returns a Symbol of the currently set role for this process, request,\n    # background job, etc.\n    def role\n      @role ||= begin\n        from_env = ENV[\"GITHUB_CONFIG_ROLE\"]\n\n        if from_env.nil? || from_env.empty?\n          :unassigned\n        else\n          from_env.to_sym\n        end\n      end\n    end\n\n    # Get a role from the host's Sites API role. You might ask \"why isn't this\n    # the default for #role\"? Because there are a bunch of places where we used\n    # to set GITHUB_CONFIG_ROLE god config and it may or may not have been picked\n    # up by processes. In those cases, we need to be more explicit so that we\n    # don't accidentally have mixed metrics.\n    def role_from_host\n      host_app = server_metadata[\"app\"]\n      host_role = server_metadata[\"role\"]\n\n      if host_app == \"github\"\n        case host_role\n        when \"api\", \"codeload\", \"registryfe\", \"stafftools\", \"dfs\"\n          host_role.to_sym\n        when \"fe\"\n          if local_host_name.start_with?(\"github-fe\")\n            :fe\n          elsif local_host_name.start_with?(\"github-staff\")\n            :lab\n          else\n            :unassigned\n          end\n        when \"arch\"\n          :codeload\n        when \"staff\"\n          :lab\n        else\n          :unassigned\n        end\n      elsif host_app == \"pages\"\n        case host_role\n        when \"dfs\"\n          # pages-dfs's timerd is a github/github process\n          :pagesdfs\n        else\n          :unassigned\n        end\n      else\n        :unassigned\n      end\n    end\n\n    def role=(role)\n      GitHub.reset_dogstats\n      @role = role\n    end\n\n    def component\n      @component ||= begin\n        from_env = ENV[\"GITHUB_CONFIG_COMPONENT\"]\n\n        if from_env.nil? || from_env.empty?\n          :unassigned\n        else\n          from_env.to_sym\n        end\n      end\n    end\n\n    def component=(component)\n      GitHub.reset_dogstats\n      @component = component\n    end\n\n    # The domain of the machine this process is currently executing on. Writing\n    # to this config value is not recommended.\n    def domain_name\n      @domain_name ||= local_host_name.split(\".\", 2).last\n    end\n    attr_writer :domain_name\n\n    # The short domain of the machine this process is currently executing on.\n    # Writing to this config value is not recommended.\n    def domain_name_short\n      @domain_name_short ||= domain_name.split(\".\", 2).first\n    end\n    attr_writer :domain_name_short\n\n    # These local git, pages and storage host names are used to avoid setting\n    # the local partitions to `localhost`.\n    def local_git_host_name\n      @local_git_host_name || \"localhost\"\n    end\n    attr_writer :local_git_host_name\n\n    def local_pages_host_name\n      @local_pages_host_name || \"localhost\"\n    end\n    attr_writer :local_pages_host_name\n\n    def local_storage_host_name\n      @local_storage_host_name || \"localhost\"\n    end\n    attr_writer :local_storage_host_name\n\n    # PRs content hostname. No http:// prefix or protocol information is included.\n    # No default b/c Enterprise might not use a FQDN.\n    #\n    # Returns String host or nil.\n    attr_accessor :prs_content_host_name\n\n    # The PRs content site URL.\n    #\n    # production:  https://prs.githubusercontent.com\n    # garage:      https://prs-garage.githubusercontent.com\n    # development: http://prs.githubusercontent.dev\n    #\n    # Returns the URL string or nil.\n    def prs_content_host_url\n      @prs_content_host_url ||= prs_content_domain? ? \"#{scheme}://#{prs_content_host_name}\".freeze : nil\n    end\n    attr_writer :prs_content_host_url\n\n    # Should pr diffs/patches be served from its own subdomain like prs.githubusercontent.com?\n    def prs_content_domain?\n      !prs_content_host_name.to_s.empty?\n    end\n\n    ##\n    # URLs\n\n    # The main GitHub site URL. It returns\n    # the http:// or https:// version of the URL based on whether the #ssl\n    # attribute is set.\n    #\n    # Returns the URL string (\"https://github.com\", \"http://github.dev\")\n    def url\n      urls.url\n    end\n\n    # Help URL - Enterprise and production serve Help docs differently\n    #\n    # Returns the URL string (\"https://help.github.com\", \"http://help.github.com/enterprise\", etc.)\n    def help_url\n      if GitHub.enterprise?\n        \"#{enterprise_help_landing_page}/user\"\n      else\n        \"https://help.github.com\"\n      end\n    end\n\n    # Developer Help URL.\n    #\n    # Returns the URL string (\"https://developer.github.com\")\n    def developer_help_url\n      if GitHub.enterprise?\n        \"https://developer.github.com/enterprise/#{major_minor_version_number}\"\n      else\n        \"https://developer.github.com\"\n      end\n    end\n\n    # Enterprise Help Admin URL.\n    #\n    # Returns the URL string (\"https://help.github.com/enterprise/2.3/admin\")\n    def enterprise_admin_help_url\n      \"#{enterprise_help_landing_page}/admin\"\n    end\n\n    # Enterprise Help landing page URL.\n    #\n    # Returns the URL string (\"https://help.github.com/enterprise/2.3\")\n    def enterprise_help_landing_page\n      \"https://help.github.com/enterprise/#{major_minor_version_number}\"\n    end\n\n    # Guides URL\n    #\n    # Returns the URL string (\"https://guides.github.com\")\n    def guides_url\n      \"https://guides.github.com\"\n    end\n\n    # Update personal credit card Help URL\n    #\n    # Returns the URL string\n    def personal_cc_help_url\n      \"https://help.github.com/articles/updating-your-personal-account-s-credit-card\"\n    end\n\n    # Update organization credit card Help URL\n    #\n    # Returns the URL string\n    def org_cc_help_url\n      \"https://help.github.com/articles/updating-your-organization-s-credit-card\"\n    end\n\n    # Update personal paypal Help URL\n    #\n    # Returns the URL string\n    def personal_paypal_help_url\n      \"https://help.github.com/articles/updating-your-personal-account-s-paypal-information/\"\n    end\n\n    # Update organization paypal Help URL\n    #\n    # Returns the URL string\n    def org_paypal_help_url\n      \"https://help.github.com/articles/updating-your-organization-s-paypal-information\"\n    end\n\n    # The meta schema for the GitHub API.\n    #\n    # Return a string path.\n    def api_schema_meta_path\n      Rails.root.join(\"app/api/schema.json\")\n    end\n\n    # The directory containing subschemas for the GitHub API.\n    #\n    # Return a string path.\n    def api_subschema_dir\n      Rails.root.join(\"app/api/schemas/v3/schemas\")\n    end\n\n    # Enable rate limiting. Disabled by default in development and Enterprise.\n    # override defaults with the RATE_LIMITING environment variable.\n    def rate_limiting_enabled?\n      return @rate_limiting_enabled if defined?(@rate_limiting_enabled)\n      @rate_limiting_enabled = ENV[\"RATE_LIMITING\"] ||\n        (!Rails.development? && !enterprise?)\n    end\n    attr_writer :rate_limiting_enabled\n\n    def apps_enabled?\n      return @apps_enabled if defined?(@apps_enabled)\n      @apps_enabled = !GitHub.enterprise?\n    end\n    attr_writer :apps_enabled\n\n    # The asset host root URL. This defaults to url and is typically\n    # overridden in production environments to enable asset loading from a\n    # CDN / separate domain.\n    #\n    # May return \"\" if assets are served from the same domain.\n    #\n    # Returns the string URL (\"https://blah.cloudfront.net\", \"\", etc)\n    def asset_host_url\n      @asset_host_url ||= url\n    end\n\n    # Allow asset_host_url to be set as just a hostname.\n    def asset_host_url=(url)\n      if url.nil? || url == \"\"\n        url = \"\"\n      elsif url && url !~ /^https?:/\n        url = \"#{scheme}://#{url}\"\n      end\n      @asset_host_url = url\n    end\n\n    # The braintree gateway URL, for #csp_connect_sources\n    def braintreegateway_url\n      @braintreegateway_url ||= if Rails.env.production?\n        \"https://api.braintreegateway.com\"\n      else\n        \"https://api.sandbox.braintreegateway.com\"\n      end\n    end\n\n    # The braintree analytics URL, for #csp_connect_sources\n    def braintree_analytics_url\n      @braintree_analytics_url ||= if Rails.env.production?\n        \"https://client-analytics.braintreegateway.com\"\n      else\n        \"https://client-analytics.sandbox.braintreegateway.com\"\n      end\n    end\n\n    # The paypal checkout URL for paypal button images, for #csp_image_sources\n    def paypal_checkout_url\n      @paypal_checkout_url ||= \"https://checkout.paypal.com\"\n    end\n\n    # The asset host to use for all email assets.\n    #\n    # GitHub.asset_host_url may be nil or blank when assets should be served from\n    # the same origin. The mailer asset host is never blank and will fallback to\n    # the full origin url.\n    #\n    # development: http://github.dev\n    # production:  https://assets-cdn.github.com\n    # labs:        https://foo.review-lab.github.com\n    #\n    # Always returns a full URL String.\n    def mailer_asset_host_url\n      if asset_host_url.present?\n        asset_host_url\n      else\n        url\n      end\n    end\n\n    # This returns the identicons host used to fetch the identicons avatar.\n    #\n    # Returns identicon hostname as a string. This string requires\n    # a '/' for joining with path parts.\n    def identicons_host\n      @identicons_host ||= if GitHub.enterprise?\n                             GitHub.url\n                           else\n                            \"https://identicons.github.com\"\n                           end\n    end\n    attr_writer :identicons_host\n\n    # This returns the identicons host used by the internal api.\n    #\n    # Returns identicon hostname as a string. This string requires\n    # a '/' for joining with path parts.\n    def internal_identicons_host\n      @internal_identicons_host ||= if GitHub.enterprise?\n                                      GitHub.url\n                                    else\n                                      \"identicon:\"\n                                    end\n    end\n    attr_writer :internal_identicons_host\n\n    # The octolytics image host URL (hosted on a CDN), for #csp_img_sources\n    def octolytics_collector_url\n      if octolytics_collector_host\n        \"#{scheme}://#{octolytics_collector_host}\"\n      end\n    end\n\n    # The hostname of the CDN that hosts the octolytics JavaScript files\n    def octolytics_collector_script_host\n      @octolytics_collector_script_host ||=\n        octolytics_collector_host ?\n          (Rails.env.production? ? \"collector-cdn.github.com\" : octolytics_collector_host) :\n          nil\n    end\n\n    # The internal hostname for octolytics_collector. This should be used to\n    # send events from inside the GitHub network to avoid transiting the\n    # internet. Note the octolytics gem requires https for non-dev environments.\n    #\n    # Defaults to octolytics_collector_host.\n    def octolytics_collector_internal_host\n      @octolytics_collector_internal_host ||= octolytics_collector_host\n    end\n\n    # The internal Hookshot hostname.\n    #\n    # Returns the URL string.\n    attr_accessor :hookshot_url, :staging_hookshot_url, :hookshot_admin_url\n    attr_accessor :hookshot_path\n\n    # Secret token for the Hookshot endpoint: \"/hooks/:guid/:id\"\n    attr_writer :hookshot_token\n\n    def hookshot_token\n      @hookshot_token ||= \"1c70a1739cf49abce047a089b7967166\"\n    end\n\n    # The OauthApplication#id for porter.\n    def porter_app_id\n      @porter_app_id ||=\n        if app = OauthApplication.where(user_id: trusted_oauth_apps_owner, name: \"GitHub Importer\").first\n          app.id\n        else\n          nil\n        end\n      if @porter_app_id.nil? && (Rails.env.development? || Rails.env.test?)\n        OauthApplication::PERSONAL_TOKENS_APPLICATION_ID\n      else\n        @porter_app_id\n      end\n    end\n    attr_writer :porter_app_id\n\n    # The URL template of an import in porter.\n    attr_accessor :porter_url_template\n\n    # The URL template of an import's stafftools in porter.\n    attr_accessor :porter_repository_admin_url_template\n\n    # The URL template of an users's stafftools in porter.\n    attr_accessor :porter_user_admin_url_template\n\n    # The token that unlocks the internal admin URLs.\n    def porter_internal_api_token\n      @porter_internal_api_token || \"porter-development-token\"\n    end\n    attr_writer :porter_internal_api_token\n\n    # Returns true if porter is configured.\n    def porter_available?\n      porter_url_template.present? &&\n        porter_repository_admin_url_template.present? &&\n        porter_user_admin_url_template.present? &&\n        !enterprise?\n    end\n\n    # Valid \"flavors\" of the `/contact` form\n    #\n    # Returns an Hash in the form of flavor-key => title\n    def contact_form_flavors\n      @contact_form_flavors ||= if enterprise?\n        {\n          \"default\" => \"Get help with GitHub\"\n        }\n      else\n        {\n          \"default\"              => \"Get help with GitHub\",\n          \"report-abuse\"         => \"Report abuse\",\n          \"dmca\"                 => \"Copyright claims (DMCA)\",\n          \"dmca-notice\"          => \"DMCA takedown notice\",\n          \"dmca-counter-notice\"  => \"DMCA counter notice\",\n          \"privacy\"              => \"Report a privacy issue\",\n          \"terms-of-service\"     => \"New Terms of Service feedback\"\n        }\n      end\n    end\n\n    # GitHub's physical office address for inclusion into\n    # email footers, invoices, legal docs, etc.\n    #\n    # multiline - true or false.\n    #\n    # Returns an Array if multiline. Returns a String otherwise.\n    def physical_address(multiline: false)\n      address_parts = [\"GitHub, Inc. 88 Colin P Kelly Jr Street\", \"San Francisco, CA 94107\"]\n      multiline ? address_parts : address_parts.join(\", \")\n    end\n\n    # Email for Marketplace messages\n    #\n    # Returns the email String.\n    def marketplace_email\n      @marketplace_email = \"marketplace@github.com\"\n    end\n    attr_writer :marketplace_email\n\n    # Email for sending out user engagement and learning materials\n    #\n    # Returns the email String.\n    def guides_email\n      @guides_email = \"guides@github.com\"\n    end\n    attr_writer :guides_email\n\n    # Email for business development\n    #\n    # Returns the email string\n    def partnerships_email\n      @partnerships_email = \"partnerships@github.com\"\n    end\n    attr_writer :partnerships_email\n\n    ##\n    # Resque config\n\n    # A prefix used for all resque queues. Used to segregate workers in lab\n    # on staff1.\n    #\n    # Returns a string prefix if set, otherwise the empty string.\n    def resque_queue_prefix\n      @resque_queue_prefix ||= \"\"\n    end\n    attr_writer :resque_queue_prefix\n\n    # Resident memory limit for resque worker processes. If memory usage exceeds\n    # this value after a job is performed the process is shut down so that a\n    # fresh process can take its place.\n    #\n    # Returns the memory limit in bytes or nil to signify no limit.\n    def resque_graceful_memory_limit\n      if defined?(@resque_graceful_memory_limit)\n        @resque_graceful_memory_limit\n      else\n        @resque_graceful_memory_limit = nil\n      end\n    end\n    attr_writer :resque_graceful_memory_limit\n\n    # Number of resque jobs to retry each pass through the retry queue.\n    #\n    # Returns an Integer.\n    def resque_retry_quantity\n      if config_max_string = GitHub.environment[\"RESQUE_RETRY_QUANTITY\"]\n        config_max = begin\n          Integer(config_max_string)\n        rescue ArgumentError => e\n          err = e.exception(\"RESQUE_RETRY_QUANTITY must be an Integer encoding\")\n          err.set_backtrace(caller)\n          Failbot.report!(err)\n          nil\n        end\n        return config_max unless config_max.nil?\n      end\n      return 100 * 100\n    end\n\n    # The camo image proxy URL. This is used to rewrite HTTP <img> tag URLs left\n    # in user content (like comments and issue bodies) through the SSL image\n    # proxy, avoiding browser mixed content warnings.\n    #\n    # This value defaults to the <asset_host_url>/img when not set explicitly.\n    #\n    # Returns the image proxy root URL string.\n    #\n    # See Also:\n    #   https://github.com/atmos/camo\n    #   https://github.com/github/camo\n    def image_proxy_url\n      @image_proxy_url ||= \"#{asset_host_url}/img\".freeze\n    end\n    attr_writer :image_proxy_url\n\n    # The secret token key used to sign generated image proxy URLs.\n    #\n    # Returns the key as a String, or nil when no secret is set.\n    attr_accessor :image_proxy_key\n\n    # Determine whether img URLs should be rewritten through the camo image\n    # proxy. This defaults to true when SSL is enabled and the\n    # image_proxy_key value is set.\n    #\n    # Returns true when img URLs should be rewritten, false otherwise.\n    def image_proxy_enabled?\n      ssl? && image_proxy_key\n    end\n\n    # Domains who'se images will not be proxied through camo when used in user\n    # content.\n    def image_proxy_host_whitelist\n      @image_proxy_host_whitelist ||= begin\n        hosts = []\n\n        # Allow any github.com image references. This needs to be cleaned up\n        # if we want to remove 'self' from CSP img-src.\n        hosts << host_name\n\n        # Allow any references to *.githubusercontent.com sources.\n        if user_content_host_name && user_content_host_name != host_name\n          hosts << Regexp.new(Regexp.escape(user_content_host_name) + \"\\\\z\")\n        end\n\n        hosts\n      end\n    end\n\n    # Should external images be allowed to be loaded as subresouces outside\n    # of our whitelisted set?\n    #\n    # Enabling this enforces the img-src CSP.\n    #\n    # Requires Camo image proxy configuration.\n    def restrict_external_images?\n      return @restrict_external_images if defined?(@restrict_external_images)\n      @restrict_external_images = true\n    end\n    attr_writer :restrict_external_images\n\n    # Should we included our whitelisted set of third party connect hosts in our\n    # connect-src CSP directive?\n    #\n    # Enabling this results in a set of whitelisted third party hosts being\n    # added to the connect-src CSP directive.\n    def allow_third_party_connect_sources?\n      return @allow_third_party_connect_sources if defined?(@allow_third_party_connect_sources)\n      @allow_third_party_connect_sources = true\n    end\n    attr_writer :allow_third_party_connect_sources\n\n    # Should we pin the certificate authority root certificates that are allowed\n    # to sign GitHub certificates? As of now this only makes sense on dotcom, as\n    # we only use Digicert and Verisign(Symantec) extended validation certificates. On any\n    # other environment (enterprise, development, test, etc) this option should\n    # be `false`.\n    #\n    # Enabling this results in a set of whitelisted certificate authorities\n    # being added to the Public-Key-Pins header policy.\n    def public_key_pinning_enabled?\n      return @public_key_pinning_enabled if defined?(@public_key_pinning_enabled)\n      @public_key_pinning_enabled = false\n    end\n    attr_writer :public_key_pinning_enabled\n\n    ##\n    # Gist\n\n    # Gist is enabled by default at /gist and can be run under a subdomain by\n    # setting the Gist.host_name option. Explicitly disabling gist by setting\n    # this option false removes all links in the UI.\n    def gist_enabled\n      return @gist_enabled if defined?(@gist_enabled)\n      @gist_enabled = true\n    end\n    alias gist_enabled? gist_enabled\n    attr_writer :gist_enabled\n\n    # The main gist raw URL. This value typically isn't written directly but\n    # should be read anywhere the raw URL for gist is required. It returns the\n    # http:// or https:// version of the raw URL based on whether the #ssl attribute\n    # is set.\n    #\n    # Returns the gist raw URL string (\"https://gist.githubusercontent.com\",\n    # \"http://gist.github.dev\", etc)\n    def gist_raw_url\n      ssl? ? gist_raw_https_url : gist_url\n    end\n\n    # The main gist site URL. This value typically isn't written directly but\n    # should be read anywhere the root URL for gist is required. It returns the\n    # http:// or https:// version of the URL based on whether the #ssl attribute\n    # is set.\n    #\n    # Returns the gist URL string (\"https://gist.github.com\",\n    # \"http://gist.github.dev\", etc)\n    def gist_url\n      ssl? ? gist_https_url : gist_http_url\n    end\n\n    # The non-SSL http version of the Gist URL. Not typically used directly. Use\n    # gist_url instead so that http vs. https is determined dynamically.\n    def gist_http_url\n      if gist_domain?\n        \"http://#{gist_host_name}\".freeze\n      else\n        \"#{url}/gist\"\n      end\n    end\n\n    # The https version of the Gist URL. Not typically used directly. Use\n    # gist_url instead so that http vs. https is determined dynamically.\n    def gist_https_url\n      if gist_domain?\n        \"https://#{gist_host_name}\".freeze\n      else\n        \"#{url}/gist\"\n      end\n    end\n\n    # The https version of the raw Gist URL. Not typically used directly. Use\n    # gist_raw_url instead so that http vs. https is determined dynamically.\n    def gist_raw_https_url\n      if gist_domain?\n        \"https://gist.#{GitHub.user_content_host_name}\".freeze\n      else\n        gist_https_url\n      end\n    end\n\n    # The URL to GitHub's graphite instance.\n    attr_accessor :graphite_url\n\n    # The URL of the Graphme app.\n    attr_accessor :graphme_url\n\n    ##\n    # Caching\n\n    # View fragment cache prefix.\n    #\n    # Bump this to expire all view caches.\n    def fragment_cache_version\n      :views10\n    end\n\n    # Cache key for task lists\n    #\n    # Bump this if task list rendering has changed and you need to\n    # expire any cached items w/ task lists\n    def task_list_cache_version\n      :task_list_1\n    end\n\n    # Ajax Poller version\n    #\n    # Bumping this will kill any active poller clients.\n    #\n    # See also ajax_poll.coffee\n    def ajax_poller_version\n      \"2\"\n    end\n\n    def audit_log_export_enabled?\n      !GitHub.enterprise?\n    end\n\n    ##\n    # elasticsearch\n\n    # Internal: Indicates the configured level of access to Elasticsearch.\n    #\n    # Allows ENV config to define what level of access to Elasticsearch is\n    # available. ENV[\"ELASTICSEARCH_ACCESS\"] can be set to one of:\n    #   allowed - Default, all Elasticsearch functionality is available.\n    #   ignored - A \"soft\" disable: the app will do its best to not issue\n    #             queries, and will try to display user-friendly error messages\n    #             when possible.\n    #   raises  - All Elasticsearch access is disabled, and any attempts to\n    #             use it will result in an exception.\n    #\n    # The \"ignored\" mode is intended for site recovery in a secondary datacenter\n    # rather than as a general control rod for normal operation. The \"raises\"\n    # mode is intended for deployment in a read-only datacenter when ES indexes\n    # are not available, and where any requests to search indexes are explicitly\n    # not supported.\n    #\n    # Returns the currently configured mode as a symbol.\n    # Raises TypeError if an invalid mode is configured.\n    def elasticsearch_access\n      if !defined?(@elasticsearch_access)\n        value = GitHub.environment[\"ELASTICSEARCH_ACCESS\"] || \"allowed\"\n        self.elasticsearch_access = value.to_sym\n      end\n      @elasticsearch_access\n    end\n\n    # Set the access level for Elasticsearch. Used by an enterprise setup script\n    # as well as the test suite.\n    #\n    # Raises TypeError if an invalid mode is provided.\n    def elasticsearch_access=(mode)\n      if ELASTICSEARCH_ACCESS_VALUES.include?(mode)\n        @elasticsearch_access = mode\n      else\n        raise TypeError, \"Invalid elasticsearch access mode: #{mode.inspect}\"\n      end\n    end\n\n    # FIXME rename\n    # Convenience query methods for determining elasticsearch_access levels:\n    def elasticsearch_access_allowed?\n      elasticsearch_access == :allowed\n    end\n\n    def elasticsearch_access_ignored?\n      elasticsearch_access == :ignored\n    end\n\n    def elasticsearch_access_raises?\n      elasticsearch_access == :raises\n    end\n\n    # The elasticsearch http host and port. This is actually hitting HA Proxy which\n    # will load-balance across the cluster.\n    attr_accessor :elasticsearch_host\n\n    # The elasticsearch host to use for audit logs.\n    attr_accessor :elasticsearch_audit_log_host\n\n    # Returns the URL (as a String) for communicating with ElasticSearch or\n    # `nil` if the elasticsearch_host has not been set.\n    def elasticsearch_url\n      elasticsearch_host ? \"http://#{elasticsearch_host}\" : nil\n    end\n\n    # The elasticsearch query timeout.\n    def es_query_timeout\n      @es_query_timeout ||= \"250ms\"\n    end\n    attr_writer :es_query_timeout\n\n    # The elasticsearch cluster to use for audit logs.\n    def es_audit_log_cluster\n      @es_audit_log_cluster ||= \"default\"\n    end\n    attr_writer :es_audit_log_cluster\n\n    # The Hash containing the name / URL mapping for the available\n    # ElasticSearch clusters.\n    def es_clusters\n      @es_clusters ||= {}\n    end\n\n    # The number of shards to use when creating the `audit_log` index.\n    def es_shard_count_for_audit_log\n      @es_shard_count_for_audit_log ||= 1\n    end\n    attr_writer :es_shard_count_for_audit_log\n\n    # The number of shards to use when creating the `code_search` index.\n    def es_shard_count_for_code_search\n      @es_shard_count_for_code_search ||= 1\n    end\n    attr_writer :es_shard_count_for_code_search\n\n    # The number of shards to use when creating the `commits` index.\n    def es_shard_count_for_commits\n      @es_shard_count_for_commits ||= 1\n    end\n    attr_writer :es_shard_count_for_commits\n\n    # The number of shards to use when creating the `issues` index.\n    def es_shard_count_for_issues\n      @es_shard_count_for_issues ||= 1\n    end\n    attr_writer :es_shard_count_for_issues\n\n    # The number of shards to use when creating the `issues` index.\n    def es_shard_count_for_pull_requests\n      @es_shard_count_for_pull_requests ||= 1\n    end\n    attr_writer :es_shard_count_for_pull_requests\n\n    # The number of shards to use when creating the `repos` index.\n    def es_shard_count_for_repos\n      @es_shard_count_for_repos ||= 1\n    end\n    attr_writer :es_shard_count_for_repos\n\n    # The number of shards to use when creating the `users` index.\n    def es_shard_count_for_users\n      @es_shard_count_for_users ||= 1\n    end\n    attr_writer :es_shard_count_for_users\n\n    # The number of shards to use when creating the `blog` index.\n    def es_shard_count_for_blog\n      @es_shard_count_for_blog ||= 1\n    end\n    attr_writer :es_shard_count_for_blog\n\n    # The number of shards to use when creating the `blog` index.\n    def es_shard_count_for_showcases\n      @es_shard_count_for_showcases ||= 1\n    end\n    attr_writer :es_shard_count_for_showcases\n\n    # The number of shards to use when creating the `gists` index.\n    def es_shard_count_for_gists\n      @es_shard_count_for_gists ||= 1\n    end\n    attr_writer :es_shard_count_for_gists\n\n    # The number of shards to use when creating the `job_postings` index.\n    def es_shard_count_for_job_postings\n      @es_shard_count_for_job_postings ||= 1\n    end\n    attr_writer :es_shard_count_for_job_postings\n\n    # The number of shards to use when creating the `locations` index.\n    def es_shard_count_for_locations\n      @es_shard_count_for_locations ||= 1\n    end\n    attr_writer :es_shard_count_for_locations\n\n    # The number of shards to use when creating the `wikis` index.\n    def es_shard_count_for_wikis\n      @es_shard_count_for_wikis ||= 1\n    end\n    attr_writer :es_shard_count_for_wikis\n\n    # The number of shards to use when creating the `projects` index.\n    def es_shard_count_for_projects\n      @es_shard_count_for_projects ||= 1\n    end\n    attr_writer :es_shard_count_for_projects\n\n    # The number of shards to use when creating the `non_marketplace_listings` index.\n    def es_shard_count_for_non_marketplace_listings\n      @es_shard_count_for_non_marketplace_listings ||= 1\n    end\n    attr_writer :es_shard_count_for_non_marketplace_listings\n\n    # The number of shards to use when creating the `marketplace_listings` index.\n    def es_shard_count_for_marketplace_listings\n      @es_shard_count_for_marketplace_listings ||= 1\n    end\n    attr_writer :es_shard_count_for_marketplace_listings\n\n    # The number of shards to use when creating the `registry_packages` index.\n    def es_shard_count_for_registry_packages\n      @es_shard_count_for_registry_packages ||= 1\n    end\n    attr_writer :es_shard_count_for_registry_packages\n\n    # The number of replicas to maintain for each search index.\n    def es_number_of_replicas\n      @es_number_of_replicas ||= 1\n    end\n    attr_writer :es_number_of_replicas\n\n    # The read timeout for Elasticsearch connections in seconds.\n    # Defaults to 7 seconds.\n    def es_read_timeout\n      @es_read_timeout ||= 7\n    end\n    attr_writer :es_read_timeout\n\n    # The connection open timeout for Elasticsearch connections in seconds.\n    # Defaults to 2 seconds.\n    def es_open_timeout\n      @es_open_timeout ||= 2\n    end\n    attr_writer :es_open_timeout\n\n    # The maximum file size that we will index in the code-search index. Source\n    # code files larger than this limit will _not_ have their contents indexed\n    # and searchable. Other meta-data about the source code files (filename,\n    # extension, language, etc) will still be searchable.\n    def es_max_doc_size\n      @es_max_doc_size ||= 384*1024  # 384KB\n    end\n    attr_writer :es_max_doc_size\n\n    # Flag indicating whether codeload is available in this environment. This\n    # is currently set true in the Enterprise chef cookbooks.\n    #\n    # Returns true if codeload is available.\n    def codeload_enabled?\n      @codeload_enabled ||= !enterprise?\n    end\n    attr_writer :codeload_enabled\n\n    ##\n    # Subversion\n\n    # The Subversion / Slummin root URL. This value typically isn't written\n    # directly but should be read anywhere the root URL for the subversion\n    # server is required. It returns the http:// or https:// version of the\n    # URL based on whether the #ssl config attribute is set.\n    #\n    # Returns the svn URL string (\"https://svn.github.com\",\n    # \"http://svn.github.dev\", etc)\n    def subversion_url\n      @subversion_url ||= \"#{scheme}://#{subversion_host_name}\".freeze\n    end\n    attr_writer :subversion_url\n\n    ##\n    # Pages\n\n    # Flag indicating whether Pages are available in this environment. This is\n    # disabled by default under FI environments but enabled everywhere else.\n    #\n    # Returns true if pages are enabled, false otherwise.\n    def pages_enabled?\n      return @pages_enabled if defined?(@pages_enabled)\n      @pages_enabled = true\n    end\n    attr_writer :pages_enabled\n\n    # Root directory where fully-built Pages sites are served from. This\n    # defaults to the tmp/pages directory under RAILS_ROOT, but is typically\n    # overridden in production environments.\n    #\n    # Returns the full path to the Pages directory as a String.\n    def pages_dir\n      @pages_dir ||=\n        if Rails.test?\n          File.expand_path(\"#{Rails.root}/tmp/pages#{test_environment_number}\").freeze\n        else\n          File.expand_path(\"#{Rails.root}/tmp/pages\").freeze\n        end\n    end\n    attr_writer :pages_dir\n\n    # Temporary directory where Pages sites are built before being copied to the\n    # pages_dir. This defaults to the tmp/pagebuild/<environment> directory, but\n    # is typically overridden in production environments.\n    #\n    # Returns the full path to the Pages build directory as a String.\n    def pages_build_dir\n      @pages_build_dir ||=\n        if Rails.test?\n          File.expand_path(\"#{Rails.root}/tmp/pagebuild/#{Rails.env}#{test_environment_number}\").freeze\n        else\n          File.expand_path(\"#{Rails.root}/tmp/pagebuild/#{Rails.env}\").freeze\n        end\n    end\n    attr_writer :pages_build_dir\n\n    # Location of Pages jekyll command. This is overriden in development\n    # environments.\n    def pages_jekyll_bin\n      @pages_jekyll_bin ||= \"/data/pages-jekyll/bin/jekyll\"\n    end\n    attr_writer :pages_jekyll_bin\n\n    # The maximum size of a built pages site in bytes. Set to 0 to disable\n    # the size limit.\n    def pages_site_size_limit\n      @pages_site_size_limit ||= (10 * 1024 * 1024 * 1024) # 10 GB\n    end\n    attr_writer :pages_site_size_limit\n\n    # ID of the GitHub Pages Oauth App\n    #\n    # Returns int ID the application ID, or nil if app doesn't exist\n    def pages_app_id\n      @pages_app_id ||= OauthApplication.where(\n        :user_id => trusted_oauth_apps_owner,\n        :name    => \"GitHub Pages\"\n      ).pluck(:id).first\n    end\n    attr_writer :pages_app_id\n\n    def pages_replica_count\n      @pages_replica_count ||= Rails.production? ? 3 : 1\n    end\n    attr_writer :pages_replica_count\n\n    # Gets the number of readonly replicas that are included in a page build,\n    # but not required for a successful consensus.\n    attr_accessor :pages_non_voting_replica_count\n\n    # Do we support custom pages CNAMEs in this environment?\n    #\n    # When custom CNAMEs are enabled, pages sites are served from\n    # USERNAME.github.io, or a custom domain the user provides in a `CNAME` file.\n    #\n    # When custom CNAMEs are disabled, pages sites are served from\n    # /pages/USERNAME/REPO and any `CNAME` file is ignored.\n    #\n    def pages_custom_cnames?\n      !enterprise?\n    end\n\n    def site_status_url\n      \"https://status.github.com\"\n    end\n\n    def show_site_status?\n      !enterprise?\n    end\n\n    ##\n    # Google Analytics\n\n    # The Google Analytics account in \"UA-XXXXXXX-X\" form. This is used in the\n    # JavaScript tracking code inserted into pages with analytics enabled.\n    attr_accessor :analytics_account\n    attr_accessor :gist_analytics_account\n\n    # Determine if Google Analytics tracking information should be inserted into\n    # page output. Analytics tracking is considered on if the analytics_account\n    # attribute is set.\n    #\n    # Returns true if tracking is enabled, false otherwise.\n    def analytics_enabled?\n      !analytics_account.nil?\n    end\n\n    # Get base URL for Google Analytics.\n    #\n    # Returns String URL or nil if Google Analytics is disabled.\n    def google_analytics_url\n      if analytics_enabled?\n        \"#{scheme}://www.google-analytics.com\"\n      end\n    end\n\n    # Third party hosts being added to the connect-src CSP directive.\n    #\n    # Needs to be enabled via allow_third_party_connect_sources.\n    #\n    # IMPORTANT!!! CC @github/dotcom-security if you need to change this.\n    def third_party_connect_sources\n      return @third_party_connect_sources if defined?(@third_party_connect_sources)\n\n      @third_party_connect_sources = [\n        google_analytics_url,\n        \"https://github-cloud.s3.amazonaws.com\",\n        \"https://#{RepositoryFile.storage_s3_new_bucket_host}\",\n        \"https://#{UploadManifestFile.storage_s3_new_bucket_host}\",\n        \"https://#{UserAsset.storage_s3_new_bucket_host}\",\n      ].freeze\n    end\n\n    # Custom setter to freeze the Object before setting it,\n    # to prevent future modifications.\n    def third_party_connect_sources=(sources)\n      @third_party_connect_sources = Array(sources).freeze\n    end\n\n    # LiveReload server URL that is added to the connect-src CSP directive in development.\n    def livereload_url\n      \"ws://127.0.0.1:35729/livereload\".freeze if Rails.development?\n    end\n\n    ##\n    # Octolytics, the new traffic analyisis tool.\n    # App ID\n    attr_accessor :octolytics_app_id\n    # Collector host for external clients\n    attr_accessor :octolytics_collector_host\n    # Collector host for internal clients (inside the GitHub network)\n    attr_writer   :octolytics_collector_internal_host\n    # Secret, for signing content that passes through the browser (e.g. the user id).\n    attr_accessor :octolytics_secret\n    # What octolytics environment should be used to pull report data from.\n    attr_accessor :octolytics_reporter_env\n    # Gist App ID\n    attr_accessor :gist_octolytics_app_id\n    # Gist Secret, for signing content that passes through the browser (e.g. the user id).\n    attr_accessor :gist_octolytics_secret\n\n    # Returns true if tracking on analytics is configured, false otherwise.\n    def octolytics_enabled?\n      !!octolytics_collector_host\n    end\n\n    ##\n    # Pond\n    attr_accessor :pond_shared_secret\n\n    # The Google Analytics username and password. This is used to fetch traffic\n    # data for specific repositories only.\n    attr_accessor :analytics_user\n    attr_accessor :analytics_pass\n\n    ##\n    # Twitter\n\n    # The Twitter OAuth access key as a String.\n    attr_accessor :twitter_key\n\n    # The Twitter OAuth secret key as a String.\n    attr_accessor :twitter_secret\n\n    ##\n    # Billing/Braintree\n\n    # Determine whether billing is enabled. Typically disabled under\n    # the enterprise environment. Enable via `gh-config` by setting\n    # BILLING_ENABLED to `1`, and disable with `0`. Defaults to true if\n    # no value is set.\n    #\n    # Returns true if billing is enabled, false otherwise.\n    def billing_enabled?\n      return false if enterprise?\n      return @billing_enabled if defined?(@billing_enabled)\n      @billing_enabled = ENV.fetch(\"BILLING_ENABLED\", \"1\") == \"1\"\n    end\n    attr_writer :billing_enabled\n\n    # Determine whether we want to make a request to Braintree for a client token use in PayPal\n    # forms. Usually false for the :test environment.\n    #\n    # Returns true if client tokens are enabled\n    def braintree_client_token_enabled?\n      billing_enabled? && @braintree_client_token_enabled\n    end\n    attr_accessor :braintree_client_token_enabled\n\n    # Determine the plan name assigned to users by default. Usually set to\n    # \"enterprise\" under enterprise or \"free\" for others.\n    #\n    # See also GitHub::Plan and User#plan.\n    #\n    # Returns the String plan name.\n    def default_plan_name\n      return @default_plan_name if defined?(@default_plan_name)\n      @default_plan_name =\n        if enterprise?\n          GitHub::Plan::ENTERPRISE\n        else\n          GitHub::Plan::FREE\n        end\n    end\n    attr_writer :default_plan_name\n\n    # Restrict signup to the default plan when enabled. Enabled by default\n    # under FI environments, disabled everywhere else.\n    #\n    # Returns true if enabled, false otherwise.\n    def enforce_default_plan?\n      return @enforce_default_plan if defined?(@enforce_default_plan)\n      @enforce_default_plan = enterprise?\n    end\n    attr_writer :enforce_default_plan\n\n    # Braintree configuration.\n    attr_accessor :braintree_environment\n    attr_accessor :braintree_merchant_id\n    attr_accessor :braintree_public_key\n    attr_accessor :braintree_private_key\n    attr_accessor :braintree_logger\n    attr_accessor :braintree_client_side_encryption_key\n\n    # Open Exchange Rates\n    attr_accessor :open_exchange_rates_app_id\n\n    ##\n    # NetSuite\n\n    # Netsuite login and account information.\n    attr_accessor :netsuite_login_email\n    attr_accessor :netsuite_password\n    attr_accessor :netsuite_account\n    attr_accessor :netsuite_role\n\n    # Ghost user login used to replace associated users of Issues-related\n    # records (Issue, IssueComment and IssueEvent) when the original user\n    # is deleted.\n    #\n    # Returns the String ghost User login.\n    def ghost_user_login\n      @ghost_user_login ||= \"ghost\"\n    end\n\n    # Staff user login used to be the actor for staff events\n    #\n    # Returns the String staff User login\n    def staff_user_login\n      @staff_user_login ||= \"github-staff\"\n    end\n\n    ##\n    # Authentication\n\n    attr_accessor :cas_url\n\n    attr_accessor :ldap_host, :ldap_port, :ldap_base,\n                  :ldap_bind_dn, :ldap_password, :ldap_method,\n                  :ldap_search_strategy,\n                  :ldap_virtual_attributes, :ldap_virtual_attribute_member,\n                  :ldap_recursive_group_search_fallback,\n                  :ldap_posix_support,\n                  :ldap_sync_enabled,\n                  :ldap_user_sync_emails, :ldap_user_sync_keys, :ldap_user_sync_gpg_keys,\n                  :ldap_profile_uid, :ldap_profile_name, :ldap_profile_mail,\n                  :ldap_profile_key, :ldap_profile_gpg_key\n\n    attr_accessor :saml_sso_url,           # idP http endpoint for sso. We redirect to here with an AuthnRequest.\n                  :saml_idp_initiated_sso, # if this is on, responses will not be checked for corresponding requests\n                  :saml_disable_admin_demote, # if this is on, admin bit is ignored and users won't promoted or demoted.\n                  :saml_issuer,            # idP issuer. Used to validate responses\n                  :saml_name_id_format,    # NameID format to use, (:persistent or unspecified). Unspecified should be discouraged\n                  :saml_certificate_file,  # idP certificate. Public key to validate idP responses.\n                  :saml_signature_method,  # algorithm to use for AuthnRequest signatures.\n                  :saml_digest_method,     # algotithm to use for AuthnRequest digests.\n                  :saml_sp_pkcs12_file,    # SP keypair for signing AuthnRequests and Metadata.\n                  :saml_admin,             # attribute name in saml response for promoting/demoting admins. Default: 'administrator'\n                  :saml_username_attr,      # attribute username in saml response for account login name. Default: 'NameID'\n                  :saml_profile_name,      # attribute name in saml response for user full name. Default: 'full_name'\n                  :saml_profile_mail,      # attribute name in saml response for user emails. Default: 'emails'\n                  :saml_profile_ssh_key,       # attribute name in saml response for user public keys. Default: 'public_keys'\n                  :saml_profile_gpg_key    # attribute name in saml response for user GPG keys. Default: 'gpg_keys'\n\n    # Public: Returns the verify_mode value used for SSL communications with\n    # LDAP server.\n    #\n    # See http://ruby-doc.org/stdlib/libdoc/openssl/rdoc/OpenSSL/SSL/SSLContext.html#verify_mode\n    # for available verify_mode values\n    def ldap_tls_verify_mode\n      @ldap_tls_verify_mode ||= OpenSSL::SSL::VERIFY_NONE\n    end\n\n    # Public: Sets the TLS verification mode. Value is expected to be an integer\n    #\n    # See http://ruby-doc.org/stdlib/libdoc/openssl/rdoc/OpenSSL/SSL/SSLContext.html#verify_mode\n    # for available verify_mode values\n    def ldap_tls_verify_mode=(verify_mode)\n      @ldap_tls_verify_mode = verify_mode.to_i\n    end\n\n    # Public: Returns true when LDAP authentication is configured and LDAP Sync is enabled.\n    # Managed via enterprise-manage.\n    def ldap_sync_enabled?\n      auth.ldap? && ldap_sync_enabled\n    end\n\n    # Public: Returns true if Emails are LDAP Synced.\n    def user_sync_emails?\n      ldap_sync_enabled? && ldap_user_sync_emails\n    end\n\n    # Public: Returns true if SSH Keys are LDAP Synced.\n    def user_sync_keys?\n      ldap_sync_enabled? && ldap_user_sync_keys\n    end\n\n    # Public: Returns true if SSH Keys are LDAP Synced.\n    def user_sync_gpg_keys?\n      ldap_sync_enabled? && ldap_user_sync_gpg_keys\n    end\n\n    # Authentication adapter options hash. See the adapter implementations under\n    # GitHub::Authentication for information on possible options.\n    def auth_options\n      if auth_mode.to_sym == :saml\n        {\n          :sso_url => saml_sso_url,\n          :idp_initiated_sso => saml_idp_initiated_sso,\n          :disable_admin_demote => saml_disable_admin_demote,\n          :issuer => saml_issuer,\n          :name_id_format => saml_name_id_format,\n          :signature_method => saml_signature_method,\n          :digest_method => saml_digest_method,\n          :idp_certificate_file => saml_certificate_file,\n          :sp_pkcs12_file => saml_sp_pkcs12_file,\n          :admin => saml_admin,\n          :username_attr => saml_username_attr,\n          :profile_fullname => saml_profile_name,\n          :profile_mail => saml_profile_mail,\n          :profile_ssh_key => saml_profile_ssh_key,\n          :profile_gpg_key => saml_profile_gpg_key,\n          :sp_url => url\n        }\n      else\n        {\n          # Used for SAML metdata, which should be available through non-SAML\n          # auth adaptors so that it can be retrieved before fully configuring SAML.\n          :sp_url => url,\n          :name_id_format => saml_name_id_format || \"urn:oasis:names:tc:SAML:2.0:nameid-format:persistent\"\n        }\n      end\n    end\n\n    def reactivate_suspended_user?\n      return false if !GitHub.enterprise?\n      return false if !GitHub.auth.external?\n\n      unless GitHub.config.get(\"auth.reactivate-suspended\").nil?\n        return GitHub.config.enabled?(\"auth.reactivate-suspended\")\n      end\n\n      #LDAP defaults to true\n      return true if GitHub.auth.ldap?\n\n      #Everything else defaults to false\n      return false\n    end\n\n    # Setting to disable password authentication for LDAP for Git operations\n    def external_auth_token_required\n      return false if !GitHub.enterprise?\n      return false if !GitHub.auth.external?\n      # External auth mechs other than LDAP do not support password auth\n      return true if !GitHub.auth.ldap?\n\n      return @external_auth_token_required if defined?(@external_auth_token_required)\n      return false\n    end\n    attr_writer :external_auth_token_required\n    alias :external_auth_token_required? :external_auth_token_required\n\n    # Algorithm to use for the SAML signature.\n    #\n    # As per the spec, https://www.w3.org/TR/xmldsig-core1/#sec-AlgID, there are\n    # several values to cater for with: rsa-sha1 (discouraged), rsa-sha256,\n    # rsa-sha384 and rsa-sha512 being the most commonly implemented.\n    #\n    # Default to rsa-sha256 as this is the recommended replacement for rsa-sha1.\n    def saml_signature_method\n      @saml_signature_method ||= \"http://www.w3.org/2001/04/xmldsig-more#rsa-sha256\"\n    end\n\n    # Allow the setting of one of four options with rsa-sha256 being enforced if\n    # an invalid value is given.\n    def saml_signature_method=(value)\n      @saml_signature_method =\n        case value\n        when \"rsa-sha1\"\n          \"http://www.w3.org/2000/09/xmldsig#rsa-sha1\"\n        when \"rsa-sha384\", \"rsa-sha512\"\n          \"http://www.w3.org/2001/04/xmldsig-more##{value}\"\n        else\n          \"http://www.w3.org/2001/04/xmldsig-more#rsa-sha256\"\n        end\n    end\n\n    # Algorithm to use for the SAML digest.\n    #\n    # As per the spec, https://www.w3.org/TR/xmldsig-core1/#sec-AlgID, there are\n    # several values to cater for with: sha1 (discouraged), sha256, and sha512\n    # being the most commonly implemented.\n    #\n    # Default to sha256 as this is the recommended replacement for sha1.\n    def saml_digest_method\n      @saml_digest_method ||= \"http://www.w3.org/2001/04/xmlenc#sha256\"\n    end\n\n    # Allow the setting of one of five options with sha256 being enforced if\n    # an invalid value is given.\n    def saml_digest_method=(value)\n      @saml_digest_method =\n        if value == \"sha1\"\n          \"http://www.w3.org/2000/09/xmldsig#sha1\"\n        elsif value == \"sha512\"\n          \"http://www.w3.org/2001/04/xmlenc#sha512\"\n        else\n          \"http://www.w3.org/2001/04/xmlenc#sha256\"\n        end\n    end\n\n    def saml_name_id_format=(value)\n      @saml_name_id_format =\n        if value == \"unspecified\"\n          \"urn:oasis:names:tc:SAML:1.1:nameid-format:unspecified\"\n        else\n          \"urn:oasis:names:tc:SAML:2.0:nameid-format:persistent\"\n        end\n    end\n\n    def sso_credential_authorization_help_url\n      ENV.fetch(\n        \"GITHUB_SSO_CREDENTIAL_AUTHORIZATION_HELP_URL\",\n        \"#{GitHub.help_url}/articles/authenticating-to-a-github-organization-with-saml-single-sign-on/\"\n      )\n    end\n\n    def iam_with_saml_sso_help_url\n      ENV.fetch(\n        \"GITHUB_IAM_WITH_SAML_SSO_HELP_URL\",\n        GitHub.help_url\n      )\n    end\n\n    def ldap_base=(ldap_base)\n      if !ldap_base.respond_to?(:each)\n        # If the domain base list comes from an environment variable we need to split it up.\n        ldap_base = String(ldap_base).split(\";\")\n      end\n      @ldap_base = ldap_base\n    end\n    attr_reader :ldap_base\n\n    # Public: LDAP Admin group defines which users are administrators based on\n    # group membership.\n    def ldap_admin_group=(group)\n      @ldap_auth_groups = nil\n      @ldap_admin_group = group\n    end\n    attr_reader :ldap_admin_group\n\n    # Public: LDAP user groups defines membership requirements for\n    # authenticating users.\n    def ldap_user_groups=(ldap_user_groups)\n      if !ldap_user_groups.respond_to?(:each)\n        # If the user groups list comes from an environment variable we need to split it up.\n        ldap_user_groups = String(ldap_user_groups).split(\";\")\n      end\n      ldap_user_groups.compact!\n      @ldap_auth_groups = nil\n      @ldap_user_groups = ldap_user_groups\n    end\n    attr_reader :ldap_user_groups\n\n    # Public: LDAP Groups users must belong to in order to successfully\n    # authenticate.\n    #\n    # Returns an empty Array if authentication is not scoped to groups.\n    # Returns an Array of group String names, including the admin group.\n    def ldap_auth_groups\n      return [] if ldap_user_groups.blank?\n      @ldap_auth_groups ||= begin\n        groups = ldap_user_groups + Array(ldap_admin_group)\n        groups.uniq!\n        groups.reject!(&:blank?)\n        groups\n      end\n    end\n\n    # Public: LDAP Search Strategy for Team Sync Member Search and\n    # authentication restricted group Membership Validation.\n    #\n    # Defaults to `detect` to force detection of the optimal strategy.\n    def ldap_search_strategy\n      @ldap_search_strategy ||= \"detect\"\n    end\n\n    # Public: Defines the maximum depth of recursion the Recursive search\n    # strategy can descend. Only used to the Recursive strategy.\n    #\n    # Pulls the value from the `ldap.search_strategy_depth` global config.\n    #\n    # Returns nil or the configured Integer depth.\n    def ldap_search_strategy_depth\n      if depth = GitHub.config.get(\"ldap.search_strategy_depth\")\n        depth.to_i\n      end\n    end\n\n    # The LDAP User Sync job interval in Integer of hours.\n    # Defaults to every 4 hours. See: GitHub::Jobs::LdapUserSync.\n    def ldap_user_sync_interval\n      @ldap_user_sync_interval ||= 4\n    end\n\n    # Set the LDAP User Sync job interval.\n    # Requires an interval greater than zero.\n    def ldap_user_sync_interval=(interval)\n      @ldap_user_sync_interval = interval.to_i if interval.to_i > 0\n    end\n\n    # The LDAP Team Sync job interval in Integer of hours.\n    # Defaults to every 4 hours. See: GitHub::Jobs::LdapTeamSync.\n    def ldap_team_sync_interval\n      @ldap_team_sync_interval ||= 4\n    end\n\n    # Set the LDAP Team Sync job interval.\n    # Requires an interval greater than zero.\n    def ldap_team_sync_interval=(interval)\n      @ldap_team_sync_interval = interval.to_i if interval.to_i > 0\n    end\n\n    # Whether the LDAP server supports virtual attributes like memberOf.\n    def ldap_virtual_attributes\n      return @ldap_virtual_attributes if defined?(@ldap_virtual_attributes)\n      @ldap_virtual_attributes = false\n    end\n\n    # Whether the LDAP group membership check should fallback to the slow non\n    # virtual attribute implementation when virtual attributes are disabled.\n    # This is false by default to prevent bad performance.\n    def ldap_recursive_group_search_fallback\n      return @ldap_recursive_group_search_fallback if defined?(@ldap_recursive_group_search_fallback)\n      @ldap_recursive_group_search_fallback = false\n    end\n\n    # Whether the LDAP group membership check should include posixGroup\n    # conditions.\n    # This is true by default.\n    def ldap_posix_support\n      return @ldap_posix_support if defined?(@ldap_posix_support)\n      @ldap_posix_support = true\n    end\n\n    # The amount of time we allow for LDAP authentication requests before timing out\n    def ldap_auth_timeout\n      @ldap_auth_timeout ||= 10\n    end\n\n    # Set the amount of time we allow for LDAP authentication requests before timing out\n    def ldap_auth_timeout=(value)\n      @ldap_auth_timeout = value if value > 0 && value <= GitHub.default_request_timeout\n    end\n\n    def auth_mode\n      @auth_mode ||= :default\n    end\n\n    def auth_mode=(mode)\n      @auth_adaptor = nil\n      @auth_mode = mode\n    end\n\n    # default password for user\n    attr_accessor :default_password\n\n    # Instantiate the Authentication object for handling auth configuration and inquiries.\n    #\n    # Returns an Authentication.\n    def auth_modes\n      @auth_modes ||= {\n        :default      => GitHub::Authentication::Default,\n        :ldap         => GitHub::Authentication::LDAP,\n        :cas          => GitHub::Authentication::CAS,\n        :github_oauth => GitHub::Authentication::GitHubOauth,\n        :saml         => GitHub::Authentication::SAML\n      }\n    end\n\n    # The instantiated Authentication adapter.\n    def auth\n      @auth_adaptor ||= auth_modes[auth_mode.to_sym].new(auth_options)\n    end\n\n    # Determines whether this is the very first time an Enterprise installation\n    # is being accessed. This is primarily used to determine whether or not the\n    # user being created should be auto-promoted to site admin status (the first\n    # user on installations are auto-promoted). You can pass in the env variable\n    # ENTERPRISE_FIRST_RUN to emulate this in development (hence the attr_writer).\n    #\n    # Returns true if no users have been created yet on the installation.\n    def enterprise_first_run?\n      # This nil check instead of `defined?` allows the attr_writer to reset\n      # this memoized value in tests by setting first_run to nil.\n      if @first_run.nil?\n        if GitHub::Enterprise.license.seats_used == 0\n          # Don't memoize a true value, this needs to be checked until\n          # seats_used is greater than zero.\n          true\n        else\n          # Now that there is at least one seat used, no more checks are\n          # required. Memoize the result.\n          @first_run = false\n        end\n      else\n        @first_run\n      end\n    end\n    attr_writer :first_run\n\n    # Available log levels.\n    RAILS_LOG_LEVELS = [:debug, :info, :warn, :error, :fatal]\n\n    # The log level used by the application. Possible log levels are :debug, :info,\n    # :warn, :error, and :fatal. This value is set by github/config/environments/<env>.rb\n    # scripts but can be adjusted under enterprise by the ENTERPRISE_RAILS_LOG_LEVEL\n    # environment variable or by modifying the RAILS_ROOT/config.yml file.\n    #\n    # Returns the configured log level as a symbol. If no log level is set\n    # explicitly, :info is returned.\n    def rails_log_level\n      @rails_log_level ||= :info\n    end\n\n    # Set the rails_log_level, verifying the value given.\n    #\n    # value - One of the LOG_LEVEL symbol values or a number between 0 and 4.\n    #\n    # Raises a TypeError when the value is not a supported log level.\n    def rails_log_level=(value)\n      value = value.to_i if value.is_a?(String) && value =~ /[0-4]/\n      value = value.to_sym if value.is_a?(String)\n      value = RAILS_LOG_LEVELS[value] if value.is_a?(Integer)\n\n      if RAILS_LOG_LEVELS.include?(value)\n        @rails_log_level = value\n      else\n        raise TypeError, \"Illegal value: #{value.inspect}\"\n      end\n    end\n\n    # Unicorn master/worker attributes\n    attr_accessor :unicorn_master_start_time\n    attr_accessor :unicorn_worker_start_time\n    attr_accessor :unicorn_master_pid\n    attr_accessor :unicorn_worker_request_count\n\n    # Determine whether Private Mode is enabled for GitHub (FI). Private Mode\n    # locks down the site- users must be logged in to view and use GitHub, and\n    # new user signups are restricted to admins only. This also disables\n    # various other functionality for the sake of a private GitHub (such as\n    # serving repositories over git://). It also causes all atom feeds to include\n    # login/token parameters, just like private feeds (see github/enterprise#244).\n    #\n    # Returns a Boolean.\n    def private_mode\n      return @private_mode if defined?(@private_mode)\n      @private_mode = GitHub.enterprise? && !(ENV[\"PRIVATE_MODE\"]).to_s.empty?\n    end\n    attr_writer :private_mode\n\n    # Is Private Mode enabled?\n    def private_mode_enabled?\n      private_mode\n    end\n\n    # Determine whether subdomain isolation is enabled for GitHub (FI).\n    # Subdomain isolation places various components of GitHub (raw, uploads,\n    # pages, etc) on their own subdomain. This prevents user controlled content\n    # from executing in the same origin as the rest of GitHub. As a result,\n    # attacks such as XSS on these subdomains are much less critical as they\n    # will be unable to access content on the main GitHub site and will not be\n    # able to perform security sensitive operations (accessing repos, etc).\n    #\n    # Returns a Boolean.\n    def subdomain_isolation\n      return @subdomain_isolation if defined?(@subdomain_isolation)\n      @subdomain_isolation = true\n    end\n    attr_writer :subdomain_isolation\n    alias :subdomain_isolation? :subdomain_isolation\n\n    # Using Private Mode and Subdomains for maximum privacy and security.\n    #\n    # Causes private mode authentication cookies to be set on *.githubhostname.\n    #\n    # Enabled when both using Enterprise isolated subdomains and Private Mode.\n    def subdomain_private_mode_enabled?\n      private_mode_enabled? && subdomain_isolation?\n    end\n\n    # Secret used for HMACing request information for proxy site detection.\n    attr_accessor :proxy_site_detection_secret\n\n    # Determine whether to create repositories in DGit by default\n    #\n    # Returns true if it's enabled, false otherwise\n    def dgit_intake_enabled?\n      if defined?(@dgit_intake_enabled)\n        return @dgit_intake_enabled\n      end\n      @dgit_intake_enabled = true  # defaults to true on dotcom\n    end\n    attr_writer :dgit_intake_enabled\n\n    # ID of the GitHub Enterprise Site Administrator Oauth App ID, which is\n    # the owner of Api::Admin::UsersManager tokens used for user impersonation.\n    #\n    # Returns int ID, or nil if the app doesn't exist and can't be created\n    def enterprise_admin_oauth_app_id\n      return nil unless GitHub.enterprise?\n      @enterprise_admin_oauth_app_id ||=\n        if app = OauthApplication.where({\n          user_id: GitHub.trusted_oauth_apps_owner,\n          name: \"GitHub Site Administrator\",\n          full_trust: true\n          }).first\n          app.id\n        elsif app = OauthApplication.register_trusted_application(\n          \"Site Administrator\",\n          SecureRandom.hex(10),\n          SecureRandom.hex(20),\n          \"https://developer.github.com/v3/enterprise/users/\",\n          \"https://developer.github.com/v3/enterprise/users/\"\n          )\n          app.id\n        else\n          nil\n        end\n    end\n\n    ##\n    # Custom Hooks (Enterprise)\n\n    # Location where custom git hooks data lives.\n    def custom_hooks_dir\n      @custom_hooks_dir ||= if Rails.production?\n                              \"/data/user/git-hooks\"\n                            elsif Rails.test?\n                              ENV[\"TEST_HOOK_DIR\"] || \"#{Rails.root}/git-hooks\"\n                            else\n                              \"#{Rails.root}/git-hooks\"\n                            end\n    end\n    attr_writer :custom_hooks_dir\n\n    def pre_receive_hooks_enabled?\n      GitHub.enterprise? || !Rails.production?\n    end\n\n    # The password cost factor for Bcrypt\n    def password_cost\n      @password_cost ||= BCrypt::Engine::DEFAULT_COST\n    end\n    attr_writer :password_cost\n\n    # The key we use to encrypt two-factor secrets in the database\n    attr_accessor :two_factor_salt\n\n    # The key we use to encrypt SAML provider recovery keys in the database\n    attr_accessor :saml_provider_salt\n\n    # U2F instance for FIDO U2F authentication.\n    #\n    # Returns a U2F::U2F instance.\n    def u2f\n      @u2f ||= U2F::U2F.new(u2f_app_id)\n    end\n\n    # The app id to use for FIDO U2F. This points to\n    # u2f_registrations#trusted_facets which tells U2F devices to trust a set\n    # of domains to share registrations.\n    #\n    # Returns a String URL.\n    def u2f_app_id\n      \"#{url}/u2f/trusted_facets\"\n    end\n\n    # The list of domains that are trusted to share U2F devices. In production\n    # this includes staging/admin domains. On enterprise and development this\n    # is just the app's URL itself.\n    #\n    # Returns an Array of String URLs.\n    def u2f_trusted_facets\n      @u2f_trusted_facets ||= [url].freeze\n    end\n    attr_writer :u2f_trusted_facets\n\n    # Constant BCrypt salt to be able to get the same hash for the same\n    # password. Used for tracking passwords from failed login attempts.\n    def constant_bcrypt_salt\n      @constant_bcrypt_salt ||= BCrypt::Engine.generate_salt(password_cost)\n    end\n    attr_writer :constant_bcrypt_salt\n\n    ##\n    # Failbot / Exceptions reporting.\n\n    # Failbot customization. Under most environments, the default config\n    # that's provided out of the box by the Failbot library is sensible but in\n    # some cases (FI), it is useful to override it.\n    #\n    # Default to writing JSON-encoded exceptions to log/exceptions.log under FI\n    # environments. Other environments use whatever the default Failbot config\n    # of the current RAILS_ENV is.\n    #\n    # Returns the Failbot custom config Hash to be passed to Failbot.setup.\n    def failbot\n      @failbot ||=\n        if Rails.test?\n          {\n            \"FAILBOT_BACKEND\" => \"memory\"\n          }\n        elsif Rails.development? || enterprise?\n          {\n            \"FAILBOT_BACKEND\" => \"file\",\n            \"FAILBOT_BACKEND_FILE_PATH\" => failbot_log_path\n          }\n        else\n          {\n            \"FAILBOT_BACKEND\" => \"json\",\n            \"FAILBOT_BACKEND_JSON_HOST\" => \"localhost\",\n            \"FAILBOT_BACKEND_JSON_PORT\" => 6668\n          }\n        end\n    end\n    attr_writer :failbot\n\n    # Failbot log file location, if applicable.\n    def failbot_log_path\n      \"#{Rails.root}/log/exceptions.log\"\n    end\n\n    ##\n    # Miscellaneous feature flags typically disabled under FI environments.\n\n    # Determine whether the blog is enabled. This is disabled under FI\n    # environments but enabled everywhere else.\n    #\n    # Returns true if it is enabled, false otherwise.\n    def blog_enabled?\n      return @blog_enabled if defined?(@blog_enabled)\n      @blog_enabled = !enterprise?\n    end\n    attr_writer :blog_enabled\n\n    # Determine whether to display terms/security/privacy in footer. This is\n    # disabled under FI environments but enabled everywhre else.\n    #\n    # Returns true if it's enabled, false otherwise\n    def footer_legalese_enabled?\n      if defined?(@footer_legalese_enabled)\n        return @footer_legalese_enabled\n      end\n      @footer_legalese_enabled = !enterprise?\n    end\n    attr_writer :footer_legalese_enabled\n\n    # Determine whether to show things related to licensing in GitHub. This is\n    # primarily the license picker and auto-license population during repository\n    # creation.\n    #\n    # Returns true if the license picker should be displayed, false otherwise.\n    def license_picker_enabled?\n      return @license_picker_enabled if defined?(@license_picker_enabled)\n\n      @license_picker_enabled = !enterprise?\n    end\n    attr_writer :license_picker_enabled\n\n    # Determine whether to show the Code of Conduct editor.\n    #\n    # Returns true if the code of conduct picker should be displayed, false otherwise.\n    def code_of_conduct_picker_enabled?\n      @code_of_conduct_picker_enabled ||= !enterprise?\n    end\n    attr_writer :code_of_conduct_picker_enabled\n\n    # Custom tabs allow repository admins to configure custom repository tabs\n    # displayed in the repository navigation, that point to an arbitraty URL.\n    # This is enabled under Enterprise environments but disabled everywhere else.\n    #\n    # Returns true if enabled, false otherwise.\n    def custom_tabs_enabled?\n      return @custom_tabs_enabled if defined?(@custom_tabs_enabled)\n      @custom_tabs_enabled = enterprise?\n    end\n    attr_writer :custom_tabs_enabled\n\n    # Allow users to enter a short professional bio and mark themselves as being\n    # hireable. This is disabled by default under FI environments and enabled\n    # everywhere else, altough we're not taking advantage of this data yet.\n    #\n    # Returns true if enabled, false otherwise.\n    def job_profiles_enabled?\n      return @job_profiles_enabled if defined?(@job_profiles_enabled)\n      @job_profiles_enabled = !enterprise?\n    end\n    attr_writer :job_profiles_enabled\n\n    # Determine whether restrictions around spammy users are enforced\n    # throughout the site. Disabled by default under Enterpise environments, enabled\n    # everywhere else.\n    #\n    # Returns true if enabled, false otherwise.\n    def spamminess_check_enabled?\n      return @spamminess_check_enabled if defined?(@spamminess_check_enabled)\n      @spamminess_check_enabled = !enterprise?\n    end\n    attr_writer :spamminess_check_enabled\n\n    # How long do we memoize spam patterns during Spam checking?\n    #\n    # We default to 0 if no value is set in the environment.\n    #\n    # Returns an integer.\n    def spam_pattern_memoization_ttl_in_seconds\n      return @spam_pattern_memoization_ttl_in_seconds if defined?(@spam_pattern_memoization_ttl_in_seconds)\n      @spam_pattern_memoization_ttl_in_seconds = (ENV[\"SPAM_PATTERNS_MEMOIZED_TTL_IN_SECONDS\"] || 0).to_i\n    end\n    attr_writer :spam_pattern_memoization_ttl_in_seconds\n\n    # Should we report user-creation data to Octolytics?\n    #\n    # Returns false in enterprise.\n    def user_creation_analytics_enabled?\n      octolytics_enabled? && !enterprise?\n    end\n\n    # Determine whether suspended users are hidden from other users. Enabled\n    # by default under all environments.\n    #\n    # Returns true if enabled, false otherwise.\n    def suspended_users_visible?\n      return @suspended_users_visible if defined?(@suspended_users_visible)\n      @suspended_users_visible = true\n    end\n    attr_writer :suspended_users_visible\n\n    # Determine whether /admin is enabled. Redirects to Staff Tools when\n    # disabled. Disable by default under Enterprise environments, enabled everywhere\n    # else.\n    #\n    # Returns true if enabled, false otherwise.\n    def admin_enabled?\n      return @admin_enabled if defined?(@admin_enabled)\n      @admin_enabled = !enterprise?\n    end\n    attr_writer :admin_enabled\n\n    # Determine whether /setup is enabled. Enabled by default in Enterprise,\n    # disabled for dotcom.\n    #\n    # Returns true if enabled, false otherwise.\n    def management_console_enabled?\n      return @management_console_enabled if defined?(@management_console_enabled)\n      @management_console_enabled = enterprise?\n    end\n    attr_writer :management_console_enabled\n\n    # Determine whether Haystack is available. Currently dotcom only.\n    #\n    # Returns true if haystack is enabled, false otherwise.\n    def haystack_enabled?\n      return @haystack_enabled if defined?(@haystack_enabled)\n      @haystack_enabled = !enterprise?\n    end\n    attr_writer :haystack_enabled\n\n    # Determine whether the instance wide audit log is enabled. Currently dotcom\n    # only.\n    #\n    # Returns true if enabled, false otherwise.\n    def instance_audit_log_enabled?\n      return @instance_audit_log_enabled if defined?(@instance_audit_log_enabled)\n      @instance_audit_log_enabled = enterprise?\n    end\n    attr_writer :instance_audit_log_enabled\n\n    # Determine whether reports are enabled. Current only used\n    # in Enterprise.\n    #\n    # Returns true if enabled, false otherwise.\n    def reports_enabled?\n      return @reports_enabled if defined?(@reports_enabled)\n      @reports_enabled = GitHub.enterprise?\n    end\n    attr_writer :reports_enabled\n\n    # Determine whether large blobs should be rejected or not.\n    # We currently don't reject large blobs in Enterprise.\n    #\n    # Returns true if enabled, false otherwise.\n    def large_blob_rejection_enabled?\n      return @large_blob_rejection_enabled if defined?(@large_blob_rejection_enabled)\n      @large_blob_rejection_enabled = true\n    end\n    attr_writer :large_blob_rejection_enabled\n\n    # Is the rejection of 40 character hex names for refs enabled?\n    def reject_sha_like_refs?\n      return @reject_sha_like_refs if defined?(@reject_sha_like_refs)\n      @reject_sha_like_refs = true\n    end\n    attr_writer :reject_sha_like_refs\n\n    # The maximum length of reference names.\n    #\n    # This is defined as the minimum size for the `pushes.refs` and\n    # `reflog_entries.refs` database columns. Refs longer than this will be\n    # truncated and cause query warnings.\n    def maximum_ref_length\n      @maximum_ref_length ||= 255\n    end\n    attr_writer :maximum_ref_length\n\n    # Whether repository health checks are available. Only available in\n    # dotcom environments right now.\n    #\n    # Returns true if enabled, false otherwise.\n    def repository_health_enabled?\n      !enterprise?\n    end\n\n    # Determine whether organization OAuth application policies are available.\n    # (This feature is currently available only in dotcom environments.)\n    #\n    # Returns true if enabled, false otherwise.\n    def oauth_application_policies_enabled?\n      !enterprise?\n    end\n\n    # Determines if we should scan for sensitive tokens in repositories.\n    # (This feature is currently available only in dotcom environments.)\n    #\n    # Returns true if enabled, false otherwise.\n    def token_scanning_enabled?\n      !enterprise?\n    end\n\n    # Determine if site admins can initiate a site-wide ssh key audit.\n    # Enabled by default in Enterprise, disabled for dotcom.\n    #\n    # Returns true if enabled, false otherwise.\n    def ssh_audit_enabled?\n      return @ssh_audit_enabled if defined?(@ssh_audit_enabled)\n      @ssh_audit_enabled = enterprise?\n    end\n    attr_writer :ssh_audit_enabled\n\n    # Determine whether repo transfers require approval.\n    #\n    # Returns true if enabled, false otherwise.\n    def repository_transfer_requests_enabled?\n      return @repository_transfer_requests_enabled if defined?(@repository_transfer_requests_enabled)\n      @repository_transfer_requests_enabled = !enterprise?\n    end\n    attr_writer :repository_transfer_requests_enabled\n\n    # Determine whether employee-only features are available. Disabled by\n    # default under Enterprise environments, enabled everywhere else.\n    #\n    # Returns true if enabled, false otherwise.\n    def preview_features_enabled?\n      return @preview_features_enabled if defined?(@preview_features_enabled)\n      @preview_features_enabled = !enterprise?\n    end\n    attr_writer :preview_features_enabled\n\n    # Whether public-push repositories are enabled.\n    # See: https://github.com/github/github/pull/15785\n    def public_push_enabled?\n      GitHub.enterprise?\n    end\n\n    # Whether browser stats collecting is enabled\n    def browser_stats_enabled?\n      return @browser_stats_enabled if defined?(@browser_stats_enabled)\n      @browser_stats_enabled = true\n    end\n    attr_writer :browser_stats_enabled\n\n    # The API URL to post browser stats to.\n    def browser_stats_url\n      [api_url, \"_private\", \"browser\", \"stats\"].join(\"/\")\n    end\n\n    # The API URL that JavaScript exceptions are reported to.\n    def browser_errors_url\n      [api_url, \"_private\", \"browser\", \"errors\"].join(\"/\")\n    end\n\n    # Is SMTP enabled in this environment?\n    #\n    # Returns true by default.\n    # Can return false in Enterprise environments if an admin has disabled SMTP\n    # on the appliance.\n    def smtp_enabled?\n      return @smtp_enabled if defined?(@smtp_enabled)\n      @smtp_enabled = true\n    end\n    attr_writer :smtp_enabled\n\n    # The SMTP domain name.\n    def smtp_domain\n      @smtp_domain ||= host_name\n    end\n    attr_writer :smtp_domain\n\n    # SMTP server address.\n    attr_accessor :smtp_address\n\n    # SMTP port.\n    def smtp_port\n      @smtp_port ||= 25\n    end\n    attr_writer :smtp_port\n\n    # The secret token used in the generation of the recipient code for\n    # reply emails.\n    #\n    # Returns 'hubbernaut' by default.\n    def smtp_secret\n      return @smtp_secret if defined?(@smtp_secret)\n      @smtp_secret ||= \"hubbernaut\"\n    end\n    attr_writer :smtp_secret\n\n    # Additional SMTP configuration.\n    attr_accessor :smtp_user_name\n    attr_accessor :smtp_password\n    attr_accessor :smtp_authentication\n\n    # Default .com to having it disabled because the\n    # front-end & worker machines talk to an MTA on localhost\n    def smtp_enable_starttls_auto\n      enterprise? ? @smtp_enable_starttls_auto : false\n    end\n    attr_writer :smtp_enable_starttls_auto\n\n    # Determine if this environment send campfire notifications.\n    #\n    # Returns true unless this is an enterprise instance.\n    def campfire_notifications?\n      !enterprise?\n    end\n\n    # The name of the session cookie used for rails sessions.\n    #\n    # Returns '_gh_sess' by default under dotcom mode and '_gh_ent' under\n    # enterprise mode.\n    def session_key\n      @session_key ||=\n        if GitHub.runtime.enterprise?\n          \"_gh_ent\"\n        else\n          \"_gh_sess\"\n        end\n    end\n    attr_writer :session_key\n\n    # The secret token for both rails and rack session signatures. This value is\n    # also used by enterprise-manage's sessions.\n    attr_accessor :session_secret\n\n    ##\n    # Network Graph\n\n    # Maximum number of commits (dots) to show on the Network Graph.\n    def network_graph_history_limit\n      @network_graph_history_limit ||= enterprise?? 50_000 : 5_000\n    end\n    attr_writer :network_graph_history_limit\n\n    # The limit of how many times an email check request can happen per\n    # ip address.\n    #\n    # Returns a fixnum limit that can be combined with a ttl.\n    def email_check_rate_limit\n      @email_check_rate_limit ||= enterprise? ? 120 : 5000\n    end\n    attr_writer :email_check_rate_limit\n\n    # The lifespan of an email check rate limit.\n    #\n    # Returns a fixnum representing time in seconds.\n    def email_check_ttl\n      @email_check_ttl ||= enterprise? ? 1.minute : 1.hour\n    end\n    attr_writer :email_check_ttl\n\n    # The Enterprise configuration id. An integer timestamp representing the\n    # last time the configuration chef run was started. This is exposed at\n    # /status.json and is useful for determining if the app is running under\n    # the expected or newer configuration version.\n    def configuration_id\n      @configuration_id.to_i rescue nil\n    end\n    attr_writer :configuration_id\n\n    # The port the git daemon in listening on locally. In production the default\n    # git port (9418) is used. On enterprise git_proxy needs to consume 9418 so\n    # the daemon must listen on something else.\n    #\n    # Returns 9418 in production.\n    def git_daemon_port\n      @git_daemon_port ||= 9418\n    end\n    attr_writer :git_daemon_port\n\n    # The fingerprint of the RSA host key. Constant on production, unique per\n    # server on enterprise.\n    #\n    # Return the fingerprint of the RSA host key.\n    def rsa_fingerprint\n      if enterprise?\n        local_hostkey_fingerprint\n      else\n        \"16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48\"\n      end\n    end\n\n    # Fingerprint of the local RSA host key. Used on enterprise instances.\n    #\n    # Return the fingerprint of the RSA host key.\n    def local_hostkey_fingerprint\n      @local_hostkey_fingerprint ||= begin\n        %x{ssh-keygen -l -f /etc/ssh/ssh_host_rsa_key}.split[1]\n      end\n    end\n\n    # New accounts are created through the signup page on enterprise instances.\n    # Not used by some external auth providers, or when in private mode, or when\n    # explicitly disabled during setup.\n    #\n    # Returns boolean\n    def signup_enabled?\n      return true unless enterprise?\n\n      !GitHub.private_mode_enabled? && GitHub.auth.signup_enabled? && GitHub.signup_enabled\n    end\n\n    # In Enterprise, admins can explicitly disable signups.\n    def signup_enabled\n      @signup_enabled\n    end\n    attr_writer :signup_enabled\n\n    # In Enterprise, realtime backups are manually enabled\n    def realtime_backups_enabled?\n      !!@realtime_backups_enabled\n    end\n    attr_writer :realtime_backups_enabled\n\n    # In Enterprise we hide the ability to block users and report\n    # abuse.\n    def user_abuse_mitigation_enabled?\n      return @user_abuse_mitigation_enabled if defined?(@user_abuse_mitigation_enabled)\n      @user_abuse_mitigation_enabled = !enterprise?\n    end\n    attr_writer :user_abuse_mitigation_enabled\n\n    # Timeout for long running Git operations in templates (e.g.,\n    # rendering diffs and commit lists in pull requests).\n    def git_template_timeout\n      @git_template_timeout ||= 10\n    end\n    attr_writer :git_template_timeout\n\n    # Enterpise customers may want to customize the email address used as the\n    # noreply sender.\n    #\n    # Returns an email address as a string. Default is noreply@<host_name>.\n    def noreply_address\n      @noreply_address ||= \"noreply@#{smtp_domain}\"\n    end\n    attr_writer :noreply_address\n\n    # Stealth email is disabled on Enterprise instances.\n    def stealth_email_enabled?\n      !enterprise?\n    end\n\n    # Allow turning on/off email replies to notifications.\n    #\n    # Defaults to true.\n    def email_replies_enabled?\n      return @email_replies_enabled if defined?(@email_replies_enabled)\n      @email_replies_enabled = true\n    end\n    attr_writer :email_replies_enabled\n\n    # Email verification is disabled on Enterprise instances\n    def email_verification_enabled?\n      return false if enterprise?\n      true\n    end\n\n    # Mandatory email verification is turned off in dev and test, and anywhere\n    # email verification is disabled. NOTE: Enforcement still requires the\n    # presence of the mandatory_email_verification experiment and feature.\n    #\n    # Force with the ENABLE_MANDATORY_VERIFICATION environment variable, e.g.:\n    #\n    #   ENABLE_MANDATORY_VERIFICATION=1 script/server\n    def mandatory_email_verification_enabled?\n      return true if !!ENV[\"ENABLE_MANDATORY_VERIFICATION\"]\n      email_verification_enabled? && !(Rails.test? || Rails.development?)\n    end\n\n    # Email preference center is disabled on Enterprise instances\n    # because we don't need to send marketing newsletters to those users.\n    def email_preference_center_enabled?\n      !enterprise?\n    end\n\n    # The MailChimp integration is is disabled on Enterprise.\n    def mailchimp_enabled?\n      !enterprise?\n    end\n\n    # We require a password confirmation on signup in Enterprise\n    # because email delivery might not be enabled for the instance,\n    # which means that a user couldn't reset their password via email.\n    def password_confirmation_required?\n      enterprise?\n    end\n\n    # We ask users identity questions on dotcom during signup.\n    # Disabled on Enterprise.\n    def user_identification_enabled?\n      !enterprise?\n    end\n\n    # Live Update XHR Socket poller\n    #\n    # Can be flipped off if the web socket connections are going nuts.\n    def live_updates_enabled?\n      return @live_updates_enabled if defined?(@live_updates_enabled)\n      @live_updates_enabled = true\n    end\n    attr_writer :live_updates_enabled\n\n    # Should Live Update configuration delegate to flipper.\n    #\n    # Flipper configuration is only setup in github.com production.\n    def live_updates_flipper_controlled?\n      return @live_updates_flipper_controlled if defined?(@live_updates_flipper_controlled)\n      @live_updates_flipper_controlled = false\n    end\n    attr_writer :live_updates_flipper_controlled\n\n    # Check to see if we are restriced by licenses, in other words if we are an\n    # enterprise install.  Determines what to show in the root of stafftools\n    def licensed_mode?\n      enterprise?\n    end\n\n    # The path to the local .ghl file on Enterprise instances.\n    def license_path\n      return unless enterprise?\n\n      @license_path ||= File.join(enterprise_config_dir, \"enterprise.ghl\")\n    end\n    attr_writer :license_path unless Rails.production?\n\n    # Path to the license .gpg key shipped as part of an Enterprise .ova.\n    def license_key\n      @license_key ||= File.join(enterprise_config_dir, \"license.gpg\")\n    end\n    attr_writer :license_key unless Rails.production?\n\n    # Path to the customer .gpg key uploaded as part of the Enterprise license.\n    def customer_key\n      @customer_key ||= File.join(enterprise_config_dir, \"customer.gpg\")\n    end\n    attr_writer :customer_key unless Rails.production?\n\n    # The configuration directory holding Enterprise related files like the\n    # .ghl license, customer gpg key, and license gpg key.\n    #\n    # Returns the path to the config dir for the current Enterprise series.\n    def enterprise_config_dir\n      \"/data/enterprise\"\n    end\n\n    # Placeholder to abstract the fact that GitHub access control is done\n    # through GitHub::AccessControl.\n    def access\n      Egress::AccessControl\n    end\n\n    # enterprise-web URL\n    attr_accessor :enterprise_web_url\n\n    # Sets the API token for accessing the enterprise-web API\n    attr_accessor :enterprise_web_token\n\n    # S3 Access key for alambic\n    attr_accessor :s3_alambic_access_key\n\n    # S3 Secret key for alambic\n    attr_accessor :s3_alambic_secret_key\n\n    # Sets the URL for accessing Alambic.\n    # TODO(storage): deprecated by alambic cluster\n    attr_accessor :alambic_url\n\n    # Sets the URL for purging CDN keys.\n    attr_accessor :alambic_cdn_url\n\n    # Sets the API token for purging CDN data through Alambic.\n    attr_accessor :alambic_cdn_token\n\n    # Sets the URL prefix for uploading assets to the \"assets\" Alambic service.\n    # TODO(storage): deprecated by alambic cluster\n    attr_accessor :alambic_uploads_url\n\n    # Sets the URL for accessing the LFS server.\n    attr_accessor :lfs_server_url\n\n    # Sets the HMAC key used to verify request bodies sent to the Internal API.\n    attr_accessor :internal_api_hmac_key\n\n    # Sets the ?v param on avatar urls.  Changing this will force break all\n    # avatar server and browser caches.\n    attr_accessor :alambic_avatar_version\n\n    # Sets the ?v param on avatar urls for a portion of URLS\n    attr_accessor :alambic_next_avatar_version\n\n    # Sets the ?b param on avatar urls.  Changing this will force break all\n    # browser caches.\n    attr_accessor :alambic_browser_avatar_version\n\n    # Sets the ?b param on avatar urls for a portion of URLS\n    attr_accessor :alambic_next_browser_avatar_version\n\n    # Sets the % chance that the next avatar version is used\n    attr_accessor :alambic_next_avatar_chance\n\n    # Sets the string user login\n    attr_accessor :alambic_fallback_user\n\n    # Sets whether gravatars are being uploaded to alambic.\n    # Currently only works with Enterprise.\n    attr_accessor :alambic_avatar_upgrading\n\n    # Sets the URL path to purge (using GitHub.alambic_cdn_url as the host)\n    attr_writer :alambic_cdn_purge_path\n\n    # Sets the number of seconds to delay an avatar purge.\n    attr_accessor :alambic_cdn_delay\n\n    # Sets the default path prefix for alambic content.  See the defaults set\n    # in the different runtime environments (test, dev, prod, enterprise).\n    # TODO(storage): deprecated by alambic cluster\n    attr_accessor :alambic_path_prefix\n\n    # Sets whether to force the Media::Blob prefix or use the default one.\n    # Defaults to false in production, and true everywhere else.\n    # TODO(storage): deprecated by alambic cluster\n    attr_accessor :alambic_use_media_prefix\n\n    # Sets the API token for replicating assest through Alambic\n    attr_accessor :alambic_replication_token\n\n    # Sets a shared token with github/render for creating RenderBlobs in GHE.\n    attr_accessor :render_blob_storage_token\n\n    # Sets a shared token with github/lfs-server for internal api actions\n    attr_accessor :lfs_server_token\n\n    attr_accessor :git_lfs_enabled\n\n    def alambic_cdn_purge_path\n      @alambic_cdn_purge_path ||= \"purge\"\n    end\n\n    # Gets the CSP host to grant access to Alambic services.\n    def alambic_csp_host\n      url_origin(alambic_uploads_url)\n    end\n\n    # Sets the URL prefix for downloading assets from the \"assets\" Alambic\n    # service.\n    #\n    # TODO(storage): deprecated by alambic cluster\n    #\n    # ex: https://alambic-origin.github.com/assets\n    attr_accessor :alambic_assets_url\n\n    # Sets the URL prefix for uploading and downloading objects through the\n    # \"storage\" Alambic service.\n    attr_accessor :storage_cluster_url\n\n    # Get the storage cluster host for CSP purposes.\n    def storage_cluster_host\n      url_origin(storage_cluster_url)\n    end\n\n    # Sets the URL prefix for downloading objects through the \"storage\"\n    # Alambic service. If nil, fall back to #storage_cluster_url. GHE with\n    # Private mode should set this to a route that verifies private mode through\n    # cookies, instead of the API.\n    attr_accessor :storage_private_mode_url\n\n    # Sets the URL format for the root url for Alambic to replicate objects.\n    # Should yield a full URL.\n    #\n    # ex: \"http://%s:8080/storage/replicate\"\n    #\n    #   GitHub.storage_replicate_fmt % \"ghe-alambic-fe1\"\n    #   # => http://ghe-alambic-fe1:8080/storage/replicate\n    attr_accessor :storage_replicate_fmt\n\n    # Sets the path for the EnterpriseStorageClusterUpgrade transition.\n    attr_accessor :storage_transition_path\n\n    # Gets the number of readonly replicas that are included in a storage upload,\n    # but not required for a successful cluster consensus.\n    attr_accessor :storage_non_voting_replica_count\n\n    attr_writer :storage_cluster_enabled\n    attr_writer :storage_replica_count\n    attr_writer :storage_auto_localhost_replica\n    attr_writer :storage_legacy_path\n\n    def storage_cluster_enabled?\n      @storage_cluster_enabled\n    end\n\n    def storage_replica_count\n      @storage_replica_count ||= 1\n    end\n\n    def storage_auto_localhost_replica?\n      if @storage_auto_localhost_replica.nil?\n        @storage_auto_localhost_replica = !Rails.production?\n      end\n      @storage_auto_localhost_replica\n    end\n\n    def storage_legacy_path\n      @storage_legacy_path ||= File.join(Rails.root, \"tmp/objects\")\n    end\n\n    # Sets the URL prefix for the Avatar proxy\n    #\n    # ex: https://avatars.github.com\n    attr_writer :alambic_avatar_url\n\n    def alambic_assets_host\n      url_origin(alambic_assets_url)\n    end\n\n    # Gets just the scheme + host + port of a URL for the CSP policy.\n    def url_origin(url)\n      origin = Addressable::URI.parse(url).origin if url\n      origin == \"null\" ? nil : origin\n    end\n\n    # The base URL for all Alambic avatars. If passed a string, it will\n    # determine which subdomain to use.\n    #\n    # string - An optional String that will be hashed to determine which avatar\n    #          subdomain should be used (0, 1, 2, or 3).\n    #\n    # Returns a full avatar url\n    def alambic_avatar_url(string = nil)\n      return @alambic_avatar_url % nil unless string\n      string_s = string.to_s\n      n = Zlib.crc32(string_s) % 4\n      @alambic_avatar_url % n\n    end\n\n    # Get all possible Alambic avatar URLs.\n    #\n    # Returns a Array of available Alambic avatar URLs. Returns an empty Array\n    # if Alambic avatars are disabled.\n    def alambic_avatar_urls\n      (0..3).map { |n| url_origin(@alambic_avatar_url % n) }.uniq\n    end\n\n    def avatar_version(key = nil)\n      nxt = alambic_next_avatar_version\n      return alambic_avatar_version if !(nxt && next_avatar_version?(key))\n      nxt\n    end\n\n    def browser_avatar_version(key = nil)\n      nxt = alambic_next_browser_avatar_version\n      return alambic_browser_avatar_version if !(nxt && next_avatar_version?(key))\n      nxt\n    end\n\n    def next_avatar_version?(key = nil)\n      chance = alambic_next_avatar_chance.to_i\n      return false unless chance > 0\n\n      if key\n        Zlib.crc32(key) % 100 < chance\n      else\n        rand(100) < chance\n      end\n    end\n\n    # Prefetch DNS entries for our asset domains.\n    #\n    # https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-DNS-Prefetch-Control\n    #\n    #     <link rel=\"dns-prefetch\" href=\"//assets-cdn.github.com\">\n    #\n    # Returns an Array of String host names to prefetch.\n    def dns_prefetch_hosts\n      @dns_prefetch_hosts ||= [\n        asset_host_url,\n        *alambic_avatar_urls,\n        s3_asset_bucket_host,\n        user_images_cdn_url\n      ].select(&:present?).freeze\n    end\n\n    # Public - disable NetGraph generation\n    # The network graph generation makes the Enterprise VM unusable.\n    # Using this flag we can disable the building for each push.\n    #\n    # Return true if the graph can be built.\n    def network_graph_building_enabled?\n      !enterprise?\n    end\n\n    # Whether any uploads are accepted.\n    #\n    # Returns true if enabled, false otherwise.\n    def uploads_enabled?\n      storage_cluster_enabled? || s3_uploads_enabled?\n    end\n\n    # Upload assets to S3, so that they may be served by Amazon and not us.\n    # Disabled by default under FI environments, enabled everwhere else.\n    #\n    # Returns true if enabled, false otherwise.\n    def s3_uploads_enabled?\n      return @s3_uploads_enabled unless @s3_uploads_enabled.nil?\n      @s3_uploads_enabled = s3_uploads_enabled!\n    end\n    attr_writer :s3_uploads_enabled\n\n    def s3_uploads_enabled!\n      !enterprise? && online?\n    end\n\n    def asset_url_host\n      @asset_url_host ||= s3_asset_host\n    end\n    attr_writer :asset_url_host\n\n    def s3_asset_host\n      @s3_asset_host ||= begin\n        if s3_environment_config[:asset_host_name]\n          \"https://#{s3_environment_config[:asset_host_name]}/\"\n        else\n          \"#{s3_asset_bucket_host}/\"\n        end\n      end\n    end\n    attr_writer :s3_asset_host\n\n    def s3_asset_bucket_host\n      @s3_asset_bucket_host ||= \"https://#{s3_environment_config[:asset_bucket_name]}.s3.amazonaws.com\"\n    end\n\n    def file_asset_host\n      @file_asset_host ||= \"/\"\n    end\n    attr_writer :file_asset_host\n\n    # Sets the local file system path to store uploaded files.\n    #\n    # Returns a String path.\n    def file_asset_path\n      @file_asset_path ||= if Rails.test?\n        (Rails.root + \"test/fixtures/assets#{test_environment_number}\").to_s\n      elsif enterprise? && Rails.production?\n        \"/data/assets\"\n      else\n        (Rails.root + \"public\").to_s\n      end\n    end\n    attr_writer :file_asset_path\n\n    # Sets the local file system path to store storage files.\n    # This is only used in enterprise.\n    #\n    # Returns a String path\n    def storage_data_path\n      @storage_data_path ||= if enterprise?\n        \"/data/user/storage\"\n      else\n        file_asset_path\n      end\n    end\n    attr_writer :storage_data_path\n\n    # Uri base path to the external assets.\n    #\n    # Returns a String path\n    def asset_base_path\n      return @asset_base_path if defined?(@asset_base_path)\n      @asset_base_path = \"assets\"\n    end\n    attr_writer :asset_base_path\n\n    # Uri base path to the external task logs.\n    #\n    # Returns a String path\n    def task_log_base_path\n      return @task_log_base_path if defined?(@task_log_base_path)\n      @task_log_base_path = \"task-logs\"\n    end\n    attr_writer :task_log_base_path\n\n    # Uri base path to the external releases.\n    #\n    # Returns a String path\n    def release_asset_base_path\n      return @release_asset_base_path if defined?(@release_asset_base_path)\n      @release_asset_base_path = \"releases\"\n    end\n    attr_writer :release_asset_base_path\n\n    # Uri base path to marketplace listing assets.\n    #\n    # Returns a String path\n    def marketplace_listing_asset_base_path\n      if defined? @marketplace_listing_asset_base_path\n        return @marketplace_listing_asset_base_path\n      end\n      @marketplace_listing_asset_base_path = \"marketplace_listings\"\n    end\n    attr_writer :marketplace_listing_asset_base_path\n\n    # Uri base path to the external showcase assets\n    #\n    # Returns a String path\n    def showcase_asset_base_path\n      return @showcase_asset_base_path if defined?(@showcase_asset_base_path)\n      @showcase_asset_base_path = \"showcases\"\n    end\n    attr_writer :showcase_asset_base_path\n\n    # Configuration attributes to use github.com as SSO for GitHub Enterprise.\n    attr_accessor :github_oauth_client_id\n    attr_accessor :github_oauth_secret_key\n    attr_accessor :github_oauth_organization\n    attr_accessor :github_oauth_team\n\n    # Rotate among a few numbers for international recipients.\n    def sms_numbers\n      @sms_numbers ||= {\n        :twilio => [\n          \"4152339579\",\n          \"4152339591\",\n          \"4152339592\",\n          \"4152339559\",\n          \"4152339562\",\n          \"4152339556\",\n          \"4152339119\",\n          \"4152339144\",\n          \"4152339117\",\n          \"4152339138\",\n          \"4152339155\",\n          \"4152339104\",\n          \"4154888210\",\n          \"4154888243\",\n          \"4154888269\",\n          \"4154888273\",\n          \"4154888272\",\n          \"4154888317\",\n          \"4154888313\",\n          \"4154888399\",\n          \"4154888349\",\n          \"4154888318\"\n        ],\n        :nexmo => [\n          \"github\"\n        ],\n        :test => [\n          \"1231231234\",\n          \"2342342345\",\n          \"3453453456\"\n        ],\n        :local => [\n          \"1010101010\"\n        ]\n      }\n    end\n    attr_writer :sms_numbers\n\n    def sms_short_code\n      @sms_short_code ||= 448482\n    end\n    attr_writer :sms_short_code\n\n    # Twilio API information\n    attr_accessor :twilio_sid\n    attr_accessor :twilio_token\n\n    # Nexmo API information\n    attr_accessor :nexmo_api_key\n    attr_accessor :nexmo_api_secret\n\n    # Determine whether site_admin scope is required for API resources that make\n    # use of the site_admin scope. (This scope is used by API resources that are\n    # only accessible to site admins).\n    #\n    # site_admin scope is NOT required by default in Enterprise environments. It\n    # is required by default everywhere else.\n    #\n    # Returns a Boolean.\n    def require_site_admin_scope\n      return @require_site_admin_scope if defined?(@require_site_admin_scope)\n      @require_site_admin_scope = (!!ENV[\"REQUIRE_SITE_ADMIN_SCOPE\"] || !enterprise?)\n    end\n    attr_writer :require_site_admin_scope\n    alias :require_site_admin_scope? :require_site_admin_scope\n\n    attr_writer :stafftools_sessions_enabled\n    def stafftools_sessions_enabled?\n      return @stafftools_sessions_enabled if defined?(@stafftools_sessions_enabled)\n      @stafftools_sessions_enabled = !enterprise?\n    end\n\n    attr_writer :hookshot_enabled\n    def hookshot_enabled?\n      @hookshot_enabled ||= !enterprise?\n    end\n\n    attr_writer :hook_limit\n    def hook_limit\n      @hook_limit ||= enterprise? ? 250 : 20\n    end\n\n    attr_writer :downloads_enabled\n    def downloads_enabled?\n      @downloads_enabled ||= !enterprise?\n    end\n\n    attr_writer :mirror_replicants\n    def mirror_replicants?\n      @mirror_replicants ||= Rails.development?\n    end\n\n    # Are repositories stored in name-with-owner order on disk?\n    attr_writer :nwo_repo_storage\n    def nwo_repo_storage?\n      enterprise?\n    end\n\n    def trusted_oauth_apps_org_name\n      if GitHub.enterprise? && !Rails.test?\n        \"github-enterprise\"\n      else\n        \"github\"\n      end\n    end\n\n    # Find the trusted Organization.  This Organization is expected to exist already.\n    #\n    # Returns an Organization or nil\n    def trusted_oauth_apps_owner\n      # Use Organization.unscoped to avoid inheriting any temporary scopes.\n      # For example, in the following code:\n      #\n      #     current_user.organizations.oauth_app_policy_met_by(current_app)\n      #\n      # Organization.find_by_login(\"github\") runs this query:\n      #\n      #     SELECT `users`.*\n      #       FROM `users`\n      #       WHERE `users`.`type` IN ('Organization') AND\n      #             `users`.`id` IN (<current_user.id>) AND\n      #             `users`.`login` = 'github'\n      #       LIMIT 1\n      #\n      # and Organization.unscoped.find_by_login runs this query:\n      #\n      #    SELECT `users`.*\n      #      FROM `users`\n      #      WHERE `users`.`type` IN ('Organization') AND\n      #            `users`.`login` = 'github'\n      #      LIMIT 1\n      Organization.unscoped.find_by_login(trusted_oauth_apps_org_name)\n    end\n\n    def two_factor_auth_enabled?\n      return @two_factor_auth_enabled if defined?(@two_factor_auth_enabled)\n      @two_factor_auth_enabled = true\n    end\n    attr_writer :two_factor_auth_enabled\n\n    # Allow TOTPs to be reused within the window for which they are valid?\n    #\n    # Returns boolean.\n    def two_factor_allow_reuse?\n      true\n    end\n\n    def traffic_graphs_enabled?\n      @traffic_graphs_enabled ||= !enterprise?\n    end\n    attr_writer :traffic_graphs_enabled\n\n    # Whether to use and show git preview features or not.\n    # For instance bitmaps.\n    #\n    # Returns false for enterprise.\n    def git_preview_features?\n      !enterprise?\n    end\n\n    # Whether a (non admin) user can create organizations on the install\n    # The user handling bits are in model_settings_dependency.\n    #\n    # Returns true for .com, uses setting if it exists.\n    def user_can_create_organizations?\n      !GitHub.enterprise? || GitHub.org_creation_enabled?\n    end\n\n    # Whether Enterprise only API functionality should be enabled\n    def enterprise_only_api_enabled?\n      GitHub.enterprise?\n    end\n\n    # Whether or not you can disable git ssh access controls\n    def can_disable_git_ssh_access?\n      GitHub.enterprise?\n    end\n\n    def git_repld_enabled?\n      return @git_repld_enabled if defined? @git_repld_enabled\n      @git_repld_enabled = false\n    end\n    attr_writer :git_repld_enabled\n\n    # Whether organization invitations can be bypassed.\n    #\n    # This feature is enabled on Enterprise in order to\n    # allow Owners to add employees directly to their Organizations.\n    def bypass_org_invites_enabled?\n      GitHub.enterprise?\n    end\n\n    # The organization invitation rate limit for new organizations (less than\n    # a month old).\n    def org_invite_rate_limit_untrusted\n      @org_invite_rate_limit_untrusted ||= (ENV[\"ORG_INVITE_RATE_LIMIT_UNTRUSTED\"] || 50).to_i\n    end\n\n    # The organization invitation rate limit for organizations older than the\n    # required age minimum.\n    def org_invite_rate_limit_trusted\n      @org_invite_rate_limit_trusted ||= (ENV[\"ORG_INVITE_RATE_LIMIT_TRUSTED\"] || 500).to_i\n    end\n\n    # The organization invitation rate limit for organizations on paying plans.\n    def org_invite_rate_limit_paying\n      @org_invite_rate_limit_paying ||= (ENV[\"ORG_INVITE_RATE_LIMIT_PAYING\"] || 500).to_i\n    end\n\n    def repository_invitation_rate_limit\n      @repository_invitation_rate_limit ||= (ENV[\"REPOSITORY_INVITATION_RATE_LIMIT\"] || 50).to_i\n    end\n\n    # Are user invitations enabled in this environment?\n    #\n    # User invitations are currently only enabled on Enterprise, when using\n    # non-external authentication.\n    def user_invites_enabled?\n      GitHub.enterprise? && !GitHub.auth.external?\n    end\n\n    # Devtools don't currently exist in Enterprise\n    def devtools_enabled?\n      @devtools_enabled = !enterprise?\n    end\n    attr_writer :devtools_enabled\n\n    # If graphite is disabled, `GitHub.stats` is configured with a client that\n    # is a no-op for every operation.\n    def graphite_disabled?\n      return true if Rails.test?\n      ENV[\"GRAPHITE_DISABLED\"] == \"1\"\n    end\n\n    # The list of stats hosts to connect to.\n    # Configured in `environments/*.rb`\n    attr_accessor :stats_hosts\n\n    # A whitelist of allowed stats keys. Only applied if this is set, otherwise\n    # no whitelisting occurs.\n    attr_accessor :stats_whitelist\n\n    def production_stats_hosts\n      [\"metrics-collector-a-cp1-prd.iad.github.net.:8226\",\n       \"metrics-collector-b-cp1-prd.iad.github.net.:8226\",\n       \"metrics-collector-c-cp1-prd.iad.github.net.:8226\"]\n    end\n\n    # Is datadog metric reporting enabled or not. dogstats is configured with a\n    # client that noops all calls if this is not true.\n    def datadog_enabled?\n      return @datadog_enabled if defined?(@datadog_enabled)\n      @datadog_enabled = true\n    end\n    attr_accessor :datadog_enabled\n\n    # String URL of the semiotic service (golang webserver that shells out to semantic).\n    def semiotic_url\n      @semiotic_url ||= ENV.fetch(\"SEMIOTIC_URL\", \"http://127.0.0.1:8001\")\n    end\n    attr_writer :semiotic_url\n\n    # String shared token with github/semiotic for all api actions\n    def semiotic_token\n      @semiotic_token ||= ENV.fetch(\"SEMIOTIC_TOKEN\", \"octocat\")\n    end\n    attr_writer :semiotic_token\n\n    # ======================================================================== #\n    #                         END OF CONFIG OPTIONS                            #\n    # ======================================================================== #\n\n    ##\n    # Utilities\n\n    # The environment configuration. In dotcom production, this is backed by the\n    # gpanel `.app-config/production.plain` file directly rather than using ENV,\n    # and supports per-datacenter prefixes.\n    # In all other cases it's simply a wrapper for ENV.\n    def environment\n      return @environment if @environment\n      plain_gpanel_config = \"#{Rails.root}/.app-config/#{Rails.env}.plain\"\n      if Rails.production? && !enterprise? && File.file?(plain_gpanel_config)\n        @environment = Config::DatacenterPrefixEnvironment.new \\\n          environment: Config::GpanelConfig.new(File.read(plain_gpanel_config))\n      else\n        @environment = Config::DatacenterPrefixEnvironment.new # just wrap ENV\n      end\n    end\n    attr_writer :environment\n\n    # Reload the config.yml values and set each config attribute.\n    def reload_config\n      import_yaml_config \"#{Rails.root}/config.yml\"\n    end\n\n    # Load config written to disk by heaven gPanel support\n    def reload_gpanel_config\n      gpanel_config = \"#{Rails.root}/.app-config/#{Rails.env}.rb\"\n      if File.file? gpanel_config\n        load gpanel_config\n        @environment = nil\n      end\n    end\n\n    # Reset all memoized configuration variables to an undefined state, causing\n    # them to be re-established the next time their accessed. This also calls\n    # #reload_config to load in config values from the global and environment\n    # config.yml files.\n    def reset_config!\n      instance_variables.each { |varname| remove_instance_variable(varname) }\n      # reset ldap so we can reload the config.\n      load_environment_config\n    end\n\n    # Loads the environment specific config file. The RAILS_ROOT/config.yml\n    # values are loaded twice: before the environment config so that global\n    # config is initially available for the environment file, and after the\n    # environment config so that global values override environment values.\n    def load_environment_config\n      if defined? Rails.env\n        reload_config\n\n        reload_gpanel_config\n\n        # Enterprise doesn't ship production.rb environment file to avoid exposing\n        # sensitive credentials.\n        load \"github/config/environments/#{Rails.env}.rb\" unless Rails.production? && enterprise?\n        load \"github/config/environments/enterprise.rb\" if enterprise?\n\n        # load the config.yml values in over the environment specific config.\n        reload_config\n      else\n        raise LoadError, \"Rails.env is not set\"\n      end\n    end\n\n    # Imports config values from the YAML file specified into the current\n    # config. The config file may include values for any attributes defined in\n    # this module.\n    #\n    # file - The string path to the YAML file to load.\n    #\n    # Returns nothing.\n    # Raises RuntimeError when the config file includes an unknown key.\n    #\n    # Examples:\n    #   The following YAML file would cause the ssl config attribute to be set\n    #   true and the host_name attribute to be set to \"github.apple.com\":\n    #\n    #   ssl:       true\n    #   host_name: github.apple.com\n    def import_yaml_config(file)\n      load_yaml_config(file).each do |key, value|\n        if respond_to?(\"#{key}=\")\n          __send__(\"#{key}=\", value)\n        else\n          fail \"unknown config value: #{key.inspect}\"\n        end\n      end\n    end\n\n    # Load a YAML file if it exists and return its deserialized contents.\n    #\n    # Returns a Hash of config values.\n    def load_yaml_config(file)\n      if !Rails.test? && File.exist?(file)\n        require \"yaml\"\n        YAML.load_file(file)\n      else\n        {}\n      end\n    end\n\n    # Public: Determine whether the limit in mentioned users in\n    # comments/issues/pull request... is enabled or no.\n    #\n    # Enterprise is the most common case where we want to disable the spam\n    # validation because the number of users are determined by the license.\n    def prevent_mention_spam?\n      !enterprise?\n    end\n\n    # Revoke OAuth accesses and SSH keys for new staff?\n    def new_staff_precautions?\n      !enterprise?\n    end\n\n    # We only want to enforce employee requirements when this is *not*\n    # Enterprise.\n    def require_employee_for_site_admin?\n      !GitHub.enterprise?\n    end\n\n    def require_two_factor_for_site_admin?\n      return @require_two_factor_for_site_admin if defined? @require_two_factor_for_site_admin\n      @require_two_factor_for_site_admin = !GitHub.enterprise? && !Rails.development? && !Rails.test?\n    end\n    attr_writer :require_two_factor_for_site_admin\n\n    # No 2FA SMS in enterprise\n    def two_factor_sms_enabled?\n      !enterprise?\n    end\n\n    # Disable Mirror repos on Enterprise\n    def mirrors_enabled?\n      !enterprise?\n    end\n\n    # Enable unlimited git.maxobjectsize in Enterprise\n    def unlimited_max_object_size_enabled?\n      enterprise?\n    end\n\n    def cluster_web_server?\n      return @cluster_web_server if defined? @cluster_web_server\n      @cluster_web_server = false\n    end\n    attr_writer :cluster_web_server\n\n    def cluster_git_server?\n      return @cluster_git_server if defined? @cluster_git_server\n      @cluster_git_server = false\n    end\n    attr_writer :cluster_git_server\n\n    def cluster_pages_server?\n      return @cluster_pages_server if defined? @cluster_pages_server\n      @cluster_pages_server = false\n    end\n    attr_writer :cluster_pages_server\n\n    # IP addresses that service hooks are sent from.\n    #\n    # This is returned from the API endpoint\n    # and listed on the service hooks page.\n    def hook_ips\n      [\n        \"192.30.252.0/22\",\n        \"185.199.108.0/22\"\n      ]\n    end\n\n    # IP addresses that users connect to for git operations\n    def git_ips\n      [\n        \"192.30.252.0/22\",\n        \"185.199.108.0/22\"\n      ]\n    end\n\n    # IP addresses for GitHub Pages' A records.\n    def a_record_ips\n      [\n        \"192.30.252.153/32\",\n        \"192.30.252.154/32\"\n      ]\n    end\n\n    # IP addresses that the importer connects from.\n    def porter_worker_ips\n      [\n        \"54.87.5.173\",     # porter-worker13-ue1-prd.aws.github.net\n        \"54.166.52.62\",    # porter-worker14-ue1-prd.aws.github.net\n        \"23.20.92.3\",      # porter-worker15-ue1-prd.aws.github.net\n      ]\n    end\n\n    attr_accessor :spamurai_key\n\n    def spamurai_url\n      \"https://spamurai:#{spamurai_key}@spamurai.breadsticks.kube-service.github.net\"\n    end\n\n    # are we running on the primary node of a fileserver pair?\n    def on_primary_file_server?\n      File.directory?(PRIMARY_FS_TEST_DIR) || local_host_name_short =~ /^github-dfs/\n    end\n\n    # Public: Is Backscatter enabled?\n    #\n    # In enterprise, returns false\n    # In production, checks the configured datacenter\n    # Otherwise returns true\n    def backscatter_enabled?\n      if GitHub.enterprise?\n        false\n      elsif Rails.production?\n        backscatter_datacenter.to_s.downcase == GitHub.datacenter\n      else\n        true\n      end\n    end\n\n    # Public: What datacenter is backscatter enabled for?\n    #\n    # Until such time as backscatter's back-end storage system (currently\n    # transient redis) changed to handle multiple datacenters, only run\n    # backscatter in the primary datacenter, configured via BACKSCATTER_DATACENTER.\n    def backscatter_datacenter\n      GitHub.environment[\"BACKSCATTER_DATACENTER\"]\n    end\n\n    # Public: Is scientist enabled?\n    #\n    # In enterprise, returns false\n    # In production, checks the configured datacenter\n    # Otherwise returns true\n    def scientist_enabled?\n      if GitHub.enterprise?\n        false\n      elsif Rails.production?\n        scientist_datacenter.to_s.downcase == GitHub.datacenter\n      else\n        true\n      end\n    end\n\n    # Public: What datacenter is scientist enabled for?\n    #\n    # Until such time as scientist's back-end storage system (currently\n    # transient redis) changed to handle multiple datacenters, only run\n    # scientist in the primary datacenter, configured via SCIENTIST_DATACENTER.\n    def scientist_datacenter\n      GitHub.environment[\"SCIENTIST_DATACENTER\"]\n    end\n\n    # Public: Is performance profiling enabled?\n    attr_accessor :profiling_enabled\n    alias profiling_enabled? profiling_enabled\n\n    # Public: Is the performance stats UI enabled?\n    attr_accessor :stats_ui_enabled\n    alias stats_ui_enabled? stats_ui_enabled\n\n    # Public: which repository networks do we never want to be considered public?\n    #\n    # This allows us to provide an extra level of protection to make sure GitHub's\n    # most sensitive repositories aren't accidentally turned public.  So, even\n    # if visibility is toggled on these, they will always be treated as private\n    # repositories.\n    def never_public_networks\n      return [].freeze if GitHub.enterprise?\n\n      [\"github/github\", \"github/puppet\"].freeze\n    end\n\n   # Public: the ids of the repository networks we never want to be considered public\n   def never_public_network_ids\n     return @never_public_network_ids if defined? @never_public_network_ids\n\n     networks = GitHub.never_public_networks\n     ids = networks.map { |nwo| Repository.nwo(nwo).try(:network_id) }\n     @never_public_network_ids = ids.compact.uniq.freeze\n   end\n\n   def reset_never_public_network_ids\n     remove_instance_variable \"@never_public_network_ids\" if defined? @never_public_network_ids\n   end\n\n    # Accounts or people that work for GitHub that we don't want\n    # to publicly display as staff or be present on the team page.\n    def hidden_teamsters\n      @hidden_teamsters ||= %w(evilshawn ghmonitor gregose-tmp hubot ice799 maki1022 mayashino monitors StreamingEagle boxen-ci btoews)\n    end\n\n    def hidden_teamster?(user)\n      hidden_teamsters.include?(user.login)\n    end\n\n    # Public: feature flag for DetectCredentialsInPush.\n    def credential_detection_enabled?\n      !GitHub.enterprise?\n    end\n\n    def max_ui_pagination_page\n      MAX_UI_PAGINATION_PAGE\n    end\n\n    # We're using the Shopify/verdict gem for storing associations for A/B tests (and other\n    # science experiments on users that have test/control groups). The storage for experiments\n    # is pluggable in verdict; currently, we'll write to MySQL tables behind the scenes.\n    def user_experiment_storage\n      @user_experiment_storage ||= GitHub::UserResearch::ExperimentDatabaseStorage.new\n    end\n\n    def user_experiments_enabled?\n      return @user_experiments_enabled if defined?(@user_experiments_enabled)\n      @user_experiments_enabled = true\n    end\n    attr_writer :user_experiments_enabled\n\n    def content_creation_rate_limiting_enabled?\n      return @content_creation_rate_limiting_enabled if defined?(@content_creation_rate_limiting_enabled)\n      @content_creation_rate_limiting_enabled = !GitHub.enterprise?\n    end\n    attr_writer :content_creation_rate_limiting_enabled\n\n    # Request parameters to filter from logs and exceptions\n    #\n    # These are filtered by Rails based on a substring match\n    def filtered_params\n      [:password, :token, :credit_card, :value, :oauth_verifier, :bt_signature]\n    end\n\n    def merge_matrix_pull_request\n      if ENV[\"MERGE_BUTTON_MATRIX_PULL_REQUEST_ID\"]\n        pull = PullRequest.find(ENV[\"MERGE_BUTTON_MATRIX_PULL_REQUEST_ID\"])\n      elsif Rails.env.development?\n        repo = Repository.find_by_name_with_owner(\"github/linguist\")\n        pull = repo.pull_requests.last\n      end\n    end\n\n    def rails_3_2?\n      rails_version_major == 3 && rails_version_minor == 2\n    end\n\n    def rails_4?\n      rails_version_major == 4 && rails_version_minor == 0\n    end\n    alias_method :rails_4_0?, :rails_4?\n\n    def rails_4_1?\n      rails_version_major == 4 && rails_version_minor == 1\n    end\n\n    def rails_4_2?\n      rails_version_major == 4 && rails_version_minor == 2\n    end\n\n    def rails_5?\n      rails_version_major == 5 && rails_version_minor == 0\n    end\n    alias_method :rails_5_0?, :rails_5?\n\n    def rails_version_major\n      Rails::VERSION::MAJOR\n    end\n    private :rails_version_major\n\n    def rails_version_minor\n      Rails::VERSION::MINOR\n    end\n    private :rails_version_minor\n\n    def origin_verification_enabled?\n      !enterprise?\n    end\n\n    # When SameSite cookie support is first deployed, any initial request that\n    # does CSRF validation will fail, since the strict SameSite cookie will not\n    # be set yet. This isn't a problem for dotcom, as we currently hide this\n    # feature behind a feature flag. So, we will have several weeks to allow all\n    # users to start receiving both the normal session cookie AND the new strict\n    # SameSite cookie. As a result, we can be confident everyone already has\n    # both cookies when we ship the feature. But, on Enterprise, this isn't the\n    # case. So, for now, we will disable support. Maybe we can enable it after a\n    # few releases and/or if we warn people when they upgrade.\n    def same_site_cookie_verification_enabled?\n      !enterprise? && same_site_cookie_enabled?\n    end\n\n    # Even if we are not validating SameSite cookies (i.e.\n    # `same_site_cookie_verification_enabled?` is `false`), we can still set the\n    # cookie for future use. However, since we are using cookie prefixes with\n    # our SameSite cookie implementation, we choose to only set the SameSite\n    # cookie for installations that have SSL enabled.\n    def same_site_cookie_enabled?\n      ssl?\n    end\n\n    def flipper_ui_enabled?\n      return @flipper_ui_enabled if defined?(@flipper_ui_enabled)\n      @flipper_ui_enabled = true\n    end\n    attr_writer :flipper_ui_enabled\n\n    def request_tracing_enabled?\n      return @request_tracing_enabled if defined?(@request_tracing_enabled)\n      @request_tracing_enabled = true\n    end\n    attr_writer :request_tracing_enabled\n\n    def request_limiting_enabled?\n      @request_limiting_enabled\n    end\n    attr_writer :request_limiting_enabled\n\n    def chatterbox_enabled?\n      return @chatterbox_enabled if defined?(@chatterbox_enabled)\n      @chatterbox_enabled = true\n    end\n    attr_writer :chatterbox_enabled\n\n    # Use small_primes to get a list of small primes that can be used for basic\n    # RSA modulus validation.\n    def small_primes\n      @small_primes ||= Prime.first(10000).freeze\n    end\n\n    def allow_cross_origin_referrer_leak?\n      !enterprise?\n    end\n\n    def read_only?\n      return true if Thread.current[:github_read_only_mode]\n      return @read_only if defined?(@read_only)\n\n      @read_only = File.exist?(Rails.root.join(\"tmp/readonly.txt\"))\n    end\n    attr_writer :read_only\n\n    def resque_redis_disabled?\n      @resque_redis_disabled ||= GitHub.environment[\"#{GitHub.role.upcase}_RESQUE_REDIS_DISABLED\"] == \"1\"\n    end\n\n    def reset_resque_redis_disabled\n      @resque_redis_disabled = nil\n    end\n\n    def websocket_redis_disabled?\n      @websocket_redis_disabled ||= GitHub.environment[\"#{GitHub.role.upcase}_WEBSOCKET_REDIS_DISABLED\"] == \"1\"\n    end\n\n    def reset_websocket_redis_disabled\n      @websocket_redis_disabled = nil\n    end\n\n    def mysql_primary_disabled?\n      @mysql_primary_disabled ||= GitHub.environment[\"#{GitHub.role.upcase}_MYSQL_PRIMARY_DISABLED\"] == \"1\"\n    end\n\n    def reset_mysql_primary_disabled\n      @mysql_primary_disabled = nil\n    end\n\n    # Given a github host, attempt to determine the site. Originally added to\n    # allow for tagging the rpc_site on all MySQL queries to aid in determining\n    # cross-site queries.\n    #\n    # Examples:\n    #\n    #   GitHub.site_from_host(\"db-mysql-9082342.cp1-iad.github.net\") => \"cp1-iad\"\n    #   GitHub.site_from_host(\"db-mysql-c0c881d.sdc42-sea.github.net\") => \"sdc42-sea\"\n    #\n    # Returns String representing the site of the host.\n    def site_from_host(host)\n      site = if host =~ /cp1-prd\\.iad\\.github\\.net/\n        \"cp1-iad\"\n      else\n        match = /(?<site>[^\\.]+)\\.github\\.net\\Z/i.match(host)\n        match && match[:site]\n      end\n\n      site && SITE_WHITELIST.include?(site) ? site : \"unknown\"\n    end\n\n    def areas_of_responsibility\n      @areas_of_responsibility ||= begin\n        yaml_path = Rails.root.join(\"docs\", \"areas-of-responsibility.yaml\")\n        YAML.load_file(yaml_path).freeze\n      end\n    end\n\n    # Is operator mode enabled for all users?\n    #\n    # When operator mode is enabled, debugging output is displayed to the\n    # client during Git push operations.\n    def global_operator_mode_enabled?\n      !!@global_operator_mode_enabled\n    end\n    attr_writer :global_operator_mode_enabled\n\n    # Is the local version of ssh-keygen old enough to use MD5 fingerprints\n    # by default?\n    def old_ssh_keygen?\n      @old_ssh_keygen\n    end\n    attr_writer :old_ssh_keygen\n\n    # Ops gets paged if there's < 10 GB available\n    SHARD_SLACK_SPACE = 15.0 * (1 << 30)\n\n    ENTERPRISE_SHARD_SLACK_SPACE = 2 * (1 << 30)\n\n    # The amount of slack disk space required\n    # on fileservers, in KB.\n    def shard_slack_space\n      gb = if GitHub.enterprise?\n        ENTERPRISE_SHARD_SLACK_SPACE\n      else\n        SHARD_SLACK_SPACE\n      end\n\n      gb / (1 << 10)\n    end\n\n    # What port should we use in the upstream for proxies when pointing mysql\n    # in the app at toxiproxy. Checks for env var, then falls back to mysql's\n    # default port.\n    #\n    # NOTE: This is only used for develompment, test and ci to simulate network\n    # issues by proxying through toxiproxy.\n    def toxiproxy_upstream_mysql_port\n      @toxiproxy_upstream_mysql_port ||= ENV.fetch(\"TOXIPROXY_UPSTREAM_MYSQL_PORT\", 3306)\n    end\n    attr_writer :toxiproxy_upstream_mysql_port\n\n    def cas_host\n      url_origin(cas_url)\n    end\n\n    # Header image for Google Inbox repository bundles.\n    #\n    # See: https://github.com/github/workflow/issues/402\n    def google_inbox_header_image\n      \"https://cloud.githubusercontent.com/assets/143418/17495839/a5054eac-5d88-11e6-95fc-7290892c7bb5.png\"\n    end\n\n    # Avatar image for Google Inbox repository bundles used to identify\n    # GitHub-specific bundes.\n    #\n    # See: https://github.com/github/workflow/issues/402\n    def google_inbox_avatar_image\n      \"https://cloud.githubusercontent.com/assets/143418/15842166/7c72db34-2c0b-11e6-9aed-b52498112777.png\"\n    end\n\n    # Allow overriding the number of accesses an OAuth application is allowed to\n    # create for a given app/user/scope combination.\n    def oauth_access_limit_overrides_enabled?\n      Rails.production? && !enterprise?\n    end\n\n    # Whether or not this server will primarily run gitauth requests\n    def gitauth_host?\n      !!ENV[\"GITAUTH\"]\n    end\n\n    # The number of unicorn workers to run on an enterprise instance.\n    def enterprise_unicorn_worker_count\n      if gitauth_host?\n        (ENV[\"ENTERPRISE_GITAUTH_WORKERS\"] || 1).to_i\n      else\n        (ENV[\"ENTERPRISE_GITHUB_WORKERS\"] || 4).to_i\n      end\n    end\n\n    # This host is a staff host\n    def staff_host?\n      ENV[\"STAFF_ENVIRONMENT\"] != nil || local_host_name.split(\".\").first =~ /^github-staff\\d+/\n    end\n\n    # This host is an arch host\n    def arch_host?\n      local_host_name =~ /^github-arch/\n    end\n\n    # This host is a babeld host\n    def babeld_host?\n      local_host_name =~ /^github-babel/\n    end\n\n    # The parsed contents of /etc/github/metadata.json (a Hash), or nil\n    def server_metadata\n      return @_parsed_metadata_json if defined?(@_parsed_metadata_json)\n      begin\n        @_parsed_metadata_json = read_metadata\n      rescue\n        @_parsed_metadata_json = {}\n      end\n    end\n\n    # The region where the server is located\n    def server_region\n      server_metadata[\"region\"]\n    end\n\n    # This host is running in production\n    def production_host?\n      server_metadata[\"env\"] == \"production\"\n    end\n\n    # The number of unicorn workers to spin up for this server.\n    def unicorn_worker_count\n      if (worker_count = ENV[\"GH_UNICORN_WORKER_COUNT\"])\n        return worker_count.to_i\n      end\n\n      worker_count = begin\n        Integer(File.read(\"/etc/github/unicorn_worker_count\"))\n      rescue Errno::ENOENT, Errno::EPERM, ArgumentError\n        nil\n      end\n      unless worker_count.nil?\n        return worker_count\n      end\n\n      if GitHub.enterprise? && Rails.production?\n        return enterprise_unicorn_worker_count\n      end\n\n      if staff_host?\n        return 3\n      end\n\n      if gitauth_host?\n        return 1 unless Rails.production?\n        return (3 * Etc.nprocessors) if babeld_host?\n        return 12 if production_host?\n        return 2\n      end\n\n      if Rails.production?\n        return (2 * Etc.nprocessors) if production_host?\n        return 4\n      end\n      2\n    end\n\n    # Should unicorn do its check_client_connection thing?\n    #   https://engineering.shopify.com/17489012-what-does-your-webserver-do-when-a-user-hits-refresh#axzz2q3YWu2Jr\n    def unicorn_check_client_connection?\n      Rails.development? || Rails.test? || arch_host?\n    end\n\n    def dependency_graph_enabled?\n      !GitHub.enterprise? && (GitHub.dependency_graph_api_url.present? ||\n                              Rails.development?)\n    end\n\n    def dependency_graph_api_url\n      ENV[\"DEPENDENCY_GRAPH_API_URL\"] || @dependency_graph_api_url\n    end\n    attr_writer :dependency_graph_api_url\n\n    # Munger is an application that provides access to data from the data\n    # science pipeline: https://github.com/github/munger\n    # It is used for things like getting topic suggestions in the GitHub.com\n    # environment and doesn't run on Enterprise.\n    def munger_available?\n      !enterprise?\n    end\n\n    # The topics data API is supplied by the github/munger application\n    attr_accessor :munger_url\n\n    # Whether to log the call stack when auto_fqdn is called\n    attr_accessor :log_auto_fqdn_caller\n\n    # Whether or not this is a Kubernetes cluster. To determine this, we look\n    # for a file created by the ServiceAccountAdmissionController.\n    # https://kubernetes.io/docs/admin/service-accounts-admin/#service-account-admission-controller\n    def kube?\n      return @kube if defined?(@kube)\n      namespace_file = \"/var/run/secrets/kubernetes.io/serviceaccount/namespace\"\n      @kube = File.file?(namespace_file)\n    end\n\n    def kubernetes_cluster_name\n      read_metadata[\"kubernetes_cluster_name\"]\n    end\n\n    # Whether or not the requests are to a host that has been enabled\n    # specifically for api read-only traffic\n    def api_read_only?\n      GitHub.resque_redis_disabled? &&\n        GitHub.websocket_redis_disabled? &&\n        GitHub.mysql_primary_disabled? &&\n        GitHub.elasticsearch_access_raises?\n    end\n\n    def platform_graphql_service_tokens=(tokens)\n      @platform_graphql_service_tokens = tokens.split(\",\")\n    end\n\n    def platform_graphql_service_tokens\n      @platform_graphql_service_tokens ||= []\n    end\n\n    def platform_graphql_logging_enabled?\n      @platform_graphql_logging_enabled || !GitHub.enterprise?\n    end\n    attr_writer :platform_graphql_logging_enabled\n\n    def valid_graphql_service_token?(token)\n      valid_token = false\n      GitHub.platform_graphql_service_tokens.each do |t|\n        if SecurityUtils.secure_compare(t, token)\n          valid_token = true\n        end\n      end\n      valid_token\n    end\n\n    def mysql_read_only_connection?\n      Thread.current[:mysql_read_only_connection] == true\n    end\n\n    def mysql_read_only_connection=(value)\n      Thread.current[:mysql_read_only_connection] = value\n    end\n\n    def mysql_switched_from_read_to_write_connection?\n      Thread.current[:mysql_switched_from_read_to_write_connection] == true\n    end\n\n    def mysql_switched_from_read_to_write_connection=(value)\n      Thread.current[:mysql_switched_from_read_to_write_connection] = value\n    end\n\n    def nsq_enabled?\n      @nsq_enabled ||= ENV.fetch(\"NSQ_ENABLED\", \"0\") == \"1\"\n    end\n    attr_writer :nsq_enabled\n\n    def nsqlookupd_urls\n      @nsqlookupd_urls ||= ENV.fetch(\"NSQLOOKUPD_URLS\", \"127.0.0.1:4161\").split(\",\")\n    end\n    attr_writer :nsqlookupd_urls\n\n    def nsqd_url\n      @nsqd_url ||= ENV.fetch(\"NSQD_URL\", \"127.0.0.1:4150\")\n    end\n    attr_writer :nsqd_url\n  end\nend\n\n# bring in otherwise untouched modules\nrequire \"github/config/gpanel_config\"\nrequire \"github/config/datacenter\"\nrequire \"github/config/datacenter_prefix_environment\"\nrequire \"github/config/fastly\"\nrequire \"github/config/importers\"\nrequire \"github/config/legacy_textile_formatting\"\nrequire \"github/config/migration\"\nrequire \"github/config/render\"\nrequire \"github/config/spokes\"\nrequire \"github/config/support_link\"\nrequire \"github/config/logging\"\nrequire \"github/config/request_limits\"\nrequire \"github/config/rate_limits\"\nrequire \"github/config/tracer\"\n","language":"Ruby"}},{"after":{"path":"lib/github/diff.rb","content":"# frozen_string_literal: true\n\nrequire \"digest\"\nrequire \"scientist\"\nrequire \"set\"\n\nmodule GitHub\n  # Git diff reading library that supports size-sensitive condensed diffs.\n  #\n  # GitHub::Diff provides an interface to diffs. diffstat information is\n  # available for all files but full unified diff text is retrieved only for\n  # files meeting the max_file, max_diff_size, and max_total_size limits.\n  #\n  # Use GitHub::Diff to generate a commit diff:\n  #   repo = Repository.name_with_owner('rtomayko/git-sh')\n  #   GitHub::Diff.new(repo, 'd2adbee...')\n  #\n  # Or a range diff between two commits:\n  #   GitHub::Diff.new(repo, 'd3adb3e...', 'd3cafba...')\n  #\n  # diffstat information is available for the diff as a whole:\n  #   diff = GitHub::Diff.new(repo, 'deadbee')\n  #   p diff.summary.additions     # => 100\n  #   p diff.summary.deletions     # => 101\n  #   p diff.summary.changes       # => 201\n  #   p diff.summary.changed_files # => 7\n  #\n  # You can also iterate over the files with stat and diff information:\n  #   diffs = GitHub::Diff.new(repo, 'd3adb3e', 'd3cadba...')\n  #   diffs.each do |entry|\n  #     p entry.path       # => 'path/to/file.rb'\n  #     p entry.status     # => 'M', 'A', 'D', 'C', 'R', or 'T'\n  #     p entry.additions  # => 23\n  #     p entry.deletions  # => 7\n  #     p entry.changes    # => 30\n  #     p entry.text       # => <unified diff text> or nil end\n  class Diff\n    include Enumerable\n    extend Forwardable\n    include Scientist\n\n    # Default values for diff loading limits\n    DEFAULT_MAX_FILES       = 300\n    DEFAULT_MAX_TOTAL_LINES = 20_000\n    DEFAULT_MAX_TOTAL_SIZE  = 1 * 1024 * 1024  # 1M\n    DEFAULT_MAX_DIFF_LINES  = 3_000\n    DEFAULT_MAX_DIFF_SIZE   = 100 * 1024 # 100K\n\n    # Assumed average size of a single diff line\n    AVERAGE_LINE_SIZE = 40 # bytes\n\n    # Top-only limits allow ~80% of all diffs GitHub renders on Dotcom\n    # to be loaded without truncation. We use them for the initial\n    # request of progressive diffs. See #apply_top_only_limits!\n    TOP_ONLY_MAX_TOTAL_LINES = 400\n    TOP_ONLY_MAX_TOTAL_SIZE  = 20 * 1024 # 20K (~ 50 bytes per line)\n    TOP_ONLY_TIMEOUT         = 1 # second\n\n    CONDENSED_DIFF_TIMEOUT_SECS   = 8\n\n    # Auto-load limits are applied in a progressive diff batch request.\n    #\n    # The lower per-file limits avoid wasting processing time on large\n    # diff entries that are of low value to the user.\n    # See #apply_auto_load_single_entry_limits!\n    #\n    # The total limits apply across all batches a single diff can be\n    # split up into. These total limits are never actually applied to\n    # `condensed_diff` call, they are used to determine if additional\n    # requests are necessary or not. See Diff::BatchedFileListView\n    AUTO_LOAD_MAX_DIFF_LINES  = 400\n    AUTO_LOAD_MAX_TOTAL_BYTES = TOP_ONLY_MAX_TOTAL_SIZE * 10\n    AUTO_LOAD_MAX_TOTAL_LINES = TOP_ONLY_MAX_TOTAL_LINES * 10\n\n    autoload :Entry,                \"github/diff/entry\"\n    autoload :Enumerator,           \"github/diff/enumerator\"\n    autoload :Generator,            \"github/diff/generator\"\n    autoload :Line,                 \"github/diff/line\"\n    autoload :Parser,               \"github/diff/parser\"\n    autoload :RelatedLinesEnumerator, \"github/diff/related_lines_enumerator\"\n    autoload :SplitLinesEnumerator, \"github/diff/split_lines_enumerator\"\n\n    AlreadyLoaded = Class.new(StandardError)\n\n    def self.max_diff_lines\n      @max_diff_lines\n    end\n\n    def self.max_diff_lines=(val)\n      @max_diff_lines = val\n    end\n    self.max_diff_lines = DEFAULT_MAX_DIFF_LINES\n\n    def self.max_total_lines\n      @max_total_lines\n    end\n\n    def self.max_total_lines=(val)\n      @max_total_lines = val\n    end\n    self.max_total_lines = DEFAULT_MAX_TOTAL_LINES\n\n    def self.default_timeout\n      custom_default_timeout || CONDENSED_DIFF_TIMEOUT_SECS\n    end\n\n    def self.custom_default_timeout\n      @custom_default_timeout\n    end\n\n    def self.custom_default_timeout=(val)\n      @custom_default_timeout = val\n    end\n\n    # The Repository instance used to make git calls.\n    attr_reader :repo\n\n    # The SHA1 commit ids of the two versions to compare.\n    attr_reader :sha2\n\n    attr_accessor :base_sha\n\n    # Maximum size of any one file's diff in bytes.\n    # Default: See DEFAULT_MAX_DIFF_SIZE\n    attr_accessor :max_diff_size\n\n    # Maximum size of all diff output in bytes.\n    # Default: See DEFAULT_MAX_TOTAL_SIZE\n    attr_accessor :max_total_size\n\n    # Maximum number of files to include full diff output for.\n    # Default: See DEFAULT_MAX_FILES\n    attr_accessor :max_files\n\n    # Maximum number of lines in a single file's diff.\n    # Default: See DEFAULT_MAX_DIFF_LINES\n    attr_accessor :max_diff_lines\n\n    # Maximum number of total lines in a diff (for all files).\n    # Default: See DEFAULT_MAX_TOTAL_LINES\n    attr_accessor :max_total_lines\n\n    # Boolean indicating mode that sets limits to load only the beginning\n    # of the diff. Default: false\n    attr_accessor :top_only\n\n    # Boolean indicating whether the summary is needed and therefore loaded.\n    # Default: false\n    attr_accessor :use_summary\n\n    # The GitRPC::Client interface used for rpc interactions. Defaults to repo.rpc\n    attr_accessor :rpc\n\n    # Ignore whitespace when comparing lines. This ignores differences even if\n    # one line has whitespace where the other line has none. Enables the -w\n    # argument to git-diff.\n    attr_accessor :ignore_whitespace\n    alias ignore_whitespace? ignore_whitespace\n\n    # The amount of time the fileserver has to generate and read the diff. Any\n    # diff that was read within this amount of time will be returned.\n    attr_writer :timeout\n    def timeout\n      @timeout || self.class.default_timeout\n    end\n\n    # Returns true if the diff had too many files\n    def truncated_for_max_files?\n      !!/^maximum file count exceeded/.match(truncated_reason)\n    end\n\n    # Returns true if the diff had too many lines\n    def truncated_for_max_lines?\n      !!/^maximum number of lines exceeded/.match(truncated_reason)\n    end\n\n    # Returns true if the diff had too many bytes\n    def truncated_for_max_size?\n      !!/^maximum diff size exceeded/.match(truncated_reason)\n    end\n\n    # Returns true if we only have partial diff output due to timeout\n    def truncated_for_timeout?\n      !!/^timeout reached/.match(truncated_reason)\n    end\n\n    # Create a new GitHub::Diff for a single commit or a range of commits.\n    #\n    # repo    - Repository object used to make git calls.\n    # sha1    - 40 char SHA1 identifying the commit to use as the starting point.\n    # sha2    - 40 char SHA1 identifying the commit to use as the ending point.\n    # options - A hash of attribute options. All instance attributes defined\n    #           above may be specified. In addition to the following:\n    #           :paths         - List of paths to scope this diff to.\n    #                            See #paths and #add_path.\n    #           :delta_indexes - List of delta indexes to scope this diff to.\n    #                            See #delta_indexes and #add_delta_index[es].\n    #\n    def initialize(repo, sha1, sha2 = nil, options = {})\n      raise TypeError if !repo.respond_to?(:git_command)\n      options, sha2 = options.merge(sha2), nil if sha2.kind_of?(Hash)\n\n      # default option values\n      @ignore_whitespace = false\n\n      # default diff selection values\n      @max_files       = DEFAULT_MAX_FILES\n      @max_diff_size   = DEFAULT_MAX_DIFF_SIZE\n      @max_total_size  = DEFAULT_MAX_TOTAL_SIZE\n      @max_diff_lines  = self.class.max_diff_lines\n      @max_total_lines = self.class.max_total_lines\n      @truncated       = false\n      @paths           = Set.new(options.delete(:paths)).freeze\n      @delta_indexes   = Set.new(options.delete(:delta_indexes)).freeze\n      @top_only        = options.delete(:top_only) || false\n      @use_summary     = options.delete(:use_summary) || false\n\n      options.each { |k, v| send(\"#{k}=\", v) }\n\n      if sha2\n        @sha1, @sha2 = sha1, sha2\n      else\n        @sha1, @sha2 = \"#{sha1}^\", sha1\n      end\n\n      @repo = repo\n\n      @rpc ||= @repo.rpc\n\n      apply_top_only_limits! if @top_only\n    end\n\n    # public: Instantiate a new diff without any path limitations or entries loaded\n    #\n    # This is useful if you need a duplicated diff but don't want it to be loaded already\n    # so you can modify the paths. Primarily this is used for review comment positioning.\n    def only_params\n      self.class.new(repo, sha1, sha2, {\n        base_sha:          base_sha,\n        ignore_whitespace: ignore_whitespace,\n        max_diff_lines:    max_diff_lines,\n        max_diff_size:     max_diff_size,\n        max_files:         max_files,\n        max_total_lines:   max_total_lines,\n        max_total_size:    max_total_size,\n        top_only:          top_only,\n        use_summary:       use_summary\n      })\n    end\n\n    # Public: Set the per diff limits to be equal to the limits for the entire diff.\n    #\n    # When we are dealing with a single file such as viewing a single diff entry or positioning a\n    # single comment, we only need a single diff entry so the limits grow to the size of the entire\n    # diff.\n    def maximize_single_entry_limits!\n      self.max_diff_size  = DEFAULT_MAX_TOTAL_SIZE\n      self.max_diff_lines = DEFAULT_MAX_TOTAL_LINES\n\n      # Calling this method on a reduced diff (for example top only) can result\n      # in the max total being less than the max for a single entry. This can\n      # result in failure to position comments and makes no sense anyway.\n      self.max_total_lines = max_diff_lines if max_total_lines < max_diff_lines\n      self.max_total_size  = max_diff_size if max_total_size < max_diff_size\n    end\n\n    # Public: Set the total limits to be equal to the per diff limits.\n    #\n    # This is the opposite of #maximize_single_entry_limits!\n    def minimize_total_limits!\n      self.max_total_size  = DEFAULT_MAX_DIFF_SIZE\n      self.max_total_lines = DEFAULT_MAX_DIFF_LINES\n    end\n\n    alias_method :top_only?, :top_only\n    alias_method :use_summary?, :use_summary\n\n    # Total number of files/diffs.\n    def size\n      @corrupt ? 0 : cache(\"size\") { entries.size }\n    end\n\n    def empty?\n      changed_files <= 0\n    end\n    alias_method :blank?, :empty?\n\n    def any?\n      available? && !empty?\n    end\n\n    # Reader for @sha1, normalizes NULL_OIDs\n    def sha1\n      if @sha1 == ::GitRPC::NULL_OID\n        nil\n      else\n        @sha1\n      end\n    end\n\n    # Retrieve and iterate over diff objects for all changed files\n    # in pathname order. Unified diff text may be excluded according to the\n    # rules for selecting diffs.\n    def each(&bk)\n      entries.each(&bk)\n    end\n\n    # Retrieve a diff object by its index position or path name.\n    #\n    # index - A numeric index position or string diff filename to retrieve.\n    #\n    # Returns a ChangedFile for the given index when found, or nil\n    # when no diff exists at that path.\n    #\n    # Raises TypeError when the index argument is invalid.\n    def [](index)\n      case index\n      when Numeric\n        entries[index]\n      when String\n        find_by_path(index)\n      else\n        raise TypeError, \"Numeric or String expected for #{index.inspect}\"\n      end\n    end\n\n    # Public: List of paths to scope this diff to\n    #\n    # Returns Array of Strings\n    def paths\n      @paths.to_a.freeze\n    end\n\n    # Public: Add paths to the diff's set of examined paths if it exists in the ToC.\n    #\n    # paths - Array of paths to add to the diff's paths\n    # side  - the side of the diff on which the path should be present. must be one of:\n    #         :a (left), :b (right), nil (either). Defaults to either.\n    #\n    # Returns nothing\n    def add_paths(new_paths, side: nil)\n      raise ArgumentError, \"Side must be :a, :b, or nil\" unless [:a, :b, nil].include?(side)\n\n      @paths = new_paths.each_with_object(@paths.dup) do |new_path, paths|\n        next if new_path.nil?\n\n        # convert unicode paths to raw so we can match paths from deltas\n        new_path = new_path.b\n\n        next if paths.include?(new_path)\n\n        # we don't already have this path so if the diff is already loaded, it is too late\n        raise AlreadyLoaded if loaded?\n\n        if delta = delta_for_path(new_path, side: side)\n          paths.merge(delta.paths)\n        else\n          paths << new_path\n        end\n      end\n\n      @paths.freeze\n\n      reset_requested_deltas\n    end\n\n    # Public: Add the path to the diff's set of examined paths if it exists in the ToC.\n    #\n    # path - the path to add to the diff's paths\n    # side - the side of the diff on which the path should be present. must be one of:\n    #        :a (left), :b (right), nil (either). Defaults to either.\n    #\n    # Returns nothing\n    def add_path(path, side: nil)\n      add_paths([path], side: side)\n    end\n\n    # Public: Find the GitRPC::Diff::Delta object for the given path\n    #\n    # path - the path for the delta in which you are interested.\n    # side - limit the search to either the :a or :b side of the delta. Defaults to either (nil)\n    #\n    # Returns the delta object or nil if it cannot be found.\n    def delta_for_path(path, side: nil)\n      delta = deltas.detect { |e| e.new_file.path == path } if side.nil? || side == :b\n      return delta unless delta.nil?\n\n      deltas.detect { |e| e.old_file.path == path } if (side == :a || side.nil?)\n    end\n\n    # Public: Array of delta indexes to scope this diff to\n    #\n    # Returns an Array of Integers\n    def delta_indexes\n      @delta_indexes.to_a.freeze\n    end\n\n    # Public: Add list of delta indexes\n    #\n    # indexes - Array of Integers\n    #\n    # Returns nothing\n    def add_delta_indexes(indexes)\n      raise AlreadyLoaded if loaded?\n\n      unless indexes.all? { |index| index.is_a?(Integer) }\n        raise TypeError, \"Some indexes are not Integers\"\n      end\n\n      indexes.reject!(&:negative?)\n      @delta_indexes += Set.new(indexes)\n      @delta_indexes.freeze\n\n      reset_requested_deltas\n    end\n\n    # Public: Add a single delta index\n    #\n    # index - Integer\n    #\n    # Returns nothing\n    def add_delta_index(index)\n      add_delta_indexes([index])\n    end\n\n    # Public: List of deltas that are requested with this diff\n    #\n    # Returns an Array of GitRPC::Diff::Deltas or GitRPC::Diff::Summary::Deltas\n    def requested_deltas\n      return @requested_deltas unless @requested_deltas.nil?\n      return @requested_deltas = deltas.dup if paths.empty? && delta_indexes.empty?\n\n      selected_deltas = []\n\n      # TODO: Once all paths are added via add_path, this step will become unnecessary\n      unless paths.empty?\n        @paths = Set.new(paths.map { |path| path.try(:b) }).freeze\n      end\n\n      unless paths.empty?\n        deltas_from_paths = deltas.select { |e| paths.include?(e.old_file.path) }\n        selected_deltas.concat(deltas_from_paths)\n      end\n\n      unless delta_indexes.empty?\n        deltas_from_indices = deltas.values_at(*delta_indexes).compact\n        selected_deltas.concat(deltas_from_indices)\n      end\n\n      @requested_deltas = selected_deltas.uniq\n    end\n\n    # Internal: Resets the list of requested deltas to ensure they get recomputed\n    #\n    # Returns nothing\n    def reset_requested_deltas\n      @requested_deltas = nil\n    end\n\n    # Public: List of requested paths\n    #\n    # Returns an Array of Strings\n    def requested_paths\n      requested_deltas.flat_map(&:paths).uniq\n    end\n\n    # Public: Lists the paths that have been loaded by this diff. Excludes truncated entries.\n    #\n    # Returns an array of the String paths of entries loaded by the diff. In the case of renames, both paths\n    # are included.\n    def non_truncated_paths\n      return @non_truncated_paths if defined?(@non_truncated_paths)\n\n      return [] if !loaded?\n\n      non_truncated = entries.reject {|e| e.truncated? }\n\n      @non_truncated_paths = non_truncated.flat_map { |e| [e.a_path_raw, e.b_path_raw].compact }.uniq\n    end\n\n    # Locate a diff for a given path name. This first checks for an exact match on\n    # b_path names and then falls back on looking for renamed files.\n    #\n    # path - String full path name to file.\n    #\n    # Returns a ChangedFile object for the diff.\n    def find_by_path(path)\n      entries.each do |entry|\n        if entry.path == path\n          return entry\n        elsif entry.path > path\n          break  # diffs are sorted by path name\n        end\n      end\n      entries.find { |entry| entry.renamed? && entry.a_path == path }\n    end\n\n    # Public: The stats on this diff\n    #\n    # Returns a GitRPC::Diff::Summary\n    def summary\n      return @summary if defined?(@summary)\n\n      update_time_remaining do\n        @summary = rpc.read_diff_summary(parsed_sha1, parsed_sha2, base_sha,\n                                         timeout: time_remaining, algorithm: git_diff_algorithm)\n      end\n    end\n\n    # Internal: Was the diff's summary loaded?\n    #\n    # Returns a Boolean\n    def summary_loaded?\n      defined?(@summary)\n    end\n\n    # Is the summary cached?\n    def summary_warm?\n      rpc.diff_summary_cached?(parsed_sha1, parsed_sha2, base_sha)\n    end\n\n    # Public: Get a semantic table of contents summary.\n    #\n    # allow_edge_languages  - Boolean if edge languages should be summarized\n    #                         (optional, default: false).\n    # use_semiotic_on_kubes - Boolean if the kubes hosted semiotic fes should\n    #                         be used.\n    #\n    # Returns a GitHub::Semiotic::TocSummary, or an unavailable TocSummary on error.\n    def toc_summary(allow_edge_languages: false, use_semiotic_on_kubes: false)\n      return @toc_summary if defined?(@toc_summary)\n\n      url = use_semiotic_on_kubes ? GitHub.semiotic_kubes_url : GitHub.semiotic_url\n      client = GitHub::Semiotic::Client.for(url, repo.rpc, cache: repo.rpc.cache,\n        # Don't leak source code, only log parse errors for public or github owned repos.\n        log_parse_errors: repo.public? || repo.owner == \"github\",\n        allow_edge_languages: allow_edge_languages)\n      paths = deltas.map(&:paths).flatten.uniq\n      @toc_summary = client.read_toc_summary(parsed_sha1, parsed_sha2, paths)\n    end\n\n    # Public: A complete list of all deltas\n    #\n    # Returns an Array of GitRPC::Diff::Deltas or GitRPC::Diff::Summary::Deltas\n    def deltas\n      return @deltas if defined?(@deltas)\n\n      @deltas = if summary_loaded? || use_summary?\n                  summary.deltas\n                else\n                  load_deltas\n                end\n    end\n\n    # Internal: Loads the diffs deltas\n    #\n    # Returns an Array of GitRPC::Diff::Deltas\n    def load_deltas\n      update_time_remaining do\n        rpc.native_read_diff_toc(parsed_sha1, parsed_sha2, base_sha,\n                                 \"timeout\" => time_remaining)\n      end\n    end\n\n    def_delegators :summary, :changes, :additions, :deletions\n\n    def changed_files\n      if summary_loaded? || use_summary?\n        summary.changed_files\n      else\n        deltas.size\n      end\n    end\n\n    def too_big?\n      changed_files > max_files\n    end\n\n    # Have the diff's entries been loaded? If not, some operations could result in a costly gitrpc call\n    def loaded?\n      !!defined?(@entries_hash)\n    end\n\n    def total_line_count\n      entries.map(&:line_count).sum\n    end\n\n    def total_byte_count\n      entries.map(&:byte_count).sum\n    end\n\n    def truncated?\n      self.truncated\n    end\n\n    def truncated\n      entries_hash[\"truncated\"]\n    end\n\n    def truncated_reason\n      entries_hash[\"truncated_reason\"]\n    end\n\n    def entries_cached?\n      cached?(\"entries_hash\")\n    end\n\n    def entries\n      entries_hash[\"entries\"]\n    end\n\n    alias to_a entries\n\n    def entries_hash\n      return @entries_hash if defined? @entries_hash\n\n      @entries_hash = load_entries_hash\n    end\n\n    def entries_hash_cache_key\n      cache_prefix(:toc_entries_hash)\n    end\n\n    def load_entries_hash\n      start_time = Time.now\n      cached = true\n\n      entries_hash = GitHub.cache.fetch(entries_hash_cache_key, :stats_key => \"diff.cache.toc_entries_hash\") do\n        cached = false\n        load_entries_hash!\n      end\n\n      duration_ms = (Time.now - start_time) * 1000\n      GitHub.dogstats.timing \"diff.load\", duration_ms, tags: %W(cached:#{cached})\n\n      entries_hash\n    end\n\n    # Internal: Retrieves the diff patches (entries) using diff-pairs\n    # by passing in the requested deltas.\n    #\n    # Returns Hash\n    def load_entries_hash!\n      truncated_deltas = requested_deltas[0, max_files]\n\n      indexed_deltas = {}\n      truncated_deltas.each do |delta|\n        # TODO: Key generation for entries and deltas should be extracted into a single method\n        key = [delta.old_file.path, delta.status, delta.new_file.path].join(\":\")\n\n        indexed_deltas[key] = delta\n      end\n\n      result = if truncated_deltas.empty?\n        { \"data\" => \"\" }\n      else\n        entries_timeout = if top_only?\n          [TOP_ONLY_TIMEOUT, time_remaining].min\n        else\n          time_remaining\n        end\n\n        update_time_remaining do\n          load_diff_pairs(truncated_deltas, entries_timeout)\n        end\n      end\n\n      text_entries = {}\n\n      parser = Parser.new(result[\"data\"])\n      parser.each do |entry|\n        # TODO: Key generation for entries and deltas should be extracted into a single method\n        key = [entry.a_path_raw || entry.b_path_raw, entry.status, entry.b_path_raw || entry.a_path_raw].join(\":\")\n\n        # TODO: Long-term refactoring => Pass delta to entry and\n        # delegate all data accessors to the delta. This way we could\n        # drop this if-clause.\n        if entry.renamed? && entry.b_blob.nil?\n          entry.b_blob = indexed_deltas[key].new_file.oid\n        end\n\n        entry.whitespace_ignored = ignore_whitespace\n        entry.a_sha = parsed_sha1\n        entry.b_sha = parsed_sha2\n\n        text_entries[key] = entry\n      end\n\n      truncated_for_max_files = requested_deltas.size > max_files\n\n      truncated = parser.truncated || truncated_for_max_files\n      truncated_reason = parser.truncated_reason\n      truncated_reason ||= \"timeout reached.\" if result[\"timed_out\"]\n\n      fresh_entries = []\n      deltas_to_process = indexed_deltas.dup\n\n      # Fill in entries with text and whitespace-only changes\n      while deltas_to_process.any?\n        key, delta = deltas_to_process.shift\n\n        if text_entries.has_key?(key)\n          fresh_entries << text_entries.delete(key)\n          break if text_entries.empty?\n        else\n          # Create diff entry for files with whitespace-only changes\n          fresh_entries << GitHub::Diff::Entry.from(:diff => self, :delta => delta).tap do |entry|\n            entry.a_sha = self.parsed_sha1\n            entry.b_sha = self.parsed_sha2\n            entry.whitespace_ignored = self.ignore_whitespace\n          end\n        end\n      end\n\n      # Fill in entries without text\n      while deltas_to_process.any?\n        key, delta = deltas_to_process.shift\n\n        fresh_entries << GitHub::Diff::Entry.from(:diff => self, :delta => delta).tap do |entry|\n          entry.a_sha = self.parsed_sha1\n          entry.b_sha = self.parsed_sha2\n          entry.whitespace_ignored = self.ignore_whitespace\n\n          # These entries are marked truncated since they were not part\n          # of the entries returned by diff-pairs.\n          entry.truncated_reason = truncated_reason\n        end\n      end\n\n      fresh_entries.sort_by!(&:path)\n\n      if truncated_for_max_files && !result[\"timed_out\"]\n        truncated_reason = \"maximum file count exceeded: total=#{requested_deltas.size}\"\n      end\n\n      {\n        \"entries\" => fresh_entries,\n        \"truncated\" => truncated,\n        \"truncated_reason\" => truncated_reason\n      }\n    end\n\n    def parsed_sha1\n      return @parsed_sha1 if defined?(@parsed_sha1)\n      @parsed_sha1 = sha1 ? rpc.rev_parse(sha1) : nil\n    end\n\n    def parsed_sha2\n      return @parsed_sha2 if defined?(@parsed_sha2)\n      @parsed_sha2 = sha2 ? rpc.rev_parse(sha2) : nil\n    end\n\n    def time_remaining\n      return @time_remaining if defined?(@time_remaining)\n      @time_remaining = self.timeout || self.class.timeout\n    end\n\n    def update_time_remaining(&block)\n      start = Time.now\n      block.call\n    ensure\n      elapsed = Time.now - start\n\n      @time_remaining = time_remaining - elapsed\n      @time_remaining = 0 if time_remaining < 0\n    end\n\n    # Git diff compatible algorithm\n    def git_diff_algorithm\n      if ignore_whitespace\n        \"ignore-whitespace\"\n      else\n        \"vanilla\"\n      end\n    end\n\n    def load_diff_pairs(truncated_deltas, entries_timeout)\n      options = {\n        \"max_diff_size\" => @max_diff_size,\n        \"max_total_size\" => @max_total_size,\n        \"max_diff_lines\" => @max_diff_lines,\n        \"max_total_lines\" => @max_total_lines,\n        \"ignore_whitespace\" => ignore_whitespace,\n        \"max_files\" => @max_files,\n        \"timeout\" => entries_timeout\n      }\n\n      rpc.read_diff_pairs_with_base(\n        parsed_sha1, parsed_sha2, base_sha,\n        truncated_deltas, options\n      )\n    end\n\n    def load_diff(timeout: self.class.default_timeout)\n      new_timeout = [self.timeout, timeout].compact.min\n      self.timeout = new_timeout\n\n      available?\n    end\n\n    # Is the diff available?\n    #\n    # It's possible for the diff to be unavailable due to:\n    #   * \"corrupt\"         - Something unexpected happened. Possibly a corrupt repository.\n    #   * \"missing commits\" - The base or head commit don't exist in this repository. This can happen\n    #                         if a commit is looked up through the wrong repository in a public network,\n    #                         but the lookup succeeds because the commit was in the shared commit cache.\n    #   * \"timeout\"         - The diff took too long to generate\n    #   * \"too busy\"        - The fileserver is under heavy load and the condense-diff\n    #                         process was killed by gitmon\n    #\n    # The entries array will be empty when unavailable.\n    #\n    # Returns false if the diff is available, or the reason that the diff is not available otherwise.\n    def unavailable_reason\n      return @unavailable_reason if defined?(@unavailable_reason)\n      cache_key = cache_prefix(\"unavailable_reason\")\n\n      if @unavailable_reason = GitHub.cache.get(cache_key)\n        @entries_hash = {\n          \"entries\" => [],\n          \"truncated\" => false,\n          \"truncated_reason\" => nil\n        }\n      elsif @unavailable_reason = unavailable_reason!\n        GitHub.cache.set(cache_key, @unavailable_reason, 5.minutes.to_i) unless [\"too busy\", \"missing commits\"].include?(@unavailable_reason)\n        @entries_hash = {\n          \"entries\" => [],\n          \"truncated\" => false,\n          \"truncated_reason\" => nil\n        }\n      end\n\n      @unavailable_reason\n    end\n\n    # Internal: Perform the actual availability check without memoization or caching.\n    #\n    # Returns an error message if the diff is corrupt or times out, false otherwise.\n    def unavailable_reason!\n      return \"corrupt\" if [sha1, sha2].include?(GitHub::NULL_OID)\n      return false if defined?(@entries_hash)\n\n      if use_summary?\n        return summary.unavailable_reason unless summary.available?\n      end\n\n      entries\n\n      false\n    rescue ::GitRPC::Timeout\n      \"timeout\"\n    rescue GitRPC::CommandBusy\n      \"too busy\"\n    rescue GitRPC::ObjectMissing\n      \"missing commits\"\n    rescue GitRPC::InvalidRepository\n      \"corrupt\"\n    rescue GitHub::Diff::Parser::UnrecognizedText, GitRPC::Error => e\n      Failbot.report(e)\n      \"corrupt\"\n    end\n\n    def available?\n      unavailable_reason == false\n    end\n\n    def timed_out?\n      unavailable_reason == \"timeout\"\n    end\n\n    def too_busy?\n      unavailable_reason == \"too busy\"\n    end\n\n    def corrupt?\n      unavailable_reason == \"corrupt\"\n    end\n\n    def missing_commits?\n      unavailable_reason == \"missing commits\"\n    end\n\n    ##\n    # Internals\n\n    def apply_top_only_limits!\n      self.max_total_lines = TOP_ONLY_MAX_TOTAL_LINES\n      self.max_total_size  = TOP_ONLY_MAX_TOTAL_SIZE\n    end\n\n    # Internal: Apply the auto-load limits for a single diff entry.\n    #\n    # Depending on the number of changed files, we adjust the max diff entry\n    # limits proportionally within the limits of DEFAULT_MAX_DIFF_LINES and\n    # AUTO_LOAD_MAX_DIFF_LINES.\n    #\n    # Notice: This might trigger the diff summary to load, see #changed_files.\n    #\n    # Returns nothing\n    def apply_auto_load_single_entry_limits!\n      lines = if empty?\n                AUTO_LOAD_MAX_DIFF_LINES\n              else\n                custom_max_diff_lines = DEFAULT_MAX_DIFF_LINES / changed_files\n                [custom_max_diff_lines, AUTO_LOAD_MAX_DIFF_LINES].max\n              end\n      size = lines * AVERAGE_LINE_SIZE\n\n      # FIXME: on top_only requests we want the diff to be truncated so that we\n      # attempt a follow up request with bigger limits. Potentially having a\n      # max_diff_size that is greater than max_total_size will allow for this.\n      # On batch requests this doesn't make sense, we just want the diff to\n      # always be skipped.\n      # This is an ugly solution, all limits should be dynamic and additional\n      # requests should not be made. Please fix this.\n      unless top_only?\n        lines = [lines, self.max_total_lines].min\n        size = [size, self.max_total_size].min\n      end\n\n      self.max_diff_lines = lines\n      self.max_diff_size  = size\n    end\n\n    def cached?(key)\n      GitHub.cache.exist?(cache_prefix(key))\n    end\n\n    def cache(key, &block)\n      if (value = instance_variable_get(\"@#{key}\")).nil?\n        value = GitHub.cache.fetch(cache_prefix(key), :stats_key => \"diff.cache.#{key}\") { yield }\n        instance_variable_set(\"@#{key}\", value)\n      end\n      value\n    end\n\n    def cache_prefix(key)\n      @prefix ||= begin\n        paths_key = Digest::MD5.hexdigest(paths.join(\":\")) if paths.any?\n        delta_indexes_key = Digest::MD5.hexdigest(delta_indexes.join(\":\")) if delta_indexes.any?\n\n        [\n          \"GitHub::Diff\", \"v14\", sha1, sha2, base_sha,\n          git_diff_algorithm,\n          paths_key, delta_indexes_key,\n          max_diff_lines, max_total_lines,\n          \"prog_output\"\n        ].compact.join(\":\")\n      end\n\n      \"#{@prefix}:#{key}\"\n    end\n  end\nend\n","language":"Ruby"},"before":{"path":"lib/github/diff.rb","content":"# frozen_string_literal: true\n\nrequire \"digest\"\nrequire \"scientist\"\nrequire \"set\"\n\nmodule GitHub\n  # Git diff reading library that supports size-sensitive condensed diffs.\n  #\n  # GitHub::Diff provides an interface to diffs. diffstat information is\n  # available for all files but full unified diff text is retrieved only for\n  # files meeting the max_file, max_diff_size, and max_total_size limits.\n  #\n  # Use GitHub::Diff to generate a commit diff:\n  #   repo = Repository.name_with_owner('rtomayko/git-sh')\n  #   GitHub::Diff.new(repo, 'd2adbee...')\n  #\n  # Or a range diff between two commits:\n  #   GitHub::Diff.new(repo, 'd3adb3e...', 'd3cafba...')\n  #\n  # diffstat information is available for the diff as a whole:\n  #   diff = GitHub::Diff.new(repo, 'deadbee')\n  #   p diff.summary.additions     # => 100\n  #   p diff.summary.deletions     # => 101\n  #   p diff.summary.changes       # => 201\n  #   p diff.summary.changed_files # => 7\n  #\n  # You can also iterate over the files with stat and diff information:\n  #   diffs = GitHub::Diff.new(repo, 'd3adb3e', 'd3cadba...')\n  #   diffs.each do |entry|\n  #     p entry.path       # => 'path/to/file.rb'\n  #     p entry.status     # => 'M', 'A', 'D', 'C', 'R', or 'T'\n  #     p entry.additions  # => 23\n  #     p entry.deletions  # => 7\n  #     p entry.changes    # => 30\n  #     p entry.text       # => <unified diff text> or nil end\n  class Diff\n    include Enumerable\n    extend Forwardable\n    include Scientist\n\n    # Default values for diff loading limits\n    DEFAULT_MAX_FILES       = 300\n    DEFAULT_MAX_TOTAL_LINES = 20_000\n    DEFAULT_MAX_TOTAL_SIZE  = 1 * 1024 * 1024  # 1M\n    DEFAULT_MAX_DIFF_LINES  = 3_000\n    DEFAULT_MAX_DIFF_SIZE   = 100 * 1024 # 100K\n\n    # Assumed average size of a single diff line\n    AVERAGE_LINE_SIZE = 40 # bytes\n\n    # Top-only limits allow ~80% of all diffs GitHub renders on Dotcom\n    # to be loaded without truncation. We use them for the initial\n    # request of progressive diffs. See #apply_top_only_limits!\n    TOP_ONLY_MAX_TOTAL_LINES = 400\n    TOP_ONLY_MAX_TOTAL_SIZE  = 20 * 1024 # 20K (~ 50 bytes per line)\n    TOP_ONLY_TIMEOUT         = 1 # second\n\n    CONDENSED_DIFF_TIMEOUT_SECS   = 8\n\n    # Auto-load limits are applied in a progressive diff batch request.\n    #\n    # The lower per-file limits avoid wasting processing time on large\n    # diff entries that are of low value to the user.\n    # See #apply_auto_load_single_entry_limits!\n    #\n    # The total limits apply across all batches a single diff can be\n    # split up into. These total limits are never actually applied to\n    # `condensed_diff` call, they are used to determine if additional\n    # requests are necessary or not. See Diff::BatchedFileListView\n    AUTO_LOAD_MAX_DIFF_LINES  = 400\n    AUTO_LOAD_MAX_TOTAL_BYTES = TOP_ONLY_MAX_TOTAL_SIZE * 10\n    AUTO_LOAD_MAX_TOTAL_LINES = TOP_ONLY_MAX_TOTAL_LINES * 10\n\n    autoload :Entry,                \"github/diff/entry\"\n    autoload :Enumerator,           \"github/diff/enumerator\"\n    autoload :Generator,            \"github/diff/generator\"\n    autoload :Line,                 \"github/diff/line\"\n    autoload :Parser,               \"github/diff/parser\"\n    autoload :RelatedLinesEnumerator, \"github/diff/related_lines_enumerator\"\n    autoload :SplitLinesEnumerator, \"github/diff/split_lines_enumerator\"\n\n    AlreadyLoaded = Class.new(StandardError)\n\n    def self.max_diff_lines\n      @max_diff_lines\n    end\n\n    def self.max_diff_lines=(val)\n      @max_diff_lines = val\n    end\n    self.max_diff_lines = DEFAULT_MAX_DIFF_LINES\n\n    def self.max_total_lines\n      @max_total_lines\n    end\n\n    def self.max_total_lines=(val)\n      @max_total_lines = val\n    end\n    self.max_total_lines = DEFAULT_MAX_TOTAL_LINES\n\n    def self.default_timeout\n      custom_default_timeout || CONDENSED_DIFF_TIMEOUT_SECS\n    end\n\n    def self.custom_default_timeout\n      @custom_default_timeout\n    end\n\n    def self.custom_default_timeout=(val)\n      @custom_default_timeout = val\n    end\n\n    # The Repository instance used to make git calls.\n    attr_reader :repo\n\n    # The SHA1 commit ids of the two versions to compare.\n    attr_reader :sha2\n\n    attr_accessor :base_sha\n\n    # Maximum size of any one file's diff in bytes.\n    # Default: See DEFAULT_MAX_DIFF_SIZE\n    attr_accessor :max_diff_size\n\n    # Maximum size of all diff output in bytes.\n    # Default: See DEFAULT_MAX_TOTAL_SIZE\n    attr_accessor :max_total_size\n\n    # Maximum number of files to include full diff output for.\n    # Default: See DEFAULT_MAX_FILES\n    attr_accessor :max_files\n\n    # Maximum number of lines in a single file's diff.\n    # Default: See DEFAULT_MAX_DIFF_LINES\n    attr_accessor :max_diff_lines\n\n    # Maximum number of total lines in a diff (for all files).\n    # Default: See DEFAULT_MAX_TOTAL_LINES\n    attr_accessor :max_total_lines\n\n    # Boolean indicating mode that sets limits to load only the beginning\n    # of the diff. Default: false\n    attr_accessor :top_only\n\n    # Boolean indicating whether the summary is needed and therefore loaded.\n    # Default: false\n    attr_accessor :use_summary\n\n    # The GitRPC::Client interface used for rpc interactions. Defaults to repo.rpc\n    attr_accessor :rpc\n\n    # Ignore whitespace when comparing lines. This ignores differences even if\n    # one line has whitespace where the other line has none. Enables the -w\n    # argument to git-diff.\n    attr_accessor :ignore_whitespace\n    alias ignore_whitespace? ignore_whitespace\n\n    # The amount of time the fileserver has to generate and read the diff. Any\n    # diff that was read within this amount of time will be returned.\n    attr_writer :timeout\n    def timeout\n      @timeout || self.class.default_timeout\n    end\n\n    # Returns true if the diff had too many files\n    def truncated_for_max_files?\n      !!/^maximum file count exceeded/.match(truncated_reason)\n    end\n\n    # Returns true if the diff had too many lines\n    def truncated_for_max_lines?\n      !!/^maximum number of lines exceeded/.match(truncated_reason)\n    end\n\n    # Returns true if the diff had too many bytes\n    def truncated_for_max_size?\n      !!/^maximum diff size exceeded/.match(truncated_reason)\n    end\n\n    # Returns true if we only have partial diff output due to timeout\n    def truncated_for_timeout?\n      !!/^timeout reached/.match(truncated_reason)\n    end\n\n    # Create a new GitHub::Diff for a single commit or a range of commits.\n    #\n    # repo    - Repository object used to make git calls.\n    # sha1    - 40 char SHA1 identifying the commit to use as the starting point.\n    # sha2    - 40 char SHA1 identifying the commit to use as the ending point.\n    # options - A hash of attribute options. All instance attributes defined\n    #           above may be specified. In addition to the following:\n    #           :paths         - List of paths to scope this diff to.\n    #                            See #paths and #add_path.\n    #           :delta_indexes - List of delta indexes to scope this diff to.\n    #                            See #delta_indexes and #add_delta_index[es].\n    #\n    def initialize(repo, sha1, sha2 = nil, options = {})\n      raise TypeError if !repo.respond_to?(:git_command)\n      options, sha2 = options.merge(sha2), nil if sha2.kind_of?(Hash)\n\n      # default option values\n      @ignore_whitespace = false\n\n      # default diff selection values\n      @max_files       = DEFAULT_MAX_FILES\n      @max_diff_size   = DEFAULT_MAX_DIFF_SIZE\n      @max_total_size  = DEFAULT_MAX_TOTAL_SIZE\n      @max_diff_lines  = self.class.max_diff_lines\n      @max_total_lines = self.class.max_total_lines\n      @truncated       = false\n      @paths           = Set.new(options.delete(:paths)).freeze\n      @delta_indexes   = Set.new(options.delete(:delta_indexes)).freeze\n      @top_only        = options.delete(:top_only) || false\n      @use_summary     = options.delete(:use_summary) || false\n\n      options.each { |k, v| send(\"#{k}=\", v) }\n\n      if sha2\n        @sha1, @sha2 = sha1, sha2\n      else\n        @sha1, @sha2 = \"#{sha1}^\", sha1\n      end\n\n      @repo = repo\n\n      @rpc ||= @repo.rpc\n\n      apply_top_only_limits! if @top_only\n    end\n\n    # public: Instantiate a new diff without any path limitations or entries loaded\n    #\n    # This is useful if you need a duplicated diff but don't want it to be loaded already\n    # so you can modify the paths. Primarily this is used for review comment positioning.\n    def only_params\n      self.class.new(repo, sha1, sha2, {\n        base_sha:          base_sha,\n        ignore_whitespace: ignore_whitespace,\n        max_diff_lines:    max_diff_lines,\n        max_diff_size:     max_diff_size,\n        max_files:         max_files,\n        max_total_lines:   max_total_lines,\n        max_total_size:    max_total_size,\n        top_only:          top_only,\n        use_summary:       use_summary\n      })\n    end\n\n    # Public: Set the per diff limits to be equal to the limits for the entire diff.\n    #\n    # When we are dealing with a single file such as viewing a single diff entry or positioning a\n    # single comment, we only need a single diff entry so the limits grow to the size of the entire\n    # diff.\n    def maximize_single_entry_limits!\n      self.max_diff_size  = DEFAULT_MAX_TOTAL_SIZE\n      self.max_diff_lines = DEFAULT_MAX_TOTAL_LINES\n\n      # Calling this method on a reduced diff (for example top only) can result\n      # in the max total being less than the max for a single entry. This can\n      # result in failure to position comments and makes no sense anyway.\n      self.max_total_lines = max_diff_lines if max_total_lines < max_diff_lines\n      self.max_total_size  = max_diff_size if max_total_size < max_diff_size\n    end\n\n    # Public: Set the total limits to be equal to the per diff limits.\n    #\n    # This is the opposite of #maximize_single_entry_limits!\n    def minimize_total_limits!\n      self.max_total_size  = DEFAULT_MAX_DIFF_SIZE\n      self.max_total_lines = DEFAULT_MAX_DIFF_LINES\n    end\n\n    alias_method :top_only?, :top_only\n    alias_method :use_summary?, :use_summary\n\n    # Total number of files/diffs.\n    def size\n      @corrupt ? 0 : cache(\"size\") { entries.size }\n    end\n\n    def empty?\n      changed_files <= 0\n    end\n    alias_method :blank?, :empty?\n\n    def any?\n      available? && !empty?\n    end\n\n    # Reader for @sha1, normalizes NULL_OIDs\n    def sha1\n      if @sha1 == ::GitRPC::NULL_OID\n        nil\n      else\n        @sha1\n      end\n    end\n\n    # Retrieve and iterate over diff objects for all changed files\n    # in pathname order. Unified diff text may be excluded according to the\n    # rules for selecting diffs.\n    def each(&bk)\n      entries.each(&bk)\n    end\n\n    # Retrieve a diff object by its index position or path name.\n    #\n    # index - A numeric index position or string diff filename to retrieve.\n    #\n    # Returns a ChangedFile for the given index when found, or nil\n    # when no diff exists at that path.\n    #\n    # Raises TypeError when the index argument is invalid.\n    def [](index)\n      case index\n      when Numeric\n        entries[index]\n      when String\n        find_by_path(index)\n      else\n        raise TypeError, \"Numeric or String expected for #{index.inspect}\"\n      end\n    end\n\n    # Public: List of paths to scope this diff to\n    #\n    # Returns Array of Strings\n    def paths\n      @paths.to_a.freeze\n    end\n\n    # Public: Add paths to the diff's set of examined paths if it exists in the ToC.\n    #\n    # paths - Array of paths to add to the diff's paths\n    # side  - the side of the diff on which the path should be present. must be one of:\n    #         :a (left), :b (right), nil (either). Defaults to either.\n    #\n    # Returns nothing\n    def add_paths(new_paths, side: nil)\n      raise ArgumentError, \"Side must be :a, :b, or nil\" unless [:a, :b, nil].include?(side)\n\n      @paths = new_paths.each_with_object(@paths.dup) do |new_path, paths|\n        next if new_path.nil?\n\n        # convert unicode paths to raw so we can match paths from deltas\n        new_path = new_path.b\n\n        next if paths.include?(new_path)\n\n        # we don't already have this path so if the diff is already loaded, it is too late\n        raise AlreadyLoaded if loaded?\n\n        if delta = delta_for_path(new_path, side: side)\n          paths.merge(delta.paths)\n        else\n          paths << new_path\n        end\n      end\n\n      @paths.freeze\n\n      reset_requested_deltas\n    end\n\n    # Public: Add the path to the diff's set of examined paths if it exists in the ToC.\n    #\n    # path - the path to add to the diff's paths\n    # side - the side of the diff on which the path should be present. must be one of:\n    #        :a (left), :b (right), nil (either). Defaults to either.\n    #\n    # Returns nothing\n    def add_path(path, side: nil)\n      add_paths([path], side: side)\n    end\n\n    # Public: Find the GitRPC::Diff::Delta object for the given path\n    #\n    # path - the path for the delta in which you are interested.\n    # side - limit the search to either the :a or :b side of the delta. Defaults to either (nil)\n    #\n    # Returns the delta object or nil if it cannot be found.\n    def delta_for_path(path, side: nil)\n      delta = deltas.detect { |e| e.new_file.path == path } if side.nil? || side == :b\n      return delta unless delta.nil?\n\n      deltas.detect { |e| e.old_file.path == path } if (side == :a || side.nil?)\n    end\n\n    # Public: Array of delta indexes to scope this diff to\n    #\n    # Returns an Array of Integers\n    def delta_indexes\n      @delta_indexes.to_a.freeze\n    end\n\n    # Public: Add list of delta indexes\n    #\n    # indexes - Array of Integers\n    #\n    # Returns nothing\n    def add_delta_indexes(indexes)\n      raise AlreadyLoaded if loaded?\n\n      unless indexes.all? { |index| index.is_a?(Integer) }\n        raise TypeError, \"Some indexes are not Integers\"\n      end\n\n      indexes.reject!(&:negative?)\n      @delta_indexes += Set.new(indexes)\n      @delta_indexes.freeze\n\n      reset_requested_deltas\n    end\n\n    # Public: Add a single delta index\n    #\n    # index - Integer\n    #\n    # Returns nothing\n    def add_delta_index(index)\n      add_delta_indexes([index])\n    end\n\n    # Public: List of deltas that are requested with this diff\n    #\n    # Returns an Array of GitRPC::Diff::Deltas or GitRPC::Diff::Summary::Deltas\n    def requested_deltas\n      return @requested_deltas unless @requested_deltas.nil?\n      return @requested_deltas = deltas.dup if paths.empty? && delta_indexes.empty?\n\n      selected_deltas = []\n\n      # TODO: Once all paths are added via add_path, this step will become unnecessary\n      unless paths.empty?\n        @paths = Set.new(paths.map { |path| path.try(:b) }).freeze\n      end\n\n      unless paths.empty?\n        deltas_from_paths = deltas.select { |e| paths.include?(e.old_file.path) }\n        selected_deltas.concat(deltas_from_paths)\n      end\n\n      unless delta_indexes.empty?\n        deltas_from_indices = deltas.values_at(*delta_indexes).compact\n        selected_deltas.concat(deltas_from_indices)\n      end\n\n      @requested_deltas = selected_deltas.uniq\n    end\n\n    # Internal: Resets the list of requested deltas to ensure they get recomputed\n    #\n    # Returns nothing\n    def reset_requested_deltas\n      @requested_deltas = nil\n    end\n\n    # Public: List of requested paths\n    #\n    # Returns an Array of Strings\n    def requested_paths\n      requested_deltas.flat_map(&:paths).uniq\n    end\n\n    # Public: Lists the paths that have been loaded by this diff. Excludes truncated entries.\n    #\n    # Returns an array of the String paths of entries loaded by the diff. In the case of renames, both paths\n    # are included.\n    def non_truncated_paths\n      return @non_truncated_paths if defined?(@non_truncated_paths)\n\n      return [] if !loaded?\n\n      non_truncated = entries.reject {|e| e.truncated? }\n\n      @non_truncated_paths = non_truncated.flat_map { |e| [e.a_path_raw, e.b_path_raw].compact }.uniq\n    end\n\n    # Locate a diff for a given path name. This first checks for an exact match on\n    # b_path names and then falls back on looking for renamed files.\n    #\n    # path - String full path name to file.\n    #\n    # Returns a ChangedFile object for the diff.\n    def find_by_path(path)\n      entries.each do |entry|\n        if entry.path == path\n          return entry\n        elsif entry.path > path\n          break  # diffs are sorted by path name\n        end\n      end\n      entries.find { |entry| entry.renamed? && entry.a_path == path }\n    end\n\n    # Public: The stats on this diff\n    #\n    # Returns a GitRPC::Diff::Summary\n    def summary\n      return @summary if defined?(@summary)\n\n      update_time_remaining do\n        @summary = rpc.read_diff_summary(parsed_sha1, parsed_sha2, base_sha,\n                                         timeout: time_remaining, algorithm: git_diff_algorithm)\n      end\n    end\n\n    # Internal: Was the diff's summary loaded?\n    #\n    # Returns a Boolean\n    def summary_loaded?\n      defined?(@summary)\n    end\n\n    # Is the summary cached?\n    def summary_warm?\n      rpc.diff_summary_cached?(parsed_sha1, parsed_sha2, base_sha)\n    end\n\n    # Public: Get a semantic table of contents summary.\n    #\n    # allow_edge_languages - Boolean if edge languages should be summarized\n    #                        (optional, default: false).\n    #\n    # Returns a GitHub::Semiotic::TocSummary, or an unavailable TocSummary on error.\n    def toc_summary(allow_edge_languages: false)\n      return @toc_summary if defined?(@toc_summary)\n\n      client = GitHub::Semiotic::Client.for(GitHub.semiotic_url, repo.rpc, cache: repo.rpc.cache,\n        # Don't leak source code, only log parse errors for public or github owned repos.\n        log_parse_errors: repo.public? || repo.owner == \"github\",\n        allow_edge_languages: allow_edge_languages)\n      paths = deltas.map(&:paths).flatten.uniq\n      @toc_summary = client.read_toc_summary(parsed_sha1, parsed_sha2, paths)\n    end\n\n    # Public: A complete list of all deltas\n    #\n    # Returns an Array of GitRPC::Diff::Deltas or GitRPC::Diff::Summary::Deltas\n    def deltas\n      return @deltas if defined?(@deltas)\n\n      @deltas = if summary_loaded? || use_summary?\n                  summary.deltas\n                else\n                  load_deltas\n                end\n    end\n\n    # Internal: Loads the diffs deltas\n    #\n    # Returns an Array of GitRPC::Diff::Deltas\n    def load_deltas\n      update_time_remaining do\n        rpc.native_read_diff_toc(parsed_sha1, parsed_sha2, base_sha,\n                                 \"timeout\" => time_remaining)\n      end\n    end\n\n    def_delegators :summary, :changes, :additions, :deletions\n\n    def changed_files\n      if summary_loaded? || use_summary?\n        summary.changed_files\n      else\n        deltas.size\n      end\n    end\n\n    def too_big?\n      changed_files > max_files\n    end\n\n    # Have the diff's entries been loaded? If not, some operations could result in a costly gitrpc call\n    def loaded?\n      !!defined?(@entries_hash)\n    end\n\n    def total_line_count\n      entries.map(&:line_count).sum\n    end\n\n    def total_byte_count\n      entries.map(&:byte_count).sum\n    end\n\n    def truncated?\n      self.truncated\n    end\n\n    def truncated\n      entries_hash[\"truncated\"]\n    end\n\n    def truncated_reason\n      entries_hash[\"truncated_reason\"]\n    end\n\n    def entries_cached?\n      cached?(\"entries_hash\")\n    end\n\n    def entries\n      entries_hash[\"entries\"]\n    end\n\n    alias to_a entries\n\n    def entries_hash\n      return @entries_hash if defined? @entries_hash\n\n      @entries_hash = load_entries_hash\n    end\n\n    def entries_hash_cache_key\n      cache_prefix(:toc_entries_hash)\n    end\n\n    def load_entries_hash\n      start_time = Time.now\n      cached = true\n\n      entries_hash = GitHub.cache.fetch(entries_hash_cache_key, :stats_key => \"diff.cache.toc_entries_hash\") do\n        cached = false\n        load_entries_hash!\n      end\n\n      duration_ms = (Time.now - start_time) * 1000\n      GitHub.dogstats.timing \"diff.load\", duration_ms, tags: %W(cached:#{cached})\n\n      entries_hash\n    end\n\n    # Internal: Retrieves the diff patches (entries) using diff-pairs\n    # by passing in the requested deltas.\n    #\n    # Returns Hash\n    def load_entries_hash!\n      truncated_deltas = requested_deltas[0, max_files]\n\n      indexed_deltas = {}\n      truncated_deltas.each do |delta|\n        # TODO: Key generation for entries and deltas should be extracted into a single method\n        key = [delta.old_file.path, delta.status, delta.new_file.path].join(\":\")\n\n        indexed_deltas[key] = delta\n      end\n\n      result = if truncated_deltas.empty?\n        { \"data\" => \"\" }\n      else\n        entries_timeout = if top_only?\n          [TOP_ONLY_TIMEOUT, time_remaining].min\n        else\n          time_remaining\n        end\n\n        update_time_remaining do\n          load_diff_pairs(truncated_deltas, entries_timeout)\n        end\n      end\n\n      text_entries = {}\n\n      parser = Parser.new(result[\"data\"])\n      parser.each do |entry|\n        # TODO: Key generation for entries and deltas should be extracted into a single method\n        key = [entry.a_path_raw || entry.b_path_raw, entry.status, entry.b_path_raw || entry.a_path_raw].join(\":\")\n\n        # TODO: Long-term refactoring => Pass delta to entry and\n        # delegate all data accessors to the delta. This way we could\n        # drop this if-clause.\n        if entry.renamed? && entry.b_blob.nil?\n          entry.b_blob = indexed_deltas[key].new_file.oid\n        end\n\n        entry.whitespace_ignored = ignore_whitespace\n        entry.a_sha = parsed_sha1\n        entry.b_sha = parsed_sha2\n\n        text_entries[key] = entry\n      end\n\n      truncated_for_max_files = requested_deltas.size > max_files\n\n      truncated = parser.truncated || truncated_for_max_files\n      truncated_reason = parser.truncated_reason\n      truncated_reason ||= \"timeout reached.\" if result[\"timed_out\"]\n\n      fresh_entries = []\n      deltas_to_process = indexed_deltas.dup\n\n      # Fill in entries with text and whitespace-only changes\n      while deltas_to_process.any?\n        key, delta = deltas_to_process.shift\n\n        if text_entries.has_key?(key)\n          fresh_entries << text_entries.delete(key)\n          break if text_entries.empty?\n        else\n          # Create diff entry for files with whitespace-only changes\n          fresh_entries << GitHub::Diff::Entry.from(:diff => self, :delta => delta).tap do |entry|\n            entry.a_sha = self.parsed_sha1\n            entry.b_sha = self.parsed_sha2\n            entry.whitespace_ignored = self.ignore_whitespace\n          end\n        end\n      end\n\n      # Fill in entries without text\n      while deltas_to_process.any?\n        key, delta = deltas_to_process.shift\n\n        fresh_entries << GitHub::Diff::Entry.from(:diff => self, :delta => delta).tap do |entry|\n          entry.a_sha = self.parsed_sha1\n          entry.b_sha = self.parsed_sha2\n          entry.whitespace_ignored = self.ignore_whitespace\n\n          # These entries are marked truncated since they were not part\n          # of the entries returned by diff-pairs.\n          entry.truncated_reason = truncated_reason\n        end\n      end\n\n      fresh_entries.sort_by!(&:path)\n\n      if truncated_for_max_files && !result[\"timed_out\"]\n        truncated_reason = \"maximum file count exceeded: total=#{requested_deltas.size}\"\n      end\n\n      {\n        \"entries\" => fresh_entries,\n        \"truncated\" => truncated,\n        \"truncated_reason\" => truncated_reason\n      }\n    end\n\n    def parsed_sha1\n      return @parsed_sha1 if defined?(@parsed_sha1)\n      @parsed_sha1 = sha1 ? rpc.rev_parse(sha1) : nil\n    end\n\n    def parsed_sha2\n      return @parsed_sha2 if defined?(@parsed_sha2)\n      @parsed_sha2 = sha2 ? rpc.rev_parse(sha2) : nil\n    end\n\n    def time_remaining\n      return @time_remaining if defined?(@time_remaining)\n      @time_remaining = self.timeout || self.class.timeout\n    end\n\n    def update_time_remaining(&block)\n      start = Time.now\n      block.call\n    ensure\n      elapsed = Time.now - start\n\n      @time_remaining = time_remaining - elapsed\n      @time_remaining = 0 if time_remaining < 0\n    end\n\n    # Git diff compatible algorithm\n    def git_diff_algorithm\n      if ignore_whitespace\n        \"ignore-whitespace\"\n      else\n        \"vanilla\"\n      end\n    end\n\n    def load_diff_pairs(truncated_deltas, entries_timeout)\n      options = {\n        \"max_diff_size\" => @max_diff_size,\n        \"max_total_size\" => @max_total_size,\n        \"max_diff_lines\" => @max_diff_lines,\n        \"max_total_lines\" => @max_total_lines,\n        \"ignore_whitespace\" => ignore_whitespace,\n        \"max_files\" => @max_files,\n        \"timeout\" => entries_timeout\n      }\n\n      rpc.read_diff_pairs_with_base(\n        parsed_sha1, parsed_sha2, base_sha,\n        truncated_deltas, options\n      )\n    end\n\n    def load_diff(timeout: self.class.default_timeout)\n      new_timeout = [self.timeout, timeout].compact.min\n      self.timeout = new_timeout\n\n      available?\n    end\n\n    # Is the diff available?\n    #\n    # It's possible for the diff to be unavailable due to:\n    #   * \"corrupt\"         - Something unexpected happened. Possibly a corrupt repository.\n    #   * \"missing commits\" - The base or head commit don't exist in this repository. This can happen\n    #                         if a commit is looked up through the wrong repository in a public network,\n    #                         but the lookup succeeds because the commit was in the shared commit cache.\n    #   * \"timeout\"         - The diff took too long to generate\n    #   * \"too busy\"        - The fileserver is under heavy load and the condense-diff\n    #                         process was killed by gitmon\n    #\n    # The entries array will be empty when unavailable.\n    #\n    # Returns false if the diff is available, or the reason that the diff is not available otherwise.\n    def unavailable_reason\n      return @unavailable_reason if defined?(@unavailable_reason)\n      cache_key = cache_prefix(\"unavailable_reason\")\n\n      if @unavailable_reason = GitHub.cache.get(cache_key)\n        @entries_hash = {\n          \"entries\" => [],\n          \"truncated\" => false,\n          \"truncated_reason\" => nil\n        }\n      elsif @unavailable_reason = unavailable_reason!\n        GitHub.cache.set(cache_key, @unavailable_reason, 5.minutes.to_i) unless [\"too busy\", \"missing commits\"].include?(@unavailable_reason)\n        @entries_hash = {\n          \"entries\" => [],\n          \"truncated\" => false,\n          \"truncated_reason\" => nil\n        }\n      end\n\n      @unavailable_reason\n    end\n\n    # Internal: Perform the actual availability check without memoization or caching.\n    #\n    # Returns an error message if the diff is corrupt or times out, false otherwise.\n    def unavailable_reason!\n      return \"corrupt\" if [sha1, sha2].include?(GitHub::NULL_OID)\n      return false if defined?(@entries_hash)\n\n      if use_summary?\n        return summary.unavailable_reason unless summary.available?\n      end\n\n      entries\n\n      false\n    rescue ::GitRPC::Timeout\n      \"timeout\"\n    rescue GitRPC::CommandBusy\n      \"too busy\"\n    rescue GitRPC::ObjectMissing\n      \"missing commits\"\n    rescue GitRPC::InvalidRepository\n      \"corrupt\"\n    rescue GitHub::Diff::Parser::UnrecognizedText, GitRPC::Error => e\n      Failbot.report(e)\n      \"corrupt\"\n    end\n\n    def available?\n      unavailable_reason == false\n    end\n\n    def timed_out?\n      unavailable_reason == \"timeout\"\n    end\n\n    def too_busy?\n      unavailable_reason == \"too busy\"\n    end\n\n    def corrupt?\n      unavailable_reason == \"corrupt\"\n    end\n\n    def missing_commits?\n      unavailable_reason == \"missing commits\"\n    end\n\n    ##\n    # Internals\n\n    def apply_top_only_limits!\n      self.max_total_lines = TOP_ONLY_MAX_TOTAL_LINES\n      self.max_total_size  = TOP_ONLY_MAX_TOTAL_SIZE\n    end\n\n    # Internal: Apply the auto-load limits for a single diff entry.\n    #\n    # Depending on the number of changed files, we adjust the max diff entry\n    # limits proportionally within the limits of DEFAULT_MAX_DIFF_LINES and\n    # AUTO_LOAD_MAX_DIFF_LINES.\n    #\n    # Notice: This might trigger the diff summary to load, see #changed_files.\n    #\n    # Returns nothing\n    def apply_auto_load_single_entry_limits!\n      lines = if empty?\n                AUTO_LOAD_MAX_DIFF_LINES\n              else\n                custom_max_diff_lines = DEFAULT_MAX_DIFF_LINES / changed_files\n                [custom_max_diff_lines, AUTO_LOAD_MAX_DIFF_LINES].max\n              end\n      size = lines * AVERAGE_LINE_SIZE\n\n      # FIXME: on top_only requests we want the diff to be truncated so that we\n      # attempt a follow up request with bigger limits. Potentially having a\n      # max_diff_size that is greater than max_total_size will allow for this.\n      # On batch requests this doesn't make sense, we just want the diff to\n      # always be skipped.\n      # This is an ugly solution, all limits should be dynamic and additional\n      # requests should not be made. Please fix this.\n      unless top_only?\n        lines = [lines, self.max_total_lines].min\n        size = [size, self.max_total_size].min\n      end\n\n      self.max_diff_lines = lines\n      self.max_diff_size  = size\n    end\n\n    def cached?(key)\n      GitHub.cache.exist?(cache_prefix(key))\n    end\n\n    def cache(key, &block)\n      if (value = instance_variable_get(\"@#{key}\")).nil?\n        value = GitHub.cache.fetch(cache_prefix(key), :stats_key => \"diff.cache.#{key}\") { yield }\n        instance_variable_set(\"@#{key}\", value)\n      end\n      value\n    end\n\n    def cache_prefix(key)\n      @prefix ||= begin\n        paths_key = Digest::MD5.hexdigest(paths.join(\":\")) if paths.any?\n        delta_indexes_key = Digest::MD5.hexdigest(delta_indexes.join(\":\")) if delta_indexes.any?\n\n        [\n          \"GitHub::Diff\", \"v14\", sha1, sha2, base_sha,\n          git_diff_algorithm,\n          paths_key, delta_indexes_key,\n          max_diff_lines, max_total_lines,\n          \"prog_output\"\n        ].compact.join(\":\")\n      end\n\n      \"#{@prefix}:#{key}\"\n    end\n  end\nend\n","language":"Ruby"}},{"after":{"path":"test/lib/github/config_test.rb","content":"# frozen_string_literal: true\n\nrequire_relative \"../../test_helper\"\n\ncontext GitHub::Config do\n  include EnvironmentTestHelper\n\n  setup do\n    GitHub.reset_websocket_redis_disabled\n    GitHub.reset_mysql_primary_disabled\n    GitHub.reset_resque_redis_disabled\n    GitHub.local_host_name_short = nil\n    GitHub.local_datacenter = nil\n    GitHub.environment = nil\n    GitHub.role = nil\n    if GitHub.instance_variable_defined? :@elasticsearch_access\n      GitHub.send :remove_instance_variable, :@elasticsearch_access\n    end\n  end\n\n  teardown do\n    GitHub.reset_websocket_redis_disabled\n    GitHub.reset_mysql_primary_disabled\n    GitHub.reset_resque_redis_disabled\n    GitHub.local_host_name_short = nil\n    GitHub.local_datacenter = nil\n    GitHub.environment = nil\n    GitHub.role = nil\n    GitHub.elasticsearch_access = :allowed\n  end\n\n  context \"flavor\" do\n    test \"for .com\" do\n      GitHub.stubs(:enterprise?).returns(false)\n      assert_equal \"GitHub\", GitHub.flavor\n    end\n\n    test \"for Enterprise\" do\n      GitHub.expects(:enterprise?).returns(true)\n      assert_equal \"GitHub Enterprise\", GitHub.flavor\n    end\n  end\n\n  context \"request_timeout\" do\n    test \"returns default_request_timeout by default\" do\n      timeout = GitHub.enterprise? ? 28 : 10\n\n      assert_equal timeout, GitHub.request_timeout({})\n      assert_equal timeout, GitHub.request_timeout(nil)\n      assert_equal timeout, GitHub.request_timeout(\"REQUEST_PATH\" => \"/\")\n    end\n\n    test \"returns custom timeout for billing paths\" do\n      timeout = GitHub.enterprise? ? 30 : 30\n\n      assert_equal timeout, GitHub.request_timeout(\"REQUEST_PATH\" => \"/account/billing/update_credit_card\")\n      assert_equal timeout, GitHub.request_timeout(\"REQUEST_PATH\" => \"/account/cc_update\")\n      assert_equal timeout, GitHub.request_timeout(\"REQUEST_PATH\" => \"/organizations/github/billing/update_credit_card\")\n      assert_equal timeout, GitHub.request_timeout(\"REQUEST_PATH\" => \"/organizations/org-1ab/billing/update_credit_card\")\n      assert_equal timeout, GitHub.request_timeout(\"REQUEST_PATH\" => \"/organizations/org-1ab/billing/cc_update\")\n      assert_equal timeout, GitHub.request_timeout(\"REQUEST_PATH\" => \"/stafftools/users/org-1ab/change_plan\")\n    end\n\n    test \"returns custom timeout for specific request paths\" do\n      timeout = GitHub.enterprise? ? 28 : 20\n\n      assert_equal timeout, GitHub.request_timeout(\"REQUEST_PATH\" => \"/organizations\")\n      assert_equal timeout, GitHub.request_timeout(\"REQUEST_PATH\" => \"/repositories\")\n      assert_equal timeout, GitHub.request_timeout(\"REQUEST_PATH\" => \"/join/plan\")\n      assert_equal timeout, GitHub.request_timeout(\"REQUEST_PATH\" => \"/redeem/cd631b0\")\n      assert_equal timeout, GitHub.request_timeout(\"REQUEST_PATH\" => \"/site/custom_sleeptown\")\n    end\n\n    test \"returns default_request_timeout for get requests\" do\n      timeout = GitHub.enterprise? ? 28 : 10\n\n      assert_equal timeout, GitHub.request_timeout(\n        \"REQUEST_PATH\" => \"/account/billing/update_credit_card\",\n        \"REQUEST_METHOD\" => \"GET\")\n    end\n  end\n\n  test \"slow request threshold\" do\n    if GitHub.enterprise?\n      assert_equal 5.0, GitHub.slow_request_threshold\n    else\n      assert_equal 2.0, GitHub.slow_request_threshold\n    end\n  end\n\n  context \"billing_enabled?\" do\n    if GitHub.enterprise?\n      test \"is false for Enterprise\" do\n        refute_predicate GitHub, :billing_enabled?\n      end\n    else\n      test \"is true for GitHub.com\" do\n        assert_predicate GitHub, :billing_enabled?\n      end\n    end\n  end\n\n  context \"host_name\" do\n    test \"dotcom default\" do\n      assert_equal \"github.com\", GitHub.host_name\n    end\n\n    test \"uses ENV var if set\" do\n      begin\n        ENV[\"GH_HOSTNAME\"] = \"mybusiness.github.org\"\n        original, GitHub.host_name = GitHub.host_name, nil\n        assert_equal \"mybusiness.github.org\", GitHub.host_name\n      ensure\n        ENV.delete \"GH_HOSTNAME\"\n        GitHub.host_name = original\n      end\n    end\n  end\n\n  context \"api_host_name\" do\n    if GitHub.enterprise?\n      test \"is just the hostname in enterprise\" do\n        assert_equal \"github.com\", GitHub.api_host_name\n      end\n    else\n      test \"has api prefix for dotcom\" do\n        assert_equal \"api.github.com\", GitHub.api_host_name\n      end\n    end\n  end\n\n  context \"api_url\" do\n    test \"includes host_name\" do\n      uri = Addressable::URI.parse(GitHub.api_url)\n      assert_match GitHub.host_name, uri.host\n    end\n\n    test \"api_url\" do\n      if GitHub.enterprise?\n        assert_equal \"https://github.com/api/v3\", GitHub.api_url\n      else\n        assert_equal \"https://api.github.com\", GitHub.api_url\n      end\n    end\n  end\n\n  context \"semiotic_url\" do\n    test \"default\" do\n      GitHub.semiotic_url = nil\n      assert_equal \"http://127.0.0.1:8001\", GitHub.semiotic_url\n    end\n\n    test \"uses ENV var if set\" do\n      GitHub.semiotic_url = nil\n      url = \"http://0.0.0.0:8002\"\n      with_env \"SEMIOTIC_URL\" => url do\n        assert_equal url, GitHub.semiotic_url\n      end\n    end\n  end\n\n  context \"semiotic_kubes_url\" do\n    test \"default\" do\n      GitHub.semiotic_kubes_url = nil\n      assert_equal \"http://127.0.0.1:8001\", GitHub.semiotic_kubes_url\n    end\n\n    test \"uses ENV var if set\" do\n      GitHub.semiotic_kubes_url = nil\n      url = \"http://0.0.0.0:8002\"\n      with_env \"SEMIOTIC_KUBE_URL\" => url do\n        assert_equal url, GitHub.semiotic_kubes_url\n      end\n    end\n  end\n\n  context \"semiotic_token\" do\n    test \"default\" do\n      GitHub.semiotic_token = nil\n      assert_equal \"octocat\", GitHub.semiotic_token\n    end\n\n    test \"uses ENV var if set\" do\n      GitHub.semiotic_token = nil\n      token = \"semantic-code\"\n      with_env \"SEMIOTIC_TOKEN\" => token do\n        assert_equal token, GitHub.semiotic_token\n      end\n    end\n  end\n\n  context \"local_host_name_short\" do\n    test \"normal hosts get their short hostname\" do\n      with_host_name \"test-host.foo.github.net\" do\n        assert_equal \"test-host\", GitHub.local_host_name_short\n      end\n    end\n\n    test \"kube processes take their node name from env\" do\n      with_host_name \"some-pod-name-12345\" do\n        with_env \"KUBE_NODE_HOSTNAME\" => \"kube-test.bar.github.net\" do\n          GitHub.stubs(:kube? => true)\n          assert_equal \"kube-test\", GitHub.local_host_name_short\n        end\n      end\n    end\n\n    test \"kube processes that forgot env are kube-unknown\" do\n      with_host_name \"some-pod-name-98765\" do\n        GitHub.stubs(:kube? => true)\n        assert_equal \"kube-unknown\", GitHub.local_host_name_short\n      end\n    end\n  end\n\n  context \".physical_address\" do\n    test \"returns the office address as a string\" do\n      address = \"GitHub, Inc. 88 Colin P Kelly Jr Street, San Francisco, CA 94107\"\n      assert_equal address, GitHub.physical_address\n    end\n\n    test \"returns the office address as a string when multiline is false\" do\n      address = \"GitHub, Inc. 88 Colin P Kelly Jr Street, San Francisco, CA 94107\"\n      assert_equal address, GitHub.physical_address(multiline: false)\n    end\n\n    test \"returns the office address as an array of address parts when multiline is true\" do\n      address = [\"GitHub, Inc. 88 Colin P Kelly Jr Street\" , \"San Francisco, CA 94107\"]\n      assert_equal address, GitHub.physical_address(multiline: true)\n    end\n  end\n\n  context \"cas_host\" do\n    if GitHub.enterprise?\n      test \"cas_host only returns url origin\" do\n        begin\n          cas_origin = \"https://cas.#{GitHub.host_name}:8443\"\n          original, GitHub.cas_url = GitHub.cas_url, \"#{cas_origin}/cas_endpoint\"\n          assert_equal cas_origin, GitHub.cas_host\n        ensure\n          GitHub.cas_url = original\n        end\n      end\n\n      test \"cas_host returns nil when there is no cas_url\" do\n        begin\n          original, GitHub.cas_url = GitHub.cas_url, nil\n          assert_nil GitHub.cas_host\n        ensure\n          GitHub.cas_url = original\n        end\n      end\n    end\n  end\n\n  context \"reactivate_suspended_user?\" do\n    if GitHub.enterprise?\n      test \"toggling reactivate_suspended_user? works\" do\n        GitHub.auth.stubs(:external?).returns(true)\n        updater = User.make\n        begin\n          GitHub.config.enable(\"auth.reactivate-suspended\", updater)\n          assert GitHub.reactivate_suspended_user?\n\n          GitHub.config.disable(\"auth.reactivate-suspended\", updater)\n          refute GitHub.reactivate_suspended_user?\n        ensure\n          GitHub.config.delete(\"auth.reactivate-suspended\")\n        end\n      end\n    end\n  end\n\n  context \"role\" do\n    test \"defaults to unassigned\" do\n      assert_equal :unassigned, GitHub.role\n    end\n\n    test \"can be overridden\" do\n      GitHub.role = :web\n      assert_equal :web, GitHub.role\n    end\n\n    test \"defaults to env var if it is set\" do\n      begin\n        ENV[\"GITHUB_CONFIG_ROLE\"] = \"envvar\"\n        assert_equal :envvar, GitHub.role\n      ensure\n        ENV.delete(\"GITHUB_CONFIG_ROLE\")\n      end\n    end\n\n    test \"defaults to unassigned if env var is empty\" do\n      begin\n        ENV[\"GITHUB_CONFIG_ROLE\"] = \"\"\n        assert_equal :unassigned, GitHub.role\n      ensure\n        ENV.delete(\"GITHUB_CONFIG_ROLE\")\n      end\n    end\n\n    test \"can override env var\" do\n      begin\n        ENV[\"GITHUB_CONFIG_ROLE\"] = \"envvar\"\n        GitHub.role = :overriden\n        assert_equal :overriden, GitHub.role\n      ensure\n        ENV.delete(\"GITHUB_CONFIG_ROLE\")\n      end\n    end\n  end\n\n  context \"unicorn workers\" do\n    if GitHub.enterprise?\n      test \"defaults to 4 for enterprise hosts\" do\n        with_rails_env \"production\" do\n          assert_equal 4, GitHub.unicorn_worker_count\n        end\n      end\n\n      test \"defaults to 1 for enterprise gitauth hosts\" do\n        with_rails_env \"production\" do\n          with_env \"GITAUTH\" => \"1\" do\n            assert_equal 1, GitHub.unicorn_worker_count\n          end\n        end\n      end\n\n      test \"gitauth be overriden by an env var\" do\n        with_rails_env \"production\" do\n          with_env \"GITAUTH\" => \"1\", \"ENTERPRISE_GITAUTH_WORKERS\" => \"5\" do\n            assert_equal 5, GitHub.unicorn_worker_count\n          end\n        end\n      end\n\n      test \"regular unicorns be overriden by an env var\" do\n        with_rails_env \"production\" do\n          with_env \"ENTERPRISE_GITHUB_WORKERS\" => \"5\" do\n            assert_equal 5, GitHub.unicorn_worker_count\n          end\n        end\n      end\n\n    else\n\n      test \"is 3 for staff hosts\" do\n        with_env \"STAFF_ENVIRONMENT\" => \"garage\" do\n          assert_equal 3, GitHub.unicorn_worker_count\n        end\n      end\n\n      test \"is 2 by default\" do\n        assert_equal 2, GitHub.unicorn_worker_count\n      end\n\n      test \"is 1 for non-production gitauth hosts\" do\n        with_env \"GITAUTH\" => \"1\" do\n          assert_equal 1, GitHub.unicorn_worker_count\n        end\n      end\n\n      test \"is 1 for non-prod github auth hosts\" do\n        with_env \"GITAUTH\" => \"1\" do\n          assert_equal 1, GitHub.unicorn_worker_count\n        end\n      end\n\n      test \"is 2 for rails-production gitauth hosts\" do\n        with_env \"GITAUTH\" => \"1\" do\n          with_server_metadata \"env\" => nil do\n            with_rails_env \"production\" do\n              assert_equal 2, GitHub.unicorn_worker_count\n            end\n          end\n        end\n      end\n\n      test \"is 12 for rails and server-production gitauth hosts\" do\n        with_env \"GITAUTH\" => \"1\" do\n          with_rails_env \"production\" do\n            with_server_metadata \"env\" => \"production\" do\n              assert_equal 12, GitHub.unicorn_worker_count\n            end\n          end\n        end\n      end\n\n      test \"is 3xCPUs for production gitauth-babeld hosts\" do\n        with_env \"GITAUTH\" => \"1\" do\n          with_rails_env \"production\" do\n            with_host_name \"github-babeld1-iasdfasdf.cp1-iad.github.net\" do\n              assert_equal (3 * Etc.nprocessors), GitHub.unicorn_worker_count\n            end\n          end\n        end\n      end\n\n      test \"is 2xCPUs for stafftools hosts\" do\n        with_rails_env \"production\" do\n          with_server_metadata \"env\" => \"production\" do\n            with_host_name \"github-stafftools1-cp1-prd.iad.github.net\" do\n              assert_equal (2 * Etc.nprocessors), GitHub.unicorn_worker_count\n            end\n          end\n        end\n      end\n\n      test \"is 2xCPUs for a prod host\" do\n        with_rails_env \"production\" do\n          with_server_metadata \"env\" => \"production\" do\n            assert_equal (2 * Etc.nprocessors), GitHub.unicorn_worker_count\n          end\n        end\n      end\n\n      test \"is 4 for prod hosts without server metadata\" do\n        with_rails_env \"production\" do\n          with_server_metadata \"env\" => nil do\n            assert_equal 4, GitHub.unicorn_worker_count\n          end\n        end\n      end\n    end\n  end\n\n  context \"resque_redis_disabled?\" do\n    test \"returns false by default\" do\n      refute GitHub.resque_redis_disabled?\n    end\n\n    test \"returns true if env var set to true for role\" do\n      GitHub.override :role, :api do\n        with_env \"API_RESQUE_REDIS_DISABLED\" => \"1\" do\n          assert GitHub.resque_redis_disabled?\n        end\n      end\n    end\n\n    test \"returns false if env var set to true for different role\" do\n      GitHub.override :role, :fe do\n        with_env \"API_RESQUE_REDIS_DISABLED\" => \"1\" do\n          refute GitHub.resque_redis_disabled?\n        end\n      end\n    end\n\n    test \"returns true if env var scoped to local datacenter set to true\" do\n      GitHub.local_datacenter = \"sdc42\"\n      GitHub.override :role, :api do\n        with_env \"SDC42_API_RESQUE_REDIS_DISABLED\" => \"1\" do\n          assert GitHub.resque_redis_disabled?\n        end\n      end\n    end\n\n    test \"returns false if env var scoped to NON local datacenter\" do\n      GitHub.local_datacenter = \"cp1\"\n      GitHub.override :role, :api do\n        with_env \"SDC42_API_RESQUE_REDIS_DISABLED\" => \"1\" do\n          refute GitHub.resque_redis_disabled?\n        end\n      end\n    end\n  end\n\n  context \"resque_retry_quantity\" do\n    test \"RESQUE_RETRY_QUANTITY absent returns a value\" do\n      begin\n        old_env = ENV.to_hash\n        ENV.delete(\"RESQUE_RETRY_QUANTITY\")\n\n        assert_instance_of Integer, GitHub.resque_retry_quantity\n      ensure\n        ENV.replace(old_env.to_hash)\n      end\n    end\n\n    test \"RESQUE_RETRY_QUANTITY present with non integer returns a value\" do\n      with_env \"RESQUE_RETRY_QUANTITY\" => \"not a number\" do\n        assert_instance_of Integer, GitHub.resque_retry_quantity\n      end\n    end\n\n    test \"RESQUE_RETRY_QUANTITY present with integer value returns that\" do\n      with_env \"RESQUE_RETRY_QUANTITY\" => \"10\" do\n        assert_equal 10, GitHub.resque_retry_quantity\n      end\n    end\n  end\n\n  context \"websocket_redis_disabled?\" do\n    test \"returns false by default\" do\n      refute GitHub.websocket_redis_disabled?\n    end\n\n    test \"returns true if env var set to true for role\" do\n      GitHub.override :role, :api do\n        with_env \"API_WEBSOCKET_REDIS_DISABLED\" => \"1\" do\n          assert GitHub.websocket_redis_disabled?\n        end\n      end\n    end\n\n    test \"returns false if env var set to true for different role\" do\n      GitHub.override :role, :fe do\n        with_env \"API_WEBSOCKET_REDIS_DISABLED\" => \"1\" do\n          refute GitHub.websocket_redis_disabled?\n        end\n      end\n    end\n\n    test \"returns true if env var scoped to local datacenter set to true\" do\n      GitHub.local_datacenter = \"sdc42\"\n      GitHub.override :role, :api do\n        with_env \"SDC42_API_WEBSOCKET_REDIS_DISABLED\" => \"1\" do\n          assert GitHub.websocket_redis_disabled?\n        end\n      end\n    end\n\n    test \"returns false if env var scoped to NON local datacenter\" do\n      GitHub.local_datacenter = \"cp1\"\n      GitHub.override :role, :api do\n        with_env \"SDC42_API_WEBSOCKET_REDIS_DISABLED\" => \"1\" do\n          refute GitHub.websocket_redis_disabled?\n        end\n      end\n    end\n  end\n\n  context \"mysql_primary_disabled?\" do\n    test \"returns false by default\" do\n      refute GitHub.mysql_primary_disabled?\n    end\n\n    test \"returns true if env var set to true for role\" do\n      GitHub.override :role, :api do\n        with_env \"API_MYSQL_PRIMARY_DISABLED\" => \"1\" do\n          assert GitHub.mysql_primary_disabled?\n        end\n      end\n    end\n\n    test \"returns false if env var set to true for different role\" do\n      GitHub.override :role, :fe do\n        with_env \"API_MYSQL_PRIMARY_DISABLED\" => \"1\" do\n          refute GitHub.mysql_primary_disabled?\n        end\n      end\n    end\n\n    test \"returns true if env var scoped to local datacenter set to true\" do\n      GitHub.local_datacenter = \"sdc42\"\n      GitHub.override :role, :api do\n        with_env \"SDC42_API_MYSQL_PRIMARY_DISABLED\" => \"1\" do\n          assert GitHub.mysql_primary_disabled?\n        end\n      end\n    end\n\n    test \"returns false if env var scoped to NON local datacenter\" do\n      GitHub.local_datacenter = \"cp1\"\n      GitHub.override :role, :api do\n        with_env \"SDC42_API_MYSQL_PRIMARY_DISABLED\" => \"1\" do\n          refute GitHub.mysql_primary_disabled?\n        end\n      end\n    end\n  end\n\n  context \"api_read_only?\" do\n    test \"returns true if all datastores return true\" do\n      GitHub.stubs(\n        :resque_redis_disabled? => true,\n        :websocket_redis_disabled? => true,\n        :mysql_primary_disabled? => true,\n        :elasticsearch_access_raises? => true\n      )\n      assert GitHub.api_read_only?\n    end\n\n    test \"returns false if resque redis disabled\" do\n      GitHub.stubs(\n        :resque_redis_disabled? => false,\n        :websocket_redis_disabled? => true,\n        :mysql_primary_disabled? => true,\n        :elasticsearch_access_raises? => true\n      )\n      refute GitHub.api_read_only?\n    end\n\n    test \"returns false if websocket redis disabled\" do\n      GitHub.stubs(\n        :resque_redis_disabled? => true,\n        :websocket_redis_disabled? => false,\n        :mysql_primary_disabled? => true,\n        :elasticsearch_access_raises? => true\n      )\n      refute GitHub.api_read_only?\n    end\n\n    test \"returns false if mysql primary disabled\" do\n      GitHub.stubs(\n        :resque_redis_disabled? => true,\n        :websocket_redis_disabled? => true,\n        :mysql_primary_disabled? => false,\n        :elasticsearch_access_raises? => true\n      )\n      refute GitHub.api_read_only?\n    end\n\n    test \"returns false if elasticsearch is set to raises\" do\n      GitHub.stubs(\n        :resque_redis_disabled? => true,\n        :websocket_redis_disabled? => true,\n        :mysql_primary_disabled? => true,\n        :elasticsearch_access_raises? => false\n      )\n      refute GitHub.api_read_only?\n    end\n  end\n\n  context \"site_from_host\" do\n    test \"returns cp1-iad for cp1 host\" do\n      assert_equal \"cp1-iad\",\n        GitHub.site_from_host(\"db-mysql-9082342.cp1-iad.github.net\")\n    end\n\n    test \"returns cp1-iad for cp1 redis host\" do\n      assert_equal \"cp1-iad\",\n        GitHub.site_from_host(\"github-redis101a-cp1-prd.iad.github.net\")\n    end\n\n    test \"returns sdc42-sea for sdc42 host\" do\n      assert_equal \"sdc42-sea\",\n        GitHub.site_from_host(\"db-mysql-c0c881d.sdc42-sea.github.net\")\n    end\n\n    test \"returns unknown for host that matches regex but is not in whitelist\" do\n      assert_equal \"unknown\",\n        GitHub.site_from_host(\"db-mysql-c0c881d.blah-bla.github.net\")\n    end\n\n    test \"returns unknown for host that does not match regex\" do\n      assert_equal \"unknown\",\n        GitHub.site_from_host(\"localhost\")\n    end\n  end\n\n  context \"elasticsearch_access\" do\n    test \"when not configured in ENV defaults to allow\" do\n      with_env \"ELASTICSEARCH_ACCESS\" => nil do\n        assert_predicate GitHub, :elasticsearch_access_allowed?\n        refute_predicate GitHub, :elasticsearch_access_ignored?\n        refute_predicate GitHub, :elasticsearch_access_raises?\n      end\n    end\n\n    test \"when set to allow\" do\n      with_env \"ELASTICSEARCH_ACCESS\" => \"allowed\" do\n        assert_predicate GitHub, :elasticsearch_access_allowed?\n        refute_predicate GitHub, :elasticsearch_access_ignored?\n        refute_predicate GitHub, :elasticsearch_access_raises?\n      end\n    end\n\n    test \"when set to ignore\" do\n      with_env \"ELASTICSEARCH_ACCESS\" => \"ignored\" do\n        refute_predicate GitHub, :elasticsearch_access_allowed?\n        assert_predicate GitHub, :elasticsearch_access_ignored?\n        refute_predicate GitHub, :elasticsearch_access_raises?\n      end\n    end\n\n    test \"when set to raise\" do\n      with_env \"ELASTICSEARCH_ACCESS\" => \"raises\" do\n        refute_predicate GitHub, :elasticsearch_access_allowed?\n        refute_predicate GitHub, :elasticsearch_access_ignored?\n        assert_predicate GitHub, :elasticsearch_access_raises?\n      end\n    end\n\n    test \"returns allowed when scoped to local datacenter and not set\" do\n      GitHub.local_datacenter = \"sdc42\"\n      with_env \"SDC42_ELASTICSEARCH_ACCESS\" => nil do\n        assert_predicate GitHub, :elasticsearch_access_allowed?\n        refute_predicate GitHub, :elasticsearch_access_ignored?\n        refute_predicate GitHub, :elasticsearch_access_raises?\n      end\n    end\n\n    test \"returns raises when scoped to local datacenter and set to raises\" do\n      GitHub.local_datacenter = \"sdc42\"\n      with_env \"SDC42_ELASTICSEARCH_ACCESS\" => \"raises\" do\n        refute_predicate GitHub, :elasticsearch_access_allowed?\n        refute_predicate GitHub, :elasticsearch_access_ignored?\n        assert_predicate GitHub, :elasticsearch_access_raises?\n      end\n    end\n\n    test \"returns allowed if env var scoped to NON local datacenter\" do\n      GitHub.local_datacenter = \"cp1\"\n      with_env \"SDC42_ELASTICSEARCH_ACCESS\" => \"raises\" do\n        assert_predicate GitHub, :elasticsearch_access_allowed?\n        refute_predicate GitHub, :elasticsearch_access_ignored?\n        refute_predicate GitHub, :elasticsearch_access_raises?\n      end\n    end\n\n    test \"raises when environment set to an invalid value\" do\n      with_env \"ELASTICSEARCH_ACCESS\" => \"whatever\" do\n        assert_raises TypeError do\n          GitHub.elasticsearch_access_allowed?\n        end\n      end\n    end\n\n    test \"setting elasticsearch_access changes the mode\" do\n      assert_predicate GitHub, :elasticsearch_access_allowed?\n      GitHub.elasticsearch_access = :ignored\n      refute_predicate GitHub, :elasticsearch_access_allowed?\n      assert_predicate GitHub, :elasticsearch_access_ignored?\n    end\n\n    test \"setting elasticsearch_access to an invalid value raises\" do\n      assert_raises TypeError do\n        GitHub.elasticsearch_access = :invalid\n      end\n    end\n  end\nend\n","language":"Ruby"},"before":{"path":"test/lib/github/config_test.rb","content":"# frozen_string_literal: true\n\nrequire_relative \"../../test_helper\"\n\ncontext GitHub::Config do\n  include EnvironmentTestHelper\n\n  setup do\n    GitHub.reset_websocket_redis_disabled\n    GitHub.reset_mysql_primary_disabled\n    GitHub.reset_resque_redis_disabled\n    GitHub.local_host_name_short = nil\n    GitHub.local_datacenter = nil\n    GitHub.environment = nil\n    GitHub.role = nil\n    if GitHub.instance_variable_defined? :@elasticsearch_access\n      GitHub.send :remove_instance_variable, :@elasticsearch_access\n    end\n  end\n\n  teardown do\n    GitHub.reset_websocket_redis_disabled\n    GitHub.reset_mysql_primary_disabled\n    GitHub.reset_resque_redis_disabled\n    GitHub.local_host_name_short = nil\n    GitHub.local_datacenter = nil\n    GitHub.environment = nil\n    GitHub.role = nil\n    GitHub.elasticsearch_access = :allowed\n  end\n\n  context \"flavor\" do\n    test \"for .com\" do\n      GitHub.stubs(:enterprise?).returns(false)\n      assert_equal \"GitHub\", GitHub.flavor\n    end\n\n    test \"for Enterprise\" do\n      GitHub.expects(:enterprise?).returns(true)\n      assert_equal \"GitHub Enterprise\", GitHub.flavor\n    end\n  end\n\n  context \"request_timeout\" do\n    test \"returns default_request_timeout by default\" do\n      timeout = GitHub.enterprise? ? 28 : 10\n\n      assert_equal timeout, GitHub.request_timeout({})\n      assert_equal timeout, GitHub.request_timeout(nil)\n      assert_equal timeout, GitHub.request_timeout(\"REQUEST_PATH\" => \"/\")\n    end\n\n    test \"returns custom timeout for billing paths\" do\n      timeout = GitHub.enterprise? ? 30 : 30\n\n      assert_equal timeout, GitHub.request_timeout(\"REQUEST_PATH\" => \"/account/billing/update_credit_card\")\n      assert_equal timeout, GitHub.request_timeout(\"REQUEST_PATH\" => \"/account/cc_update\")\n      assert_equal timeout, GitHub.request_timeout(\"REQUEST_PATH\" => \"/organizations/github/billing/update_credit_card\")\n      assert_equal timeout, GitHub.request_timeout(\"REQUEST_PATH\" => \"/organizations/org-1ab/billing/update_credit_card\")\n      assert_equal timeout, GitHub.request_timeout(\"REQUEST_PATH\" => \"/organizations/org-1ab/billing/cc_update\")\n      assert_equal timeout, GitHub.request_timeout(\"REQUEST_PATH\" => \"/stafftools/users/org-1ab/change_plan\")\n    end\n\n    test \"returns custom timeout for specific request paths\" do\n      timeout = GitHub.enterprise? ? 28 : 20\n\n      assert_equal timeout, GitHub.request_timeout(\"REQUEST_PATH\" => \"/organizations\")\n      assert_equal timeout, GitHub.request_timeout(\"REQUEST_PATH\" => \"/repositories\")\n      assert_equal timeout, GitHub.request_timeout(\"REQUEST_PATH\" => \"/join/plan\")\n      assert_equal timeout, GitHub.request_timeout(\"REQUEST_PATH\" => \"/redeem/cd631b0\")\n      assert_equal timeout, GitHub.request_timeout(\"REQUEST_PATH\" => \"/site/custom_sleeptown\")\n    end\n\n    test \"returns default_request_timeout for get requests\" do\n      timeout = GitHub.enterprise? ? 28 : 10\n\n      assert_equal timeout, GitHub.request_timeout(\n        \"REQUEST_PATH\" => \"/account/billing/update_credit_card\",\n        \"REQUEST_METHOD\" => \"GET\")\n    end\n  end\n\n  test \"slow request threshold\" do\n    if GitHub.enterprise?\n      assert_equal 5.0, GitHub.slow_request_threshold\n    else\n      assert_equal 2.0, GitHub.slow_request_threshold\n    end\n  end\n\n  context \"billing_enabled?\" do\n    if GitHub.enterprise?\n      test \"is false for Enterprise\" do\n        refute_predicate GitHub, :billing_enabled?\n      end\n    else\n      test \"is true for GitHub.com\" do\n        assert_predicate GitHub, :billing_enabled?\n      end\n    end\n  end\n\n  context \"host_name\" do\n    test \"dotcom default\" do\n      assert_equal \"github.com\", GitHub.host_name\n    end\n\n    test \"uses ENV var if set\" do\n      begin\n        ENV[\"GH_HOSTNAME\"] = \"mybusiness.github.org\"\n        original, GitHub.host_name = GitHub.host_name, nil\n        assert_equal \"mybusiness.github.org\", GitHub.host_name\n      ensure\n        ENV.delete \"GH_HOSTNAME\"\n        GitHub.host_name = original\n      end\n    end\n  end\n\n  context \"api_host_name\" do\n    if GitHub.enterprise?\n      test \"is just the hostname in enterprise\" do\n        assert_equal \"github.com\", GitHub.api_host_name\n      end\n    else\n      test \"has api prefix for dotcom\" do\n        assert_equal \"api.github.com\", GitHub.api_host_name\n      end\n    end\n  end\n\n  context \"api_url\" do\n    test \"includes host_name\" do\n      uri = Addressable::URI.parse(GitHub.api_url)\n      assert_match GitHub.host_name, uri.host\n    end\n\n    test \"api_url\" do\n      if GitHub.enterprise?\n        assert_equal \"https://github.com/api/v3\", GitHub.api_url\n      else\n        assert_equal \"https://api.github.com\", GitHub.api_url\n      end\n    end\n  end\n\n  context \"semiotic_url\" do\n    test \"default\" do\n      GitHub.semiotic_url = nil\n      assert_equal \"http://127.0.0.1:8001\", GitHub.semiotic_url\n    end\n\n    test \"uses ENV var if set\" do\n      GitHub.semiotic_url = nil\n      url = \"http://0.0.0.0:8002\"\n      with_env \"SEMIOTIC_URL\" => url do\n        assert_equal url, GitHub.semiotic_url\n      end\n    end\n  end\n\n  context \"semiotic_token\" do\n    test \"default\" do\n      GitHub.semiotic_token = nil\n      assert_equal \"octocat\", GitHub.semiotic_token\n    end\n\n    test \"uses ENV var if set\" do\n      GitHub.semiotic_token = nil\n      token = \"semantic-code\"\n      with_env \"SEMIOTIC_TOKEN\" => token do\n        assert_equal token, GitHub.semiotic_token\n      end\n    end\n  end\n\n  context \"local_host_name_short\" do\n    test \"normal hosts get their short hostname\" do\n      with_host_name \"test-host.foo.github.net\" do\n        assert_equal \"test-host\", GitHub.local_host_name_short\n      end\n    end\n\n    test \"kube processes take their node name from env\" do\n      with_host_name \"some-pod-name-12345\" do\n        with_env \"KUBE_NODE_HOSTNAME\" => \"kube-test.bar.github.net\" do\n          GitHub.stubs(:kube? => true)\n          assert_equal \"kube-test\", GitHub.local_host_name_short\n        end\n      end\n    end\n\n    test \"kube processes that forgot env are kube-unknown\" do\n      with_host_name \"some-pod-name-98765\" do\n        GitHub.stubs(:kube? => true)\n        assert_equal \"kube-unknown\", GitHub.local_host_name_short\n      end\n    end\n  end\n\n  context \".physical_address\" do\n    test \"returns the office address as a string\" do\n      address = \"GitHub, Inc. 88 Colin P Kelly Jr Street, San Francisco, CA 94107\"\n      assert_equal address, GitHub.physical_address\n    end\n\n    test \"returns the office address as a string when multiline is false\" do\n      address = \"GitHub, Inc. 88 Colin P Kelly Jr Street, San Francisco, CA 94107\"\n      assert_equal address, GitHub.physical_address(multiline: false)\n    end\n\n    test \"returns the office address as an array of address parts when multiline is true\" do\n      address = [\"GitHub, Inc. 88 Colin P Kelly Jr Street\" , \"San Francisco, CA 94107\"]\n      assert_equal address, GitHub.physical_address(multiline: true)\n    end\n  end\n\n  context \"cas_host\" do\n    if GitHub.enterprise?\n      test \"cas_host only returns url origin\" do\n        begin\n          cas_origin = \"https://cas.#{GitHub.host_name}:8443\"\n          original, GitHub.cas_url = GitHub.cas_url, \"#{cas_origin}/cas_endpoint\"\n          assert_equal cas_origin, GitHub.cas_host\n        ensure\n          GitHub.cas_url = original\n        end\n      end\n\n      test \"cas_host returns nil when there is no cas_url\" do\n        begin\n          original, GitHub.cas_url = GitHub.cas_url, nil\n          assert_nil GitHub.cas_host\n        ensure\n          GitHub.cas_url = original\n        end\n      end\n    end\n  end\n\n  context \"reactivate_suspended_user?\" do\n    if GitHub.enterprise?\n      test \"toggling reactivate_suspended_user? works\" do\n        GitHub.auth.stubs(:external?).returns(true)\n        updater = User.make\n        begin\n          GitHub.config.enable(\"auth.reactivate-suspended\", updater)\n          assert GitHub.reactivate_suspended_user?\n\n          GitHub.config.disable(\"auth.reactivate-suspended\", updater)\n          refute GitHub.reactivate_suspended_user?\n        ensure\n          GitHub.config.delete(\"auth.reactivate-suspended\")\n        end\n      end\n    end\n  end\n\n  context \"role\" do\n    test \"defaults to unassigned\" do\n      assert_equal :unassigned, GitHub.role\n    end\n\n    test \"can be overridden\" do\n      GitHub.role = :web\n      assert_equal :web, GitHub.role\n    end\n\n    test \"defaults to env var if it is set\" do\n      begin\n        ENV[\"GITHUB_CONFIG_ROLE\"] = \"envvar\"\n        assert_equal :envvar, GitHub.role\n      ensure\n        ENV.delete(\"GITHUB_CONFIG_ROLE\")\n      end\n    end\n\n    test \"defaults to unassigned if env var is empty\" do\n      begin\n        ENV[\"GITHUB_CONFIG_ROLE\"] = \"\"\n        assert_equal :unassigned, GitHub.role\n      ensure\n        ENV.delete(\"GITHUB_CONFIG_ROLE\")\n      end\n    end\n\n    test \"can override env var\" do\n      begin\n        ENV[\"GITHUB_CONFIG_ROLE\"] = \"envvar\"\n        GitHub.role = :overriden\n        assert_equal :overriden, GitHub.role\n      ensure\n        ENV.delete(\"GITHUB_CONFIG_ROLE\")\n      end\n    end\n  end\n\n  context \"unicorn workers\" do\n    if GitHub.enterprise?\n      test \"defaults to 4 for enterprise hosts\" do\n        with_rails_env \"production\" do\n          assert_equal 4, GitHub.unicorn_worker_count\n        end\n      end\n\n      test \"defaults to 1 for enterprise gitauth hosts\" do\n        with_rails_env \"production\" do\n          with_env \"GITAUTH\" => \"1\" do\n            assert_equal 1, GitHub.unicorn_worker_count\n          end\n        end\n      end\n\n      test \"gitauth be overriden by an env var\" do\n        with_rails_env \"production\" do\n          with_env \"GITAUTH\" => \"1\", \"ENTERPRISE_GITAUTH_WORKERS\" => \"5\" do\n            assert_equal 5, GitHub.unicorn_worker_count\n          end\n        end\n      end\n\n      test \"regular unicorns be overriden by an env var\" do\n        with_rails_env \"production\" do\n          with_env \"ENTERPRISE_GITHUB_WORKERS\" => \"5\" do\n            assert_equal 5, GitHub.unicorn_worker_count\n          end\n        end\n      end\n\n    else\n\n      test \"is 3 for staff hosts\" do\n        with_env \"STAFF_ENVIRONMENT\" => \"garage\" do\n          assert_equal 3, GitHub.unicorn_worker_count\n        end\n      end\n\n      test \"is 2 by default\" do\n        assert_equal 2, GitHub.unicorn_worker_count\n      end\n\n      test \"is 1 for non-production gitauth hosts\" do\n        with_env \"GITAUTH\" => \"1\" do\n          assert_equal 1, GitHub.unicorn_worker_count\n        end\n      end\n\n      test \"is 1 for non-prod github auth hosts\" do\n        with_env \"GITAUTH\" => \"1\" do\n          assert_equal 1, GitHub.unicorn_worker_count\n        end\n      end\n\n      test \"is 2 for rails-production gitauth hosts\" do\n        with_env \"GITAUTH\" => \"1\" do\n          with_server_metadata \"env\" => nil do\n            with_rails_env \"production\" do\n              assert_equal 2, GitHub.unicorn_worker_count\n            end\n          end\n        end\n      end\n\n      test \"is 12 for rails and server-production gitauth hosts\" do\n        with_env \"GITAUTH\" => \"1\" do\n          with_rails_env \"production\" do\n            with_server_metadata \"env\" => \"production\" do\n              assert_equal 12, GitHub.unicorn_worker_count\n            end\n          end\n        end\n      end\n\n      test \"is 3xCPUs for production gitauth-babeld hosts\" do\n        with_env \"GITAUTH\" => \"1\" do\n          with_rails_env \"production\" do\n            with_host_name \"github-babeld1-iasdfasdf.cp1-iad.github.net\" do\n              assert_equal (3 * Etc.nprocessors), GitHub.unicorn_worker_count\n            end\n          end\n        end\n      end\n\n      test \"is 2xCPUs for stafftools hosts\" do\n        with_rails_env \"production\" do\n          with_server_metadata \"env\" => \"production\" do\n            with_host_name \"github-stafftools1-cp1-prd.iad.github.net\" do\n              assert_equal (2 * Etc.nprocessors), GitHub.unicorn_worker_count\n            end\n          end\n        end\n      end\n\n      test \"is 2xCPUs for a prod host\" do\n        with_rails_env \"production\" do\n          with_server_metadata \"env\" => \"production\" do\n            assert_equal (2 * Etc.nprocessors), GitHub.unicorn_worker_count\n          end\n        end\n      end\n\n      test \"is 4 for prod hosts without server metadata\" do\n        with_rails_env \"production\" do\n          with_server_metadata \"env\" => nil do\n            assert_equal 4, GitHub.unicorn_worker_count\n          end\n        end\n      end\n    end\n  end\n\n  context \"resque_redis_disabled?\" do\n    test \"returns false by default\" do\n      refute GitHub.resque_redis_disabled?\n    end\n\n    test \"returns true if env var set to true for role\" do\n      GitHub.override :role, :api do\n        with_env \"API_RESQUE_REDIS_DISABLED\" => \"1\" do\n          assert GitHub.resque_redis_disabled?\n        end\n      end\n    end\n\n    test \"returns false if env var set to true for different role\" do\n      GitHub.override :role, :fe do\n        with_env \"API_RESQUE_REDIS_DISABLED\" => \"1\" do\n          refute GitHub.resque_redis_disabled?\n        end\n      end\n    end\n\n    test \"returns true if env var scoped to local datacenter set to true\" do\n      GitHub.local_datacenter = \"sdc42\"\n      GitHub.override :role, :api do\n        with_env \"SDC42_API_RESQUE_REDIS_DISABLED\" => \"1\" do\n          assert GitHub.resque_redis_disabled?\n        end\n      end\n    end\n\n    test \"returns false if env var scoped to NON local datacenter\" do\n      GitHub.local_datacenter = \"cp1\"\n      GitHub.override :role, :api do\n        with_env \"SDC42_API_RESQUE_REDIS_DISABLED\" => \"1\" do\n          refute GitHub.resque_redis_disabled?\n        end\n      end\n    end\n  end\n\n  context \"resque_retry_quantity\" do\n    test \"RESQUE_RETRY_QUANTITY absent returns a value\" do\n      begin\n        old_env = ENV.to_hash\n        ENV.delete(\"RESQUE_RETRY_QUANTITY\")\n\n        assert_instance_of Integer, GitHub.resque_retry_quantity\n      ensure\n        ENV.replace(old_env.to_hash)\n      end\n    end\n\n    test \"RESQUE_RETRY_QUANTITY present with non integer returns a value\" do\n      with_env \"RESQUE_RETRY_QUANTITY\" => \"not a number\" do\n        assert_instance_of Integer, GitHub.resque_retry_quantity\n      end\n    end\n\n    test \"RESQUE_RETRY_QUANTITY present with integer value returns that\" do\n      with_env \"RESQUE_RETRY_QUANTITY\" => \"10\" do\n        assert_equal 10, GitHub.resque_retry_quantity\n      end\n    end\n  end\n\n  context \"websocket_redis_disabled?\" do\n    test \"returns false by default\" do\n      refute GitHub.websocket_redis_disabled?\n    end\n\n    test \"returns true if env var set to true for role\" do\n      GitHub.override :role, :api do\n        with_env \"API_WEBSOCKET_REDIS_DISABLED\" => \"1\" do\n          assert GitHub.websocket_redis_disabled?\n        end\n      end\n    end\n\n    test \"returns false if env var set to true for different role\" do\n      GitHub.override :role, :fe do\n        with_env \"API_WEBSOCKET_REDIS_DISABLED\" => \"1\" do\n          refute GitHub.websocket_redis_disabled?\n        end\n      end\n    end\n\n    test \"returns true if env var scoped to local datacenter set to true\" do\n      GitHub.local_datacenter = \"sdc42\"\n      GitHub.override :role, :api do\n        with_env \"SDC42_API_WEBSOCKET_REDIS_DISABLED\" => \"1\" do\n          assert GitHub.websocket_redis_disabled?\n        end\n      end\n    end\n\n    test \"returns false if env var scoped to NON local datacenter\" do\n      GitHub.local_datacenter = \"cp1\"\n      GitHub.override :role, :api do\n        with_env \"SDC42_API_WEBSOCKET_REDIS_DISABLED\" => \"1\" do\n          refute GitHub.websocket_redis_disabled?\n        end\n      end\n    end\n  end\n\n  context \"mysql_primary_disabled?\" do\n    test \"returns false by default\" do\n      refute GitHub.mysql_primary_disabled?\n    end\n\n    test \"returns true if env var set to true for role\" do\n      GitHub.override :role, :api do\n        with_env \"API_MYSQL_PRIMARY_DISABLED\" => \"1\" do\n          assert GitHub.mysql_primary_disabled?\n        end\n      end\n    end\n\n    test \"returns false if env var set to true for different role\" do\n      GitHub.override :role, :fe do\n        with_env \"API_MYSQL_PRIMARY_DISABLED\" => \"1\" do\n          refute GitHub.mysql_primary_disabled?\n        end\n      end\n    end\n\n    test \"returns true if env var scoped to local datacenter set to true\" do\n      GitHub.local_datacenter = \"sdc42\"\n      GitHub.override :role, :api do\n        with_env \"SDC42_API_MYSQL_PRIMARY_DISABLED\" => \"1\" do\n          assert GitHub.mysql_primary_disabled?\n        end\n      end\n    end\n\n    test \"returns false if env var scoped to NON local datacenter\" do\n      GitHub.local_datacenter = \"cp1\"\n      GitHub.override :role, :api do\n        with_env \"SDC42_API_MYSQL_PRIMARY_DISABLED\" => \"1\" do\n          refute GitHub.mysql_primary_disabled?\n        end\n      end\n    end\n  end\n\n  context \"api_read_only?\" do\n    test \"returns true if all datastores return true\" do\n      GitHub.stubs(\n        :resque_redis_disabled? => true,\n        :websocket_redis_disabled? => true,\n        :mysql_primary_disabled? => true,\n        :elasticsearch_access_raises? => true\n      )\n      assert GitHub.api_read_only?\n    end\n\n    test \"returns false if resque redis disabled\" do\n      GitHub.stubs(\n        :resque_redis_disabled? => false,\n        :websocket_redis_disabled? => true,\n        :mysql_primary_disabled? => true,\n        :elasticsearch_access_raises? => true\n      )\n      refute GitHub.api_read_only?\n    end\n\n    test \"returns false if websocket redis disabled\" do\n      GitHub.stubs(\n        :resque_redis_disabled? => true,\n        :websocket_redis_disabled? => false,\n        :mysql_primary_disabled? => true,\n        :elasticsearch_access_raises? => true\n      )\n      refute GitHub.api_read_only?\n    end\n\n    test \"returns false if mysql primary disabled\" do\n      GitHub.stubs(\n        :resque_redis_disabled? => true,\n        :websocket_redis_disabled? => true,\n        :mysql_primary_disabled? => false,\n        :elasticsearch_access_raises? => true\n      )\n      refute GitHub.api_read_only?\n    end\n\n    test \"returns false if elasticsearch is set to raises\" do\n      GitHub.stubs(\n        :resque_redis_disabled? => true,\n        :websocket_redis_disabled? => true,\n        :mysql_primary_disabled? => true,\n        :elasticsearch_access_raises? => false\n      )\n      refute GitHub.api_read_only?\n    end\n  end\n\n  context \"site_from_host\" do\n    test \"returns cp1-iad for cp1 host\" do\n      assert_equal \"cp1-iad\",\n        GitHub.site_from_host(\"db-mysql-9082342.cp1-iad.github.net\")\n    end\n\n    test \"returns cp1-iad for cp1 redis host\" do\n      assert_equal \"cp1-iad\",\n        GitHub.site_from_host(\"github-redis101a-cp1-prd.iad.github.net\")\n    end\n\n    test \"returns sdc42-sea for sdc42 host\" do\n      assert_equal \"sdc42-sea\",\n        GitHub.site_from_host(\"db-mysql-c0c881d.sdc42-sea.github.net\")\n    end\n\n    test \"returns unknown for host that matches regex but is not in whitelist\" do\n      assert_equal \"unknown\",\n        GitHub.site_from_host(\"db-mysql-c0c881d.blah-bla.github.net\")\n    end\n\n    test \"returns unknown for host that does not match regex\" do\n      assert_equal \"unknown\",\n        GitHub.site_from_host(\"localhost\")\n    end\n  end\n\n  context \"elasticsearch_access\" do\n    test \"when not configured in ENV defaults to allow\" do\n      with_env \"ELASTICSEARCH_ACCESS\" => nil do\n        assert_predicate GitHub, :elasticsearch_access_allowed?\n        refute_predicate GitHub, :elasticsearch_access_ignored?\n        refute_predicate GitHub, :elasticsearch_access_raises?\n      end\n    end\n\n    test \"when set to allow\" do\n      with_env \"ELASTICSEARCH_ACCESS\" => \"allowed\" do\n        assert_predicate GitHub, :elasticsearch_access_allowed?\n        refute_predicate GitHub, :elasticsearch_access_ignored?\n        refute_predicate GitHub, :elasticsearch_access_raises?\n      end\n    end\n\n    test \"when set to ignore\" do\n      with_env \"ELASTICSEARCH_ACCESS\" => \"ignored\" do\n        refute_predicate GitHub, :elasticsearch_access_allowed?\n        assert_predicate GitHub, :elasticsearch_access_ignored?\n        refute_predicate GitHub, :elasticsearch_access_raises?\n      end\n    end\n\n    test \"when set to raise\" do\n      with_env \"ELASTICSEARCH_ACCESS\" => \"raises\" do\n        refute_predicate GitHub, :elasticsearch_access_allowed?\n        refute_predicate GitHub, :elasticsearch_access_ignored?\n        assert_predicate GitHub, :elasticsearch_access_raises?\n      end\n    end\n\n    test \"returns allowed when scoped to local datacenter and not set\" do\n      GitHub.local_datacenter = \"sdc42\"\n      with_env \"SDC42_ELASTICSEARCH_ACCESS\" => nil do\n        assert_predicate GitHub, :elasticsearch_access_allowed?\n        refute_predicate GitHub, :elasticsearch_access_ignored?\n        refute_predicate GitHub, :elasticsearch_access_raises?\n      end\n    end\n\n    test \"returns raises when scoped to local datacenter and set to raises\" do\n      GitHub.local_datacenter = \"sdc42\"\n      with_env \"SDC42_ELASTICSEARCH_ACCESS\" => \"raises\" do\n        refute_predicate GitHub, :elasticsearch_access_allowed?\n        refute_predicate GitHub, :elasticsearch_access_ignored?\n        assert_predicate GitHub, :elasticsearch_access_raises?\n      end\n    end\n\n    test \"returns allowed if env var scoped to NON local datacenter\" do\n      GitHub.local_datacenter = \"cp1\"\n      with_env \"SDC42_ELASTICSEARCH_ACCESS\" => \"raises\" do\n        assert_predicate GitHub, :elasticsearch_access_allowed?\n        refute_predicate GitHub, :elasticsearch_access_ignored?\n        refute_predicate GitHub, :elasticsearch_access_raises?\n      end\n    end\n\n    test \"raises when environment set to an invalid value\" do\n      with_env \"ELASTICSEARCH_ACCESS\" => \"whatever\" do\n        assert_raises TypeError do\n          GitHub.elasticsearch_access_allowed?\n        end\n      end\n    end\n\n    test \"setting elasticsearch_access changes the mode\" do\n      assert_predicate GitHub, :elasticsearch_access_allowed?\n      GitHub.elasticsearch_access = :ignored\n      refute_predicate GitHub, :elasticsearch_access_allowed?\n      assert_predicate GitHub, :elasticsearch_access_ignored?\n    end\n\n    test \"setting elasticsearch_access to an invalid value raises\" do\n      assert_raises TypeError do\n        GitHub.elasticsearch_access = :invalid\n      end\n    end\n  end\nend\n","language":"Ruby"}}]}
